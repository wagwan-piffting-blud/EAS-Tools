/*! For license information please see ort.webgpu.js.LICENSE.txt */
"use strict";var ort=(()=>{var e,t,r,n,o,s,a,i,u,c,d,p,l,f,h,w,m,y,g,b,v,T,E,I,A,C,x,O,U,L,$,R,M,N=Object.defineProperty,B=Object.getOwnPropertyDescriptor,S=Object.getOwnPropertyNames,k=Object.prototype.hasOwnProperty,P=(e=>"undefined"!=typeof require?require:"undefined"!=typeof Proxy?new Proxy(e,{get:(e,t)=>("undefined"!=typeof require?require:e)[t]}):e)(function(e){if("undefined"!=typeof require)return require.apply(this,arguments);throw Error('Dynamic require of "'+e+'" is not supported')}),_=(e,t)=>function(){return e&&(t=(0,e[S(e)[0]])(e=0)),t},G=(e,t)=>{for(var r in t)N(e,r,{get:t[r],enumerable:!0})},D=e=>((e,t,r,n)=>{if(t&&"object"==typeof t||"function"==typeof t)for(let r of S(t))k.call(e,r)||undefined===r||N(e,r,{get:()=>t[r],enumerable:!(n=B(t,r))||n.enumerable});return e})(N({},"__esModule",{value:!0}),e),W=_({"common/dist/esm/backend-impl.js"(){e=new Map,t=[],r=(r,n,o)=>{if(n&&"function"==typeof n.init&&"function"==typeof n.createInferenceSessionHandler){const s=e.get(r);if(void 0===s)e.set(r,{backend:n,priority:o});else{if(s.priority>o)return;if(s.priority===o&&s.backend!==n)throw new Error(`cannot register backend "${r}" using priority ${o}`)}if(o>=0){const n=t.indexOf(r);-1!==n&&t.splice(n,1);for(let n=0;n<t.length;n++)if(e.get(t[n]).priority<=o)return void t.splice(n,0,r);t.push(r)}return}throw new TypeError("not a valid backend")},n=async t=>{const r=e.get(t);if(!r)return"backend not found.";if(r.initialized)return r.backend;if(r.aborted)return r.error;{const e=!!r.initPromise;try{return e||(r.initPromise=r.backend.init(t)),await r.initPromise,r.initialized=!0,r.backend}catch(t){return e||(r.error=`${t}`,r.aborted=!0),r.error}finally{delete r.initPromise}}},o=async e=>{const r=e.executionProviders||[],o=r.map(e=>"string"==typeof e?e:e.name),s=0===o.length?t:o;let a;const i=[],u=new Set;for(const e of s){const t=await n(e);"string"==typeof t?i.push({name:e,err:t}):(a||(a=t),a===t&&u.add(e))}if(!a)throw new Error(`no available backend found. ERR: ${i.map(e=>`[${e.name}] ${e.err}`).join(", ")}`);for(const{name:e,err:t}of i)o.includes(e)&&console.warn(`removing requested execution provider "${e}" from session options because it is not available: ${t}`);const c=r.filter(e=>u.has("string"==typeof e?e:e.name));return[a,new Proxy(e,{get:(e,t)=>"executionProviders"===t?c:Reflect.get(e,t)})]}}}),j=_({"common/dist/esm/backend.js"(){W()}}),F=_({"common/dist/esm/version.js"(){s="1.23.0"}}),V=_({"common/dist/esm/env-impl.js"(){F(),a="warning",i={wasm:{},webgl:{},webgpu:{},versions:{common:s},set logLevel(e){if(void 0!==e){if("string"!=typeof e||-1===["verbose","info","warning","error","fatal"].indexOf(e))throw new Error(`Unsupported logging level: ${e}`);a=e}},get logLevel(){return a}},Object.defineProperty(i,"logLevel",{enumerable:!0})}}),z=_({"common/dist/esm/env.js"(){V(),u=i}}),H=_({"common/dist/esm/tensor-conversion-impl.js"(){c=(e,t)=>{const r="undefined"!=typeof document?document.createElement("canvas"):new OffscreenCanvas(1,1);r.width=e.dims[3],r.height=e.dims[2];const n=r.getContext("2d");if(null!=n){let o,s;void 0!==t?.tensorLayout&&"NHWC"===t.tensorLayout?(o=e.dims[2],s=e.dims[3]):(o=e.dims[3],s=e.dims[2]);const a=void 0!==t?.format?t.format:"RGB",i=t?.norm;let u,c;void 0===i||void 0===i.mean?u=[255,255,255,255]:"number"==typeof i.mean?u=[i.mean,i.mean,i.mean,i.mean]:(u=[i.mean[0],i.mean[1],i.mean[2],0],void 0!==i.mean[3]&&(u[3]=i.mean[3])),void 0===i||void 0===i.bias?c=[0,0,0,0]:"number"==typeof i.bias?c=[i.bias,i.bias,i.bias,i.bias]:(c=[i.bias[0],i.bias[1],i.bias[2],0],void 0!==i.bias[3]&&(c[3]=i.bias[3]));const d=s*o;let p=0,l=d,f=2*d,h=-1;"RGBA"===a?(p=0,l=d,f=2*d,h=3*d):"RGB"===a?(p=0,l=d,f=2*d):"RBG"===a&&(p=0,f=d,l=2*d);for(let t=0;t<s;t++)for(let r=0;r<o;r++){const o=(e.data[p++]-c[0])*u[0],s=(e.data[l++]-c[1])*u[1],a=(e.data[f++]-c[2])*u[2],i=-1===h?255:(e.data[h++]-c[3])*u[3];n.fillStyle="rgba("+o+","+s+","+a+","+i+")",n.fillRect(r,t,1,1)}if("toDataURL"in r)return r.toDataURL();throw new Error("toDataURL is not supported")}throw new Error("Can not access image data")},d=(e,t)=>{const r="undefined"!=typeof document?document.createElement("canvas").getContext("2d"):new OffscreenCanvas(1,1).getContext("2d");let n;if(null==r)throw new Error("Can not access image data");{let o,s,a;void 0!==t?.tensorLayout&&"NHWC"===t.tensorLayout?(o=e.dims[2],s=e.dims[1],a=e.dims[3]):(o=e.dims[3],s=e.dims[2],a=e.dims[1]);const i=void 0!==t&&void 0!==t.format?t.format:"RGB",u=t?.norm;let c,d;void 0===u||void 0===u.mean?c=[255,255,255,255]:"number"==typeof u.mean?c=[u.mean,u.mean,u.mean,u.mean]:(c=[u.mean[0],u.mean[1],u.mean[2],255],void 0!==u.mean[3]&&(c[3]=u.mean[3])),void 0===u||void 0===u.bias?d=[0,0,0,0]:"number"==typeof u.bias?d=[u.bias,u.bias,u.bias,u.bias]:(d=[u.bias[0],u.bias[1],u.bias[2],0],void 0!==u.bias[3]&&(d[3]=u.bias[3]));const p=s*o;if(void 0!==t&&(void 0!==t.format&&4===a&&"RGBA"!==t.format||3===a&&"RGB"!==t.format&&"BGR"!==t.format))throw new Error("Tensor format doesn't match input tensor dims");const l=4;let f=0,h=1,w=2,m=3,y=0,g=p,b=2*p,v=-1;"RGBA"===i?(y=0,g=p,b=2*p,v=3*p):"RGB"===i?(y=0,g=p,b=2*p):"RBG"===i&&(y=0,b=p,g=2*p),n=r.createImageData(o,s);for(let t=0;t<s*o;f+=l,h+=l,w+=l,m+=l,t++)n.data[f]=(e.data[y++]-d[0])*c[0],n.data[h]=(e.data[g++]-d[1])*c[1],n.data[w]=(e.data[b++]-d[2])*c[2],n.data[m]=-1===v?255:(e.data[v++]-d[3])*c[3]}return n}}}),q=_({"common/dist/esm/tensor-factory-impl.js"(){Y(),p=(e,t)=>{if(void 0===e)throw new Error("Image buffer must be defined");if(void 0===t.height||void 0===t.width)throw new Error("Image height and width must be defined");if("NHWC"===t.tensorLayout)throw new Error("NHWC Tensor layout is not supported yet");const{height:r,width:n}=t,o=t.norm??{mean:255,bias:0};let s,a;s="number"==typeof o.mean?[o.mean,o.mean,o.mean,o.mean]:[o.mean[0],o.mean[1],o.mean[2],o.mean[3]??255],a="number"==typeof o.bias?[o.bias,o.bias,o.bias,o.bias]:[o.bias[0],o.bias[1],o.bias[2],o.bias[3]??0];const i=void 0!==t.format?t.format:"RGBA",u=void 0!==t.tensorFormat&&void 0!==t.tensorFormat?t.tensorFormat:"RGB",c=r*n,d="RGBA"===u?new Float32Array(4*c):new Float32Array(3*c);let p=4,l=0,f=1,h=2,w=3,m=0,y=c,g=2*c,b=-1;"RGB"===i&&(p=3,l=0,f=1,h=2,w=-1),"RGBA"===u?b=3*c:"RBG"===u?(m=0,g=c,y=2*c):"BGR"===u&&(g=0,y=c,m=2*c);for(let t=0;t<c;t++,l+=p,h+=p,f+=p,w+=p)d[m++]=(e[l]+a[0])/s[0],d[y++]=(e[f]+a[1])/s[1],d[g++]=(e[h]+a[2])/s[2],-1!==b&&-1!==w&&(d[b++]=(e[w]+a[3])/s[3]);return new I("float32",d,"RGBA"===u?[1,4,r,n]:[1,3,r,n])},l=async(e,t)=>{const r="undefined"!=typeof HTMLImageElement&&e instanceof HTMLImageElement,n="undefined"!=typeof ImageData&&e instanceof ImageData,o="undefined"!=typeof ImageBitmap&&e instanceof ImageBitmap,s="string"==typeof e;let a,i=t??{};const u=()=>{if("undefined"!=typeof document)return document.createElement("canvas");if("undefined"!=typeof OffscreenCanvas)return new OffscreenCanvas(1,1);throw new Error("Canvas is not supported")},c=e=>"undefined"!=typeof HTMLCanvasElement&&e instanceof HTMLCanvasElement||e instanceof OffscreenCanvas?e.getContext("2d"):null;if(r){const r=u();r.width=e.width,r.height=e.height;const n=c(r);if(null==n)throw new Error("Can not access image data");{let r=e.height,o=e.width;if(void 0!==t&&void 0!==t.resizedHeight&&void 0!==t.resizedWidth&&(r=t.resizedHeight,o=t.resizedWidth),void 0!==t){if(i=t,void 0!==t.tensorFormat)throw new Error("Image input config format must be RGBA for HTMLImageElement");i.tensorFormat="RGBA",i.height=r,i.width=o}else i.tensorFormat="RGBA",i.height=r,i.width=o;n.drawImage(e,0,0),a=n.getImageData(0,0,o,r).data}}else{if(!n){if(o){if(void 0===t)throw new Error("Please provide image config with format for Imagebitmap");const r=u();r.width=e.width,r.height=e.height;const n=c(r);if(null!=n){const t=e.height,r=e.width;return n.drawImage(e,0,0,r,t),a=n.getImageData(0,0,r,t).data,i.height=t,i.width=r,p(a,i)}throw new Error("Can not access image data")}if(s)return new Promise((t,r)=>{const n=u(),o=c(n);if(!e||!o)return r();const s=new Image;s.crossOrigin="Anonymous",s.src=e,s.onload=()=>{n.width=s.width,n.height=s.height,o.drawImage(s,0,0,n.width,n.height);const e=o.getImageData(0,0,n.width,n.height);i.height=n.height,i.width=n.width,t(p(e.data,i))}});throw new Error("Input data provided is not supported - aborted tensor creation")}{let r,n;if(void 0!==t&&void 0!==t.resizedWidth&&void 0!==t.resizedHeight?(r=t.resizedHeight,n=t.resizedWidth):(r=e.height,n=e.width),void 0!==t&&(i=t),i.format="RGBA",i.height=r,i.width=n,void 0!==t){const t=u();t.width=n,t.height=r;const o=c(t);if(null==o)throw new Error("Can not access image data");o.putImageData(e,0,0),a=o.getImageData(0,0,n,r).data}else a=e.data}}if(void 0!==a)return p(a,i);throw new Error("Input data provided is not supported - aborted tensor creation")},f=(e,t)=>{const{width:r,height:n,download:o,dispose:s}=t;return new I({location:"texture",type:"float32",texture:e,dims:[1,n,r,4],download:o,dispose:s})},h=(e,t)=>{const{dataType:r,dims:n,download:o,dispose:s}=t;return new I({location:"gpu-buffer",type:r??"float32",gpuBuffer:e,dims:n,download:o,dispose:s})},w=(e,t)=>{const{dataType:r,dims:n,download:o,dispose:s}=t;return new I({location:"ml-tensor",type:r??"float32",mlTensor:e,dims:n,download:o,dispose:s})},m=(e,t,r)=>new I({location:"cpu-pinned",type:e,data:t,dims:r??[t.length]})}}),Z=_({"common/dist/esm/tensor-impl-type-mapping.js"(){y=new Map([["float32",Float32Array],["uint8",Uint8Array],["int8",Int8Array],["uint16",Uint16Array],["int16",Int16Array],["int32",Int32Array],["bool",Uint8Array],["float64",Float64Array],["uint32",Uint32Array],["int4",Uint8Array],["uint4",Uint8Array]]),g=new Map([[Float32Array,"float32"],[Uint8Array,"uint8"],[Int8Array,"int8"],[Uint16Array,"uint16"],[Int16Array,"int16"],[Int32Array,"int32"],[Float64Array,"float64"],[Uint32Array,"uint32"]]),b=!1,v=()=>{if(!b){b=!0;const e="undefined"!=typeof BigInt64Array&&BigInt64Array.from,t="undefined"!=typeof BigUint64Array&&BigUint64Array.from,r=globalThis.Float16Array,n=void 0!==r&&r.from;e&&(y.set("int64",BigInt64Array),g.set(BigInt64Array,"int64")),t&&(y.set("uint64",BigUint64Array),g.set(BigUint64Array,"uint64")),n?(y.set("float16",r),g.set(r,"float16")):y.set("float16",Uint16Array)}}}}),X=_({"common/dist/esm/tensor-utils-impl.js"(){Y(),T=e=>{let t=1;for(let r=0;r<e.length;r++){const n=e[r];if("number"!=typeof n||!Number.isSafeInteger(n))throw new TypeError(`dims[${r}] must be an integer, got: ${n}`);if(n<0)throw new RangeError(`dims[${r}] must be a non-negative integer, got: ${n}`);t*=n}return t},E=(e,t)=>{switch(e.location){case"cpu":return new I(e.type,e.data,t);case"cpu-pinned":return new I({location:"cpu-pinned",data:e.data,type:e.type,dims:t});case"texture":return new I({location:"texture",texture:e.texture,type:e.type,dims:t});case"gpu-buffer":return new I({location:"gpu-buffer",gpuBuffer:e.gpuBuffer,type:e.type,dims:t});case"ml-tensor":return new I({location:"ml-tensor",mlTensor:e.mlTensor,type:e.type,dims:t});default:throw new Error(`tensorReshape: tensor location ${e.location} is not supported`)}}}}),Y=_({"common/dist/esm/tensor-impl.js"(){H(),q(),Z(),X(),I=class{constructor(e,t,r){let n,o;if(v(),"object"==typeof e&&"location"in e)switch(this.dataLocation=e.location,n=e.type,o=e.dims,e.location){case"cpu-pinned":{const t=y.get(n);if(!t)throw new TypeError(`unsupported type "${n}" to create tensor from pinned buffer`);if(!(e.data instanceof t))throw new TypeError(`buffer should be of type ${t.name}`);this.cpuData=e.data;break}case"texture":if("float32"!==n)throw new TypeError(`unsupported type "${n}" to create tensor from texture`);this.gpuTextureData=e.texture,this.downloader=e.download,this.disposer=e.dispose;break;case"gpu-buffer":if("float32"!==n&&"float16"!==n&&"int32"!==n&&"int64"!==n&&"uint32"!==n&&"uint8"!==n&&"bool"!==n&&"uint4"!==n&&"int4"!==n)throw new TypeError(`unsupported type "${n}" to create tensor from gpu buffer`);this.gpuBufferData=e.gpuBuffer,this.downloader=e.download,this.disposer=e.dispose;break;case"ml-tensor":if("float32"!==n&&"float16"!==n&&"int32"!==n&&"int64"!==n&&"uint32"!==n&&"uint64"!==n&&"int8"!==n&&"uint8"!==n&&"bool"!==n&&"uint4"!==n&&"int4"!==n)throw new TypeError(`unsupported type "${n}" to create tensor from MLTensor`);this.mlTensorData=e.mlTensor,this.downloader=e.download,this.disposer=e.dispose;break;default:throw new Error(`Tensor constructor: unsupported location '${this.dataLocation}'`)}else{let s,a;if("string"==typeof e)if(n=e,a=r,"string"===e){if(!Array.isArray(t))throw new TypeError("A string tensor's data must be a string array.");s=t}else{const r=y.get(e);if(void 0===r)throw new TypeError(`Unsupported tensor type: ${e}.`);if(Array.isArray(t)){if("float16"===e&&r===Uint16Array||"uint4"===e||"int4"===e)throw new TypeError(`Creating a ${e} tensor from number array is not supported. Please use ${r.name} as data.`);s="uint64"===e||"int64"===e?r.from(t,BigInt):r.from(t)}else if(t instanceof r)s=t;else if(t instanceof Uint8ClampedArray){if("uint8"!==e)throw new TypeError("A Uint8ClampedArray tensor's data must be type of uint8");s=Uint8Array.from(t)}else{if(!("float16"===e&&t instanceof Uint16Array&&r!==Uint16Array))throw new TypeError(`A ${n} tensor's data must be type of ${r}`);s=new globalThis.Float16Array(t.buffer,t.byteOffset,t.length)}}else if(a=t,Array.isArray(e)){if(0===e.length)throw new TypeError("Tensor type cannot be inferred from an empty array.");const t=typeof e[0];if("string"===t)n="string",s=e;else{if("boolean"!==t)throw new TypeError(`Invalid element type of data array: ${t}.`);n="bool",s=Uint8Array.from(e)}}else if(e instanceof Uint8ClampedArray)n="uint8",s=Uint8Array.from(e);else{const t=g.get(e.constructor);if(void 0===t)throw new TypeError(`Unsupported type for tensor data: ${e.constructor}.`);n=t,s=e}if(void 0===a)a=[s.length];else if(!Array.isArray(a))throw new TypeError("A tensor's dims must be a number array");o=a,this.cpuData=s,this.dataLocation="cpu"}const s=T(o);if(this.cpuData&&s!==this.cpuData.length&&("uint4"!==n&&"int4"!==n||Math.ceil(s/2)!==this.cpuData.length))throw new Error(`Tensor's size(${s}) does not match data length(${this.cpuData.length}).`);this.type=n,this.dims=o,this.size=s}static async fromImage(e,t){return l(e,t)}static fromTexture(e,t){return f(e,t)}static fromGpuBuffer(e,t){return h(e,t)}static fromMLTensor(e,t){return w(e,t)}static fromPinnedBuffer(e,t,r){return m(e,t,r)}toDataURL(e){return c(this,e)}toImageData(e){return d(this,e)}get data(){if(this.ensureValid(),!this.cpuData)throw new Error("The data is not on CPU. Use `getData()` to download GPU data to CPU, or use `texture` or `gpuBuffer` property to access the GPU data directly.");return this.cpuData}get location(){return this.dataLocation}get texture(){if(this.ensureValid(),!this.gpuTextureData)throw new Error("The data is not stored as a WebGL texture.");return this.gpuTextureData}get gpuBuffer(){if(this.ensureValid(),!this.gpuBufferData)throw new Error("The data is not stored as a WebGPU buffer.");return this.gpuBufferData}get mlTensor(){if(this.ensureValid(),!this.mlTensorData)throw new Error("The data is not stored as a WebNN MLTensor.");return this.mlTensorData}async getData(e){switch(this.ensureValid(),this.dataLocation){case"cpu":case"cpu-pinned":return this.data;case"texture":case"gpu-buffer":case"ml-tensor":if(!this.downloader)throw new Error("The current tensor is not created with a specified data downloader.");if(this.isDownloading)throw new Error("The current tensor is being downloaded.");try{this.isDownloading=!0;const t=await this.downloader();return this.downloader=void 0,this.dataLocation="cpu",this.cpuData=t,e&&this.disposer&&(this.disposer(),this.disposer=void 0),t}finally{this.isDownloading=!1}default:throw new Error(`cannot get data from location: ${this.dataLocation}`)}}dispose(){if(this.isDownloading)throw new Error("The current tensor is being downloaded.");this.disposer&&(this.disposer(),this.disposer=void 0),this.cpuData=void 0,this.gpuTextureData=void 0,this.gpuBufferData=void 0,this.mlTensorData=void 0,this.downloader=void 0,this.isDownloading=void 0,this.dataLocation="none"}ensureValid(){if("none"===this.dataLocation)throw new Error("The tensor is disposed.")}reshape(e){if(this.ensureValid(),this.downloader||this.disposer)throw new Error("Cannot reshape a tensor that owns GPU resource.");return E(this,e)}}}}),J=_({"common/dist/esm/tensor.js"(){Y(),A=I}}),K=_({"common/dist/esm/trace.js"(){V(),C=(e,t)=>{(void 0===i.trace?i.wasm.trace:i.trace)&&console.timeStamp(`${e}::ORT::${t}`)},x=(e,t)=>{const r=(new Error).stack?.split(/\r\n|\r|\n/g)||[];let n=!1;for(let o=0;o<r.length;o++){if(n&&!r[o].includes("TRACE_FUNC")){let n=`FUNC_${e}::${r[o].trim().split(" ")[1]}`;return t&&(n+=`::${t}`),void C("CPU",n)}r[o].includes("TRACE_FUNC")&&(n=!0)}},O=e=>{(void 0===i.trace?i.wasm.trace:i.trace)&&x("BEGIN",e)},U=e=>{(void 0===i.trace?i.wasm.trace:i.trace)&&x("END",e)},L=e=>{(void 0===i.trace?i.wasm.trace:i.trace)&&console.time(`ORT::${e}`)},$=e=>{(void 0===i.trace?i.wasm.trace:i.trace)&&console.timeEnd(`ORT::${e}`)}}}),Q=_({"common/dist/esm/inference-session-impl.js"(){W(),J(),K(),R=class e{constructor(e){this.handler=e}async run(e,t,r){O(),L("InferenceSession.run");const n={};let o={};if("object"!=typeof e||null===e||e instanceof A||Array.isArray(e))throw new TypeError("'feeds' must be an object that use input names as keys and OnnxValue as corresponding values.");let s=!0;if("object"==typeof t){if(null===t)throw new TypeError("Unexpected argument[1]: cannot be null.");if(t instanceof A)throw new TypeError("'fetches' cannot be a Tensor");if(Array.isArray(t)){if(0===t.length)throw new TypeError("'fetches' cannot be an empty array.");s=!1;for(const e of t){if("string"!=typeof e)throw new TypeError("'fetches' must be a string array or an object.");if(-1===this.outputNames.indexOf(e))throw new RangeError(`'fetches' contains invalid output name: ${e}.`);n[e]=null}if("object"==typeof r&&null!==r)o=r;else if(void 0!==r)throw new TypeError("'options' must be an object.")}else{let e=!1;const a=Object.getOwnPropertyNames(t);for(const r of this.outputNames)if(-1!==a.indexOf(r)){const o=t[r];(null===o||o instanceof A)&&(e=!0,s=!1,n[r]=o)}if(e){if("object"==typeof r&&null!==r)o=r;else if(void 0!==r)throw new TypeError("'options' must be an object.")}else o=t}}else if(void 0!==t)throw new TypeError("Unexpected argument[1]: must be 'fetches' or 'options'.");for(const t of this.inputNames)if(void 0===e[t])throw new Error(`input '${t}' is missing in 'feeds'.`);if(s)for(const e of this.outputNames)n[e]=null;const a=await this.handler.run(e,n,o),i={};for(const e in a)if(Object.hasOwnProperty.call(a,e)){const t=a[e];i[e]=t instanceof A?t:new A(t.type,t.data,t.dims)}return $("InferenceSession.run"),U(),i}async release(){return this.handler.dispose()}static async create(t,r,n,s){let a;O(),L("InferenceSession.create");let i={};if("string"==typeof t){if(a=t,"object"==typeof r&&null!==r)i=r;else if(void 0!==r)throw new TypeError("'options' must be an object.")}else if(t instanceof Uint8Array){if(a=t,"object"==typeof r&&null!==r)i=r;else if(void 0!==r)throw new TypeError("'options' must be an object.")}else{if(!(t instanceof ArrayBuffer||"undefined"!=typeof SharedArrayBuffer&&t instanceof SharedArrayBuffer))throw new TypeError("Unexpected argument[0]: must be 'path' or 'buffer'.");{const e=t;let o=0,u=t.byteLength;if("object"==typeof r&&null!==r)i=r;else if("number"==typeof r){if(o=r,!Number.isSafeInteger(o))throw new RangeError("'byteOffset' must be an integer.");if(o<0||o>=e.byteLength)throw new RangeError(`'byteOffset' is out of range [0, ${e.byteLength}).`);if(u=t.byteLength-o,"number"==typeof n){if(u=n,!Number.isSafeInteger(u))throw new RangeError("'byteLength' must be an integer.");if(u<=0||o+u>e.byteLength)throw new RangeError(`'byteLength' is out of range (0, ${e.byteLength-o}].`);if("object"==typeof s&&null!==s)i=s;else if(void 0!==s)throw new TypeError("'options' must be an object.")}else if(void 0!==n)throw new TypeError("'byteLength' must be a number.")}else if(void 0!==r)throw new TypeError("'options' must be an object.");a=new Uint8Array(e,o,u)}}const[u,c]=await o(i),d=await u.createInferenceSessionHandler(a,c);return $("InferenceSession.create"),U(),new e(d)}startProfiling(){this.handler.startProfiling()}endProfiling(){this.handler.endProfiling()}get inputNames(){return this.handler.inputNames}get outputNames(){return this.handler.outputNames}get inputMetadata(){return this.handler.inputMetadata}get outputMetadata(){return this.handler.outputMetadata}}}}),ee=_({"common/dist/esm/inference-session.js"(){Q(),M=R}}),te=_({"common/dist/esm/tensor-conversion.js"(){}}),re=_({"common/dist/esm/tensor-factory.js"(){}}),ne=_({"common/dist/esm/onnx-model.js"(){}}),oe=_({"common/dist/esm/onnx-value.js"(){}}),se={};G(se,{InferenceSession:()=>M,TRACE:()=>C,TRACE_EVENT_BEGIN:()=>L,TRACE_EVENT_END:()=>$,TRACE_FUNC_BEGIN:()=>O,TRACE_FUNC_END:()=>U,Tensor:()=>A,env:()=>u,registerBackend:()=>r});var ae,ie,ue,ce,de=_({"common/dist/esm/index.js"(){j(),z(),ee(),J(),te(),re(),K(),ne(),oe()}}),pe=_({"web/lib/wasm/wasm-utils-env.ts"(){ae=!1}}),le={};G(le,{default:()=>ce});var fe,he,we,me,ye,ge,be,ve,Te,Ee,Ie,Ae,Ce,xe,Oe,Ue,Le,$e,Re,Me,Ne,Be,Se,ke,Pe,_e,Ge,De,We,je,Fe,Ve,ze,He,qe,Ze,Xe,Ye,Je,Ke,Qe,et,tt,rt,nt,ot,st,at,it,ut,ct,dt,pt,lt,ft,ht,wt,mt,yt,gt,bt,vt,Tt,Et=_({"web/lib/wasm/proxy-worker/main.ts"(){gr(),At(),It(),ie="ort-wasm-proxy-worker",(ue=globalThis.self?.name===ie)&&(self.onmessage=e=>{const{type:t,in:r}=e.data;try{switch(t){case"init-wasm":Me(r.wasm).then(()=>{St(r).then(()=>{postMessage({type:t})},e=>{postMessage({type:t,err:e})})},e=>{postMessage({type:t,err:e})});break;case"init-ep":{const{epName:e,env:n}=r;kt(n,e).then(()=>{postMessage({type:t})},e=>{postMessage({type:t,err:e})});break}case"copy-from":{const{buffer:e}=r,n=Dt(e);postMessage({type:t,out:n});break}case"create":{const{model:e,options:n}=r;Wt(e,n).then(e=>{postMessage({type:t,out:e})},e=>{postMessage({type:t,err:e})});break}case"release":jt(r),postMessage({type:t});break;case"run":{const{sessionId:e,inputIndices:n,inputs:o,outputIndices:s,options:a}=r;Vt(e,n,o,s,new Array(s.length).fill(null),a).then(e=>{e.some(e=>"cpu"!==e[3])?postMessage({type:t,err:"Proxy does not support non-cpu tensor location."}):postMessage({type:t,out:e},Ht([...o,...e]))},e=>{postMessage({type:t,err:e})});break}case"end-profiling":zt(r),postMessage({type:t})}}catch(e){postMessage({type:t,err:e})}}),ce=ue?null:e=>new Worker(e??he,{type:"classic",name:ie})}}),It=_({"web/lib/wasm/wasm-utils-import.ts"(){pe(),fe=ae||"undefined"==typeof location?void 0:location.origin,he=(()=>{if(!ae)return"undefined"!=typeof document?document.currentScript?.src:"undefined"!=typeof self?self.location?.href:void 0})(),we=()=>{if(he&&!he.startsWith("blob:"))return he.substring(0,he.lastIndexOf("/")+1)},me=(e,t)=>{try{const r=t??he;return(r?new URL(e,r):new URL(e)).origin===fe}catch{return!1}},ye=(e,t)=>{const r=t??he;try{return(r?new URL(e,r):new URL(e)).href}catch{return}},ge=(e,t)=>`${t??"./"}${e}`,be=async e=>{const t=await fetch(e,{credentials:"same-origin"}),r=await t.blob();return URL.createObjectURL(r)},ve=async e=>(await import(e)).default,Te=(Et(),D(le)).default,Ee=async()=>{if(!he)throw new Error("Failed to load proxy worker: cannot determine the script source URL.");if(me(he))return[void 0,Te()];const e=await be(he);return[e,Te(e)]},Ie=void 0,Ae=async(e,t,r,n)=>{let o=Ie;if(o)if(he)o=me(he);else{if(!n||r)throw new Error("cannot determine the script source URL.");o=!0}if(o)return[void 0,Ie];{const n="ort-wasm-simd-threaded.asyncify.mjs",o=e??ye(n,t),s=!ae&&r&&o&&!me(o,t),a=s?await be(o):o??ge(n,t);return[s?a:void 0,await ve(a)]}}}}),At=_({"web/lib/wasm/wasm-factory.ts"(){It(),xe=!1,Oe=!1,Ue=!1,Le=()=>{if("undefined"==typeof SharedArrayBuffer)return!1;try{return"undefined"!=typeof MessageChannel&&(new MessageChannel).port1.postMessage(new SharedArrayBuffer(1)),WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,5,4,1,3,1,1,10,11,1,9,0,65,0,254,16,2,0,26,11]))}catch(e){return!1}},$e=()=>{try{return WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,10,30,1,28,0,65,0,253,15,253,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,253,186,1,26,11]))}catch(e){return!1}},Re=()=>{try{return WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,5,1,96,0,1,123,3,2,1,0,10,19,1,17,0,65,1,253,15,65,2,253,15,65,3,253,15,253,147,2,11]))}catch(e){return!1}},Me=async e=>{if(xe)return Promise.resolve();if(Oe)throw new Error("multiple calls to 'initializeWebAssembly()' detected.");if(Ue)throw new Error("previous call to 'initializeWebAssembly()' failed.");Oe=!0;const t=e.initTimeout;let r=e.numThreads;if(!1===e.simd);else if("relaxed"===e.simd){if(!Re())throw new Error("Relaxed WebAssembly SIMD is not supported in the current environment.")}else if(!$e())throw new Error("WebAssembly SIMD is not supported in the current environment.");const n=Le();r>1&&!n&&("undefined"==typeof self||self.crossOriginIsolated||console.warn("env.wasm.numThreads is set to "+r+", but this will not work unless you enable crossOriginIsolated mode. See https://web.dev/cross-origin-isolation-guide/ for more info."),console.warn("WebAssembly multi-threading is not supported in the current environment. Falling back to single-threading."),e.numThreads=r=1);const o=e.wasmPaths,s="string"==typeof o?o:void 0,a=o?.mjs,i=a?.href??a,u=o?.wasm,c=u?.href??u,d=e.wasmBinary,[p,l]=await Ae(i,s,r>1,!!d||!!c);let f=!1;const h=[];if(t>0&&h.push(new Promise(e=>{setTimeout(()=>{f=!0,e()},t)})),h.push(new Promise((e,t)=>{const n={numThreads:r};if(d)n.wasmBinary=d;else if(c||s)n.locateFile=e=>c??s+e;else if(i&&0!==i.indexOf("blob:"))n.locateFile=e=>new URL(e,i).href;else if(p){const e=we();e&&(n.locateFile=t=>e+t)}l(n).then(t=>{Oe=!1,xe=!0,Ce=t,e(),p&&URL.revokeObjectURL(p)},e=>{Oe=!1,Ue=!0,t(e)})})),await Promise.race(h),f)throw new Error(`WebAssembly backend initializing failed due to timeout: ${t}ms`)},Ne=()=>{if(xe&&Ce)return Ce;throw new Error("WebAssembly is not initialized yet.")}}}),Ct=_({"web/lib/wasm/wasm-utils.ts"(){At(),Be=(e,t)=>{const r=Ne(),n=r.lengthBytesUTF8(e)+1,o=r._malloc(n);return r.stringToUTF8(e,o,n),t.push(o),o},Se=(e,t,r,n)=>{if("object"==typeof e&&null!==e){if(r.has(e))throw new Error("Circular reference in options");r.add(e)}Object.entries(e).forEach(([e,o])=>{const s=t?t+e:e;if("object"==typeof o)Se(o,s+".",r,n);else if("string"==typeof o||"number"==typeof o)n(s,o.toString());else{if("boolean"!=typeof o)throw new Error("Can't handle extra config type: "+typeof o);n(s,o?"1":"0")}})},ke=e=>{const t=Ne(),r=t.stackSave();try{const r=t.PTR_SIZE,n=t.stackAlloc(2*r);t._OrtGetLastError(n,n+r);const o=Number(t.getValue(n,4===r?"i32":"i64")),s=t.getValue(n+r,"*"),a=s?t.UTF8ToString(s):"";throw new Error(`${e} ERROR_CODE: ${o}, ERROR_MESSAGE: ${a}`)}finally{t.stackRestore(r)}}}}),xt=_({"web/lib/wasm/run-options.ts"(){At(),Ct(),Pe=e=>{const t=Ne();let r=0;const n=[],o=e||{};try{if(void 0===e?.logSeverityLevel)o.logSeverityLevel=2;else if("number"!=typeof e.logSeverityLevel||!Number.isInteger(e.logSeverityLevel)||e.logSeverityLevel<0||e.logSeverityLevel>4)throw new Error(`log severity level is not valid: ${e.logSeverityLevel}`);if(void 0===e?.logVerbosityLevel)o.logVerbosityLevel=0;else if("number"!=typeof e.logVerbosityLevel||!Number.isInteger(e.logVerbosityLevel))throw new Error(`log verbosity level is not valid: ${e.logVerbosityLevel}`);void 0===e?.terminate&&(o.terminate=!1);let s=0;return void 0!==e?.tag&&(s=Be(e.tag,n)),r=t._OrtCreateRunOptions(o.logSeverityLevel,o.logVerbosityLevel,!!o.terminate,s),0===r&&ke("Can't create run options."),void 0!==e?.extra&&Se(e.extra,"",new WeakSet,(e,o)=>{const s=Be(e,n),a=Be(o,n);0!==t._OrtAddRunConfigEntry(r,s,a)&&ke(`Can't set a run config entry: ${e} - ${o}.`)}),[r,n]}catch(e){throw 0!==r&&t._OrtReleaseRunOptions(r),n.forEach(e=>t._free(e)),e}}}}),Ot=_({"web/lib/wasm/session-options.ts"(){At(),Ct(),_e=e=>{switch(e){case"disabled":return 0;case"basic":return 1;case"extended":return 2;case"layout":return 3;case"all":return 99;default:throw new Error(`unsupported graph optimization level: ${e}`)}},Ge=e=>{switch(e){case"sequential":return 0;case"parallel":return 1;default:throw new Error(`unsupported execution mode: ${e}`)}},De=e=>{e.extra||(e.extra={}),e.extra.session||(e.extra.session={});const t=e.extra.session;t.use_ort_model_bytes_directly||(t.use_ort_model_bytes_directly="1"),e.executionProviders&&e.executionProviders.some(e=>"webgpu"===("string"==typeof e?e:e.name))&&(e.enableMemPattern=!1)},We=(e,t,r,n)=>{const o=Be(t,n),s=Be(r,n);0!==Ne()._OrtAddSessionConfigEntry(e,o,s)&&ke(`Can't set a session config entry: ${t} - ${r}.`)},je=(e,t,r,n)=>{const o=Be(t,n),s=Be(r,n);e.push([o,s])},Fe=async(e,t,r)=>{for(const n of t){let t="string"==typeof n?n:n.name;const o=[];switch(t){case"webnn":if(t="WEBNN","string"!=typeof n){const t=n,o=t?.deviceType;o&&We(e,"deviceType",o,r)}break;case"webgpu":{let e;if(t="WebGPU","string"!=typeof n){const t=n;if(t.device){if(!("undefined"!=typeof GPUDevice&&t.device instanceof GPUDevice))throw new Error("Invalid GPU device set in WebGPU EP options.");e=t.device}}const s=Ne().webgpuRegisterDevice(e);if(s){const[e,t,n]=s;je(o,"deviceId",e.toString(),r),je(o,"webgpuInstance",t.toString(),r),je(o,"webgpuDevice",n.toString(),r)}}break;case"wasm":case"cpu":continue;default:throw new Error(`not supported execution provider: ${t}`)}const s=Be(t,r),a=o.length;let i=0,u=0;if(a>0){i=Ne()._malloc(a*Ne().PTR_SIZE),r.push(i),u=Ne()._malloc(a*Ne().PTR_SIZE),r.push(u);for(let e=0;e<a;e++)Ne().setValue(i+e*Ne().PTR_SIZE,o[e][0],"*"),Ne().setValue(u+e*Ne().PTR_SIZE,o[e][1],"*")}0!==await Ne()._OrtAppendExecutionProvider(e,s,i,u,a)&&ke(`Can't append execution provider: ${t}.`)}},Ve=async e=>{const t=Ne();let r=0;const n=[],o=e||{};De(o);try{const e=_e(o.graphOptimizationLevel??"all"),s=Ge(o.executionMode??"sequential"),a="string"==typeof o.logId?Be(o.logId,n):0,i=o.logSeverityLevel??2;if(!Number.isInteger(i)||i<0||i>4)throw new Error(`log severity level is not valid: ${i}`);const u=o.logVerbosityLevel??0;if(!Number.isInteger(u)||u<0||u>4)throw new Error(`log verbosity level is not valid: ${u}`);const c="string"==typeof o.optimizedModelFilePath?Be(o.optimizedModelFilePath,n):0;if(r=t._OrtCreateSessionOptions(e,!!o.enableCpuMemArena,!!o.enableMemPattern,s,!!o.enableProfiling,0,a,i,u,c),0===r&&ke("Can't create session options."),o.executionProviders&&await Fe(r,o.executionProviders,n),void 0!==o.enableGraphCapture){if("boolean"!=typeof o.enableGraphCapture)throw new Error(`enableGraphCapture must be a boolean value: ${o.enableGraphCapture}`);We(r,"enableGraphCapture",o.enableGraphCapture.toString(),n)}if(o.freeDimensionOverrides)for(const[e,s]of Object.entries(o.freeDimensionOverrides)){if("string"!=typeof e)throw new Error(`free dimension override name must be a string: ${e}`);if("number"!=typeof s||!Number.isInteger(s)||s<0)throw new Error(`free dimension override value must be a non-negative integer: ${s}`);const o=Be(e,n);0!==t._OrtAddFreeDimensionOverride(r,o,s)&&ke(`Can't set a free dimension override: ${e} - ${s}.`)}return void 0!==o.extra&&Se(o.extra,"",new WeakSet,(e,t)=>{We(r,e,t,n)}),[r,n]}catch(e){throw 0!==r&&0!==t._OrtReleaseSessionOptions(r)&&ke("Can't release session options."),n.forEach(e=>t._free(e)),e}}}}),Ut=_({"web/lib/wasm/wasm-common.ts"(){ze=e=>{switch(e){case"int8":return 3;case"uint8":return 2;case"bool":return 9;case"int16":return 5;case"uint16":return 4;case"int32":return 6;case"uint32":return 12;case"float16":return 10;case"float32":return 1;case"float64":return 11;case"string":return 8;case"int64":return 7;case"uint64":return 13;case"int4":return 22;case"uint4":return 21;default:throw new Error(`unsupported data type: ${e}`)}},He=e=>{switch(e){case 3:return"int8";case 2:return"uint8";case 9:return"bool";case 5:return"int16";case 4:return"uint16";case 6:return"int32";case 12:return"uint32";case 10:return"float16";case 1:return"float32";case 11:return"float64";case 8:return"string";case 7:return"int64";case 13:return"uint64";case 22:return"int4";case 21:return"uint4";default:throw new Error(`unsupported data type: ${e}`)}},qe=(e,t)=>{const r=[-1,4,1,1,2,2,4,8,-1,1,2,8,4,8,-1,-1,-1,-1,-1,-1,-1,.5,.5][e],n="number"==typeof t?t:t.reduce((e,t)=>e*t,1);return r>0?Math.ceil(n*r):void 0},Ze=e=>{switch(e){case"float16":return"undefined"!=typeof Float16Array&&Float16Array.from?Float16Array:Uint16Array;case"float32":return Float32Array;case"uint8":case"bool":return Uint8Array;case"int8":return Int8Array;case"uint16":return Uint16Array;case"int16":return Int16Array;case"int32":return Int32Array;case"float64":return Float64Array;case"uint32":return Uint32Array;case"int64":return BigInt64Array;case"uint64":return BigUint64Array;default:throw new Error(`unsupported type: ${e}`)}},Xe=e=>{switch(e){case"verbose":return 0;case"info":return 1;case"warning":return 2;case"error":return 3;case"fatal":return 4;default:throw new Error(`unsupported logging level: ${e}`)}},Ye=e=>"float32"===e||"float16"===e||"int32"===e||"int64"===e||"uint32"===e||"uint8"===e||"bool"===e||"uint4"===e||"int4"===e,Je=e=>"float32"===e||"float16"===e||"int32"===e||"int64"===e||"uint32"===e||"uint64"===e||"int8"===e||"uint8"===e||"bool"===e||"uint4"===e||"int4"===e,Ke=e=>{switch(e){case"none":return 0;case"cpu":return 1;case"cpu-pinned":return 2;case"texture":return 3;case"gpu-buffer":return 4;case"ml-tensor":return 5;default:throw new Error(`unsupported data location: ${e}`)}}}}),Lt=_({"web/lib/wasm/wasm-utils-load-file.ts"(){pe(),Qe=async e=>{if("string"!=typeof e)return e instanceof Blob?new Uint8Array(await e.arrayBuffer()):e instanceof Uint8Array?e:new Uint8Array(e);if(!ae){const t=await fetch(e);if(!t.ok)throw new Error(`failed to load external data file: ${e}`);const r=t.headers.get("Content-Length"),n=r?parseInt(r,10):0;if(n<1073741824)return new Uint8Array(await t.arrayBuffer());{if(!t.body)throw new Error(`failed to load external data file: ${e}, no response body.`);const r=t.body.getReader();let o;try{o=new ArrayBuffer(n)}catch(e){if(!(e instanceof RangeError))throw e;{const e=Math.ceil(n/65536);o=new WebAssembly.Memory({initial:e,maximum:e}).buffer}}let s=0;for(;;){const{done:e,value:t}=await r.read();if(e)break;const n=t.byteLength;new Uint8Array(o,s,n).set(t),s+=n}return new Uint8Array(o,0,n)}}try{const{readFile:t}=P("node:fs/promises");return new Uint8Array(await t(e))}catch(t){if("ERR_FS_FILE_TOO_LARGE"===t.code){const{createReadStream:t}=P("node:fs"),r=t(e),n=[];for await(const e of r)n.push(e);return new Uint8Array(Buffer.concat(n))}throw t}}}}),$t=_({"web/lib/wasm/jsep/tensor-view.ts"(){Ut(),et=(e,t)=>new(Ze(t))(e)}}),Rt=_({"web/lib/wasm/jsep/log.ts"(){Ut(),tt=["V","I","W","E","F"],rt=(e,t)=>{console.log(`[${tt[e]},${(new Date).toISOString()}]${t}`)},st=(e,t)=>{nt=e,ot=t},at=(e,t)=>{const r=Xe(e);r>=Xe(nt)&&rt(r,"function"==typeof t?t():t)},it=(...e)=>{ot&&at(...e)}}}),Mt=_({"web/lib/wasm/jsep/webnn/tensor-manager.ts"(){Ut(),Rt(),ut=new Map([["float32",32],["float16",16],["int32",32],["uint32",32],["int64",64],["uint64",64],["int8",8],["uint8",8],["int4",4],["uint4",4]]),ct=(e,t)=>{if("int32"===t)return e;const r=ut.get(t);if(!r)throw new Error(`WebNN backend does not support data type: ${t}`);const n=r/8;if(e.byteLength%n!==0)throw new Error(`Invalid Uint8Array length - must be a multiple of ${n}.`);const o=e.byteLength/n,s=new(Ze(t))(e.buffer,e.byteOffset,o);switch(t){case"int64":case"uint64":{const e=new Int32Array(o);for(let t=0;t<o;t++){const r=s[t];if(r>2147483647n||r<-2147483648n)throw new Error("Can not convert int64 data to int32 - value out of range.");e[t]=Number(r)}return new Uint8Array(e.buffer)}case"int8":case"uint8":case"uint32":{if("uint32"===t&&s.some(e=>e>2147483647))throw new Error("Can not convert uint32 data to int32 - value out of range.");const e=Int32Array.from(s,Number);return new Uint8Array(e.buffer)}default:throw new Error(`Unsupported data conversion from ${t} to 'int32'`)}},dt=(e,t)=>{if("int32"===t)return e;if(e.byteLength%4!=0)throw new Error("Invalid Uint8Array length - must be a multiple of 4 (int32).");const r=e.byteLength/4,n=new Int32Array(e.buffer,e.byteOffset,r);switch(t){case"int64":{const e=BigInt64Array.from(n,BigInt);return new Uint8Array(e.buffer)}case"uint64":{if(n.some(e=>e<0))throw new Error("Can not convert int32 data to uin64 - negative value found.");const e=BigUint64Array.from(n,BigInt);return new Uint8Array(e.buffer)}case"int8":{if(n.some(e=>e<-128||e>127))throw new Error("Can not convert int32 data to int8 - value out of range.");const e=Int8Array.from(n,Number);return new Uint8Array(e.buffer)}case"uint8":if(n.some(e=>e<0||e>255))throw new Error("Can not convert int32 data to uint8 - value out of range.");return Uint8Array.from(n,Number);case"uint32":{if(n.some(e=>e<0))throw new Error("Can not convert int32 data to uint32 - negative value found.");const e=Uint32Array.from(n,Number);return new Uint8Array(e.buffer)}default:throw new Error(`Unsupported data conversion from 'int32' to ${t}`)}},pt=1,lt=()=>pt++,ft=new Map([["int8","int32"],["uint8","int32"],["uint32","int32"],["int64","int32"]]),ht=(e,t)=>{const r=ut.get(e);if(!r)throw new Error(`WebNN backend does not support data type: ${e}`);return t.length>0?Math.ceil(t.reduce((e,t)=>e*t)*r/8):0},wt=class{constructor(e){this.isDataConverted=!1;const{sessionId:t,context:r,tensor:n,dataType:o,shape:s,fallbackDataType:a}=e;this.sessionId=t,this.mlContext=r,this.mlTensor=n,this.dataType=o,this.tensorShape=s,this.fallbackDataType=a}get tensor(){return this.mlTensor}get type(){return this.dataType}get fallbackType(){return this.fallbackDataType}get shape(){return this.tensorShape}get byteLength(){return ht(this.dataType,this.tensorShape)}destroy(){it("verbose",()=>"[WebNN] TensorWrapper.destroy"),this.mlTensor.destroy()}write(e){this.mlContext.writeTensor(this.mlTensor,e)}async read(e){if(this.fallbackDataType){const t=await this.mlContext.readTensor(this.mlTensor),r=dt(new Uint8Array(t),this.dataType);return e?void(e instanceof ArrayBuffer?new Uint8Array(e):new Uint8Array(e.buffer,e.byteOffset,e.byteLength)).set(r):r.buffer}return e?this.mlContext.readTensor(this.mlTensor,e):this.mlContext.readTensor(this.mlTensor)}canReuseTensor(e,t,r){return this.mlContext===e&&this.dataType===t&&this.tensorShape.length===r.length&&this.tensorShape.every((e,t)=>e===r[t])}setIsDataConverted(e){this.isDataConverted=e}},mt=class{constructor(e,t){this.tensorManager=e,this.wrapper=t}get tensorWrapper(){return this.wrapper}releaseTensor(){this.tensorWrapper&&(this.tensorManager.releaseTensor(this.tensorWrapper),this.wrapper=void 0)}async ensureTensor(e,t,r,n){const o=this.tensorManager.getMLContext(e);let s;if(!o.opSupportLimits().input.dataTypes.includes(t)){if(s=ft.get(t),!s||!o.opSupportLimits().input.dataTypes.includes(s))throw new Error(`WebNN backend does not support data type: ${t}`);it("verbose",()=>`[WebNN] TensorIdTracker.ensureTensor: fallback dataType from ${t} to ${s}`)}if(this.wrapper){if(this.wrapper.canReuseTensor(o,t,r))return this.wrapper.tensor;if(n){if(this.wrapper.byteLength!==ht(t,r))throw new Error("Unable to copy data to tensor with different size.");this.activeUpload=new Uint8Array(await this.wrapper.read())}this.tensorManager.releaseTensor(this.wrapper)}const a="undefined"==typeof MLTensorUsage?void 0:MLTensorUsage.READ|MLTensorUsage.WRITE;return this.wrapper=await this.tensorManager.getCachedTensor(e,t,r,a,!0,!0,s),n&&this.activeUpload&&(this.wrapper.write(this.activeUpload),this.activeUpload=void 0),this.wrapper.tensor}upload(e){let t=e;if(this.wrapper){if(this.wrapper.fallbackType){if("int32"!==this.wrapper.fallbackType)throw new Error(`Unsupported fallback data type: ${this.wrapper.fallbackType}`);t=ct(e,this.wrapper.type),this.wrapper.setIsDataConverted(!0)}if(e.byteLength===this.wrapper.byteLength)return void this.wrapper.write(t);it("verbose",()=>"Data size does not match tensor size. Releasing tensor."),this.releaseTensor()}this.activeUpload?this.activeUpload.set(t):this.activeUpload=new Uint8Array(t)}async download(e){if(this.activeUpload){const t=this.wrapper?.isDataConverted?dt(this.activeUpload,this.wrapper?.type):this.activeUpload;return e?void(e instanceof ArrayBuffer?new Uint8Array(e).set(t):new Uint8Array(e.buffer,e.byteOffset,e.byteLength).set(t)):t.buffer}if(!this.wrapper)throw new Error("Tensor has not been created.");return e?this.wrapper.read(e):this.wrapper.read()}},yt=class{constructor(e){this.backend=e,this.tensorTrackersById=new Map,this.freeTensors=[],this.externalTensors=new Set}getMLContext(e){const t=this.backend.getMLContext(e);if(!t)throw new Error("MLContext not found for session.");return t}reserveTensorId(){const e=lt();return this.tensorTrackersById.set(e,new mt(this)),e}releaseTensorId(e){const t=this.tensorTrackersById.get(e);t&&(this.tensorTrackersById.delete(e),t.tensorWrapper&&this.releaseTensor(t.tensorWrapper))}async ensureTensor(e,t,r,n,o){it("verbose",()=>`[WebNN] TensorManager.ensureTensor {tensorId: ${t}, dataType: ${r}, shape: ${n}, copyOld: ${o}}`);const s=this.tensorTrackersById.get(t);if(!s)throw new Error("Tensor not found.");return s.ensureTensor(e,r,n,o)}upload(e,t){const r=this.tensorTrackersById.get(e);if(!r)throw new Error("Tensor not found.");r.upload(t)}async download(e,t){it("verbose",()=>`[WebNN] TensorManager.download {tensorId: ${e}, dstBuffer: ${t?.byteLength}}`);const r=this.tensorTrackersById.get(e);if(!r)throw new Error("Tensor not found.");return r.download(t)}releaseTensorsForSession(e){for(const t of this.freeTensors)t.sessionId===e&&t.destroy();this.freeTensors=this.freeTensors.filter(t=>t.sessionId!==e)}registerTensor(e,t,r,n){const o=this.getMLContext(e),s=lt(),a=new wt({sessionId:e,context:o,tensor:t,dataType:r,shape:n});return this.tensorTrackersById.set(s,new mt(this,a)),this.externalTensors.add(a),s}async getCachedTensor(e,t,r,n,o,s,a){const i=this.getMLContext(e);for(const[n,o]of this.freeTensors.entries())if(o.canReuseTensor(i,t,r)){it("verbose",()=>`[WebNN] Reusing tensor {dataType: ${t}, ${a?`fallbackDataType: ${a},`:""} shape: ${r}`);const o=this.freeTensors.splice(n,1)[0];return o.sessionId=e,o}it("verbose",()=>`[WebNN] MLContext.createTensor {dataType: ${t}, ${a?`fallbackDataType: ${a},`:""} shape: ${r}}`);const u=await i.createTensor({dataType:a??t,shape:r,dimensions:r,usage:n,writable:o,readable:s});return new wt({sessionId:e,context:i,tensor:u,dataType:t,shape:r,fallbackDataType:a})}releaseTensor(e){this.externalTensors.has(e)&&this.externalTensors.delete(e),this.freeTensors.push(e)}},gt=(...e)=>new yt(...e)}}),Nt={};G(Nt,{WebNNBackend:()=>Tt});var Bt,St,kt,Pt,_t,Gt,Dt,Wt,jt,Ft,Vt,zt,Ht,qt,Zt,Xt,Yt,Jt,Kt,Qt,er,tr,rr,nr,or,sr,ar,ir,ur,cr,dr,pr,lr,fr,hr,wr,mr,yr=_({"web/lib/wasm/jsep/backend-webnn.ts"(){Ut(),At(),$t(),Mt(),Rt(),bt=new Map([[1,"float32"],[10,"float16"],[6,"int32"],[12,"uint32"],[7,"int64"],[13,"uint64"],[22,"int4"],[21,"uint4"],[3,"int8"],[2,"uint8"],[9,"uint8"]]),vt=(e,t)=>{if(e===t)return!0;if(void 0===e||void 0===t)return!1;const r=Object.keys(e).sort(),n=Object.keys(t).sort();return r.length===n.length&&r.every((r,o)=>r===n[o]&&e[r]===t[r])},Tt=class{constructor(e){this.tensorManager=gt(this),this.mlContextBySessionId=new Map,this.sessionIdsByMLContext=new Map,this.mlContextCache=[],this.sessionGraphInputs=new Map,this.sessionGraphOutputs=new Map,this.temporaryGraphInputs=[],this.temporaryGraphOutputs=[],this.temporarySessionTensorIds=new Map,st(e.logLevel,!!e.debug)}get currentSessionId(){if(void 0===this.activeSessionId)throw new Error("No active session");return this.activeSessionId}onRunStart(e){it("verbose",()=>`[WebNN] onRunStart {sessionId: ${e}}`),this.activeSessionId=e}onRunEnd(e){it("verbose",()=>`[WebNN] onRunEnd {sessionId: ${e}}`);const t=this.temporarySessionTensorIds.get(e);if(t){for(const e of t)it("verbose",()=>`[WebNN] releasing temporary tensor {tensorId: ${e}}`),this.tensorManager.releaseTensorId(e);this.temporarySessionTensorIds.delete(e),this.activeSessionId=void 0}}async createMLContext(e){if(e instanceof GPUDevice){const t=this.mlContextCache.findIndex(t=>t.gpuDevice===e);if(-1!==t)return this.mlContextCache[t].mlContext;{const t=await navigator.ml.createContext(e);return this.mlContextCache.push({gpuDevice:e,mlContext:t}),t}}if(void 0===e){const e=this.mlContextCache.findIndex(e=>void 0===e.options&&void 0===e.gpuDevice);if(-1!==e)return this.mlContextCache[e].mlContext;{const e=await navigator.ml.createContext();return this.mlContextCache.push({mlContext:e}),e}}const t=this.mlContextCache.findIndex(t=>vt(t.options,e));if(-1!==t)return this.mlContextCache[t].mlContext;{const t=await navigator.ml.createContext(e);return this.mlContextCache.push({options:e,mlContext:t}),t}}registerMLContext(e,t){this.mlContextBySessionId.set(e,t);let r=this.sessionIdsByMLContext.get(t);r||(r=new Set,this.sessionIdsByMLContext.set(t,r)),r.add(e),this.temporaryGraphInputs.length>0&&(this.sessionGraphInputs.set(e,this.temporaryGraphInputs),this.temporaryGraphInputs=[]),this.temporaryGraphOutputs.length>0&&(this.sessionGraphOutputs.set(e,this.temporaryGraphOutputs),this.temporaryGraphOutputs=[])}onReleaseSession(e){this.sessionGraphInputs.delete(e),this.sessionGraphOutputs.delete(e);const t=this.mlContextBySessionId.get(e);if(!t)return;this.tensorManager.releaseTensorsForSession(e),this.mlContextBySessionId.delete(e);const r=this.sessionIdsByMLContext.get(t);if(r.delete(e),0===r.size){this.sessionIdsByMLContext.delete(t);const e=this.mlContextCache.findIndex(e=>e.mlContext===t);-1!==e&&this.mlContextCache.splice(e,1)}}getMLContext(e){return this.mlContextBySessionId.get(e)}reserveTensorId(){return this.tensorManager.reserveTensorId()}releaseTensorId(e){it("verbose",()=>`[WebNN] releaseTensorId {tensorId: ${e}}`),this.tensorManager.releaseTensorId(e)}async ensureTensor(e,t,r,n,o){const s=bt.get(r);if(!s)throw new Error(`Unsupported ONNX data type: ${r}`);return this.tensorManager.ensureTensor(e??this.currentSessionId,t,s,n,o)}async createTemporaryTensor(e,t,r){it("verbose",()=>`[WebNN] createTemporaryTensor {onnxDataType: ${t}, shape: ${r}}`);const n=bt.get(t);if(!n)throw new Error(`Unsupported ONNX data type: ${t}`);const o=this.tensorManager.reserveTensorId();await this.tensorManager.ensureTensor(e,o,n,r,!1);const s=this.temporarySessionTensorIds.get(e);return s?s.push(o):this.temporarySessionTensorIds.set(e,[o]),o}uploadTensor(e,t){if(!Ne().shouldTransferToMLTensor)throw new Error("Trying to upload to a MLTensor while shouldTransferToMLTensor is false");it("verbose",()=>`[WebNN] uploadTensor {tensorId: ${e}, data: ${t.byteLength}}`),this.tensorManager.upload(e,t)}async downloadTensor(e,t){return this.tensorManager.download(e,t)}createMLTensorDownloader(e,t){return async()=>{const r=await this.tensorManager.download(e);return et(r,t)}}registerMLTensor(e,t,r,n){const o=bt.get(r);if(!o)throw new Error(`Unsupported ONNX data type: ${r}`);const s=this.tensorManager.registerTensor(e,t,o,n);return it("verbose",()=>`[WebNN] registerMLTensor {tensor: ${t}, dataType: ${o}, dimensions: ${n}} -> {tensorId: ${s}}`),s}registerMLConstant(e,t,r,n,o,s,a=!1){if(!s)throw new Error("External mounted files are not available.");let i=e;e.startsWith("./")&&(i=e.substring(2));const u=s.get(i);if(!u)throw new Error(`File with name ${i} not found in preloaded files.`);if(t+r>u.byteLength)throw new Error("Out of bounds: data offset and length exceed the external file data size.");const c=u.slice(t,t+r).buffer;let d;switch(o.dataType){case"float32":d=new Float32Array(c);break;case"float16":d="undefined"!=typeof Float16Array&&Float16Array.from?new Float16Array(c):new Uint16Array(c);break;case"int32":d=new Int32Array(c);break;case"uint32":d=new Uint32Array(c);break;case"int64":if(a){const e=ct(new Uint8Array(c),"int64");d=new Int32Array(e.buffer),o.dataType="int32"}else d=new BigInt64Array(c);break;case"uint64":d=new BigUint64Array(c);break;case"int8":d=new Int8Array(c);break;case"int4":case"uint4":case"uint8":d=new Uint8Array(c);break;default:throw new Error(`Unsupported data type: ${o.dataType} in creating WebNN Constant from external data.`)}return it("verbose",()=>`[WebNN] registerMLConstant {dataType: ${o.dataType}, shape: ${o.shape}}} ${a?"(Note: it was int64 data type and registered to int32 as workaround)":""}`),n.constant(o,d)}registerGraphInput(e){this.temporaryGraphInputs.push(e)}registerGraphOutput(e){this.temporaryGraphOutputs.push(e)}isGraphInput(e,t){const r=this.sessionGraphInputs.get(e);return!!r&&r.includes(t)}isGraphOutput(e,t){const r=this.sessionGraphOutputs.get(e);return!!r&&r.includes(t)}isGraphInputOutputTypeSupported(e,t,r=!0){const n=this.mlContextBySessionId.get(e),o=bt.get(ze(t));return void 0!==o&&(r?!!n?.opSupportLimits().input.dataTypes.includes(o):!!n?.opSupportLimits().output.dataTypes.includes(o))}flush(){}}}}),gr=_({"web/lib/wasm/wasm-core-impl.ts"(){de(),xt(),Ot(),Ut(),At(),Ct(),Lt(),Bt=(e,t)=>{0!==Ne()._OrtInit(e,t)&&ke("Can't initialize onnxruntime.")},St=async e=>{Bt(e.wasm.numThreads,Xe(e.logLevel))},kt=async(e,t)=>{Ne().asyncInit?.();let r=e.webgpu.adapter;if("webgpu"===t){if("undefined"==typeof navigator||!navigator.gpu)throw new Error("WebGPU is not supported in current environment");if(r){if("object"!=typeof r.limits||"object"!=typeof r.features||"function"!=typeof r.requestDevice)throw new Error("Invalid GPU adapter set in `env.webgpu.adapter`. It must be a GPUAdapter object.")}else{const t=e.webgpu.powerPreference;if(void 0!==t&&"low-power"!==t&&"high-performance"!==t)throw new Error(`Invalid powerPreference setting: "${t}"`);const n=e.webgpu.forceFallbackAdapter;if(void 0!==n&&"boolean"!=typeof n)throw new Error(`Invalid forceFallbackAdapter setting: "${n}"`);if(r=await navigator.gpu.requestAdapter({powerPreference:t,forceFallbackAdapter:n}),!r)throw new Error('Failed to get GPU adapter. You may need to enable flag "--enable-unsafe-webgpu" if you are using Chrome.')}}if("webnn"===t&&("undefined"==typeof navigator||!navigator.ml))throw new Error("WebNN is not supported in current environment");if("webgpu"===t&&Ne().webgpuInit(t=>{e.webgpu.device=t}),"webnn"===t){const t=new((yr(),D(Nt)).WebNNBackend)(e);Ne().webnnInit([t,()=>t.reserveTensorId(),e=>t.releaseTensorId(e),async(e,r,n,o,s)=>t.ensureTensor(e,r,n,o,s),(e,r)=>{t.uploadTensor(e,r)},async(e,r)=>t.downloadTensor(e,r),(e,r)=>t.registerMLContext(e,r),!!e.trace])}},Pt=new Map,_t=e=>{const t=Ne(),r=t.stackSave();try{const r=t.PTR_SIZE,n=t.stackAlloc(2*r);0!==t._OrtGetInputOutputCount(e,n,n+r)&&ke("Can't get session input/output count.");const o=4===r?"i32":"i64";return[Number(t.getValue(n,o)),Number(t.getValue(n+r,o))]}finally{t.stackRestore(r)}},Gt=(e,t)=>{const r=Ne(),n=r.stackSave();let o=0;try{const n=r.PTR_SIZE,s=r.stackAlloc(2*n);0!==r._OrtGetInputOutputMetadata(e,t,s,s+n)&&ke("Can't get session input/output metadata.");const a=Number(r.getValue(s,"*"));o=Number(r.getValue(s+n,"*"));const i=r.HEAP32[o/4];if(0===i)return[a,0];const u=r.HEAPU32[o/4+1],c=[];for(let e=0;e<u;e++){const t=Number(r.getValue(o+8+e*n,"*"));c.push(0!==t?r.UTF8ToString(t):Number(r.getValue(o+8+(e+u)*n,"*")))}return[a,i,c]}finally{r.stackRestore(n),0!==o&&r._OrtFree(o)}},Dt=e=>{const t=Ne(),r=t._malloc(e.byteLength);if(0===r)throw new Error(`Can't create a session. failed to allocate a buffer of size ${e.byteLength}.`);return t.HEAPU8.set(e,r),[r,e.byteLength]},Wt=async(e,t)=>{let r,n;const o=Ne();Array.isArray(e)?[r,n]=e:e.buffer===o.HEAPU8.buffer?[r,n]=[e.byteOffset,e.byteLength]:[r,n]=Dt(e);let s=0,a=0,i=0,u=[];const c=[],d=[];try{if([a,u]=await Ve(t),t?.externalData&&o.mountExternalData){const e=[];for(const r of t.externalData){const t="string"==typeof r?r:r.path;e.push(Qe("string"==typeof r?r:r.data).then(e=>{o.mountExternalData(t,e)}))}await Promise.all(e)}for(const e of t?.executionProviders??[])if("webnn"===("string"==typeof e?e:e.name)){if(o.shouldTransferToMLTensor=!1,"string"!=typeof e){const t=e,r=t?.context,n=t?.gpuDevice,s=t?.deviceType,a=t?.powerPreference;o.currentContext=r||(n?await o.webnnCreateMLContext(n):await o.webnnCreateMLContext({deviceType:s,powerPreference:a}))}else o.currentContext=await o.webnnCreateMLContext();break}s=await o._OrtCreateSession(r,n,a),o.webgpuOnCreateSession?.(s),0===s&&ke("Can't create a session."),o.jsepOnCreateSession?.(),o.currentContext&&(o.webnnRegisterMLContext(s,o.currentContext),o.currentContext=void 0,o.shouldTransferToMLTensor=!0);const[e,p]=_t(s),l=!!t?.enableGraphCapture,f=[],h=[],w=[],m=[],y=[];for(let t=0;t<e;t++){const[e,r,n]=Gt(s,t);0===e&&ke("Can't get an input name."),c.push(e);const a=o.UTF8ToString(e);f.push(a),w.push(0===r?{name:a,isTensor:!1}:{name:a,isTensor:!0,type:He(r),shape:n})}for(let r=0;r<p;r++){const[n,a,i]=Gt(s,r+e);0===n&&ke("Can't get an output name."),d.push(n);const u=o.UTF8ToString(n);h.push(u),m.push(0===a?{name:u,isTensor:!1}:{name:u,isTensor:!0,type:He(a),shape:i});{if(l&&void 0===t?.preferredOutputLocation){y.push("gpu-buffer");continue}const e="string"==typeof t?.preferredOutputLocation?t.preferredOutputLocation:t?.preferredOutputLocation?.[u]??"cpu",r=o.webnnIsGraphOutput;if("cpu"===e&&r&&r(s,u)){y.push("ml-tensor-cpu-output");continue}if("cpu"!==e&&"cpu-pinned"!==e&&"gpu-buffer"!==e&&"ml-tensor"!==e)throw new Error(`Not supported preferred output location: ${e}.`);if(l&&"gpu-buffer"!==e)throw new Error(`Not supported preferred output location: ${e}. Only 'gpu-buffer' location is supported when enableGraphCapture is true.`);y.push(e)}}let g=null;return y.some(e=>"gpu-buffer"===e||"ml-tensor"===e||"ml-tensor-cpu-output"===e)&&(i=o._OrtCreateBinding(s),0===i&&ke("Can't create IO binding."),g={handle:i,outputPreferredLocations:y,outputPreferredLocationsEncoded:y.map(e=>"ml-tensor-cpu-output"===e?"ml-tensor":e).map(e=>Ke(e))}),Pt.set(s,[s,c,d,g,l,!1]),[s,f,h,w,m]}catch(e){throw c.forEach(e=>o._OrtFree(e)),d.forEach(e=>o._OrtFree(e)),0!==i&&0!==o._OrtReleaseBinding(i)&&ke("Can't release IO binding."),0!==s&&0!==o._OrtReleaseSession(s)&&ke("Can't release session."),e}finally{o._free(r),0!==a&&0!==o._OrtReleaseSessionOptions(a)&&ke("Can't release session options."),u.forEach(e=>o._free(e)),o.unmountExternalData?.()}},jt=e=>{const t=Ne(),r=Pt.get(e);if(!r)throw new Error(`cannot release session. invalid session id: ${e}`);const[n,o,s,a,i]=r;a&&(i&&0!==t._OrtClearBoundOutputs(a.handle)&&ke("Can't clear bound outputs."),0!==t._OrtReleaseBinding(a.handle)&&ke("Can't release IO binding.")),t.jsepOnReleaseSession?.(e),t.webnnOnReleaseSession?.(e),t.webgpuOnReleaseSession?.(e),o.forEach(e=>t._OrtFree(e)),s.forEach(e=>t._OrtFree(e)),0!==t._OrtReleaseSession(n)&&ke("Can't release session."),Pt.delete(e)},Ft=async(e,t,r,n,o,s,a=!1)=>{if(!e)return void t.push(0);const i=Ne(),u=i.PTR_SIZE,c=e[0],d=e[1],p=e[3];let l,f,h=p;if("string"===c&&("gpu-buffer"===p||"ml-tensor"===p))throw new Error("String tensor is not supported on GPU.");if(a&&"gpu-buffer"!==p)throw new Error(`External buffer must be provided for input/output index ${s} when enableGraphCapture is true.`);if("gpu-buffer"===p){const t=e[2].gpuBuffer;f=qe(ze(c),d);{const e=i.webgpuRegisterBuffer;if(!e)throw new Error('Tensor location "gpu-buffer" is not supported without using WebGPU.');l=e(t,n)}}else if("ml-tensor"===p){const t=e[2].mlTensor;f=qe(ze(c),d);const r=i.webnnRegisterMLTensor;if(!r)throw new Error('Tensor location "ml-tensor" is not supported without using WebNN.');l=r(n,t,ze(c),d)}else{const t=e[2];if(Array.isArray(t)){f=u*t.length,l=i._malloc(f),r.push(l);for(let e=0;e<t.length;e++){if("string"!=typeof t[e])throw new TypeError(`tensor data at index ${e} is not a string`);i.setValue(l+e*u,Be(t[e],r),"*")}}else{const e=i.webnnIsGraphInput,s=i.webnnIsGraphOutput;if("string"!==c&&e&&s){const a=i.UTF8ToString(o);if(e(n,a)||s(n,a)){const e=ze(c);f=qe(e,d),h="ml-tensor";const r=i.webnnCreateTemporaryTensor,o=i.webnnUploadTensor;if(!r||!o)throw new Error('Tensor location "ml-tensor" is not supported without using WebNN.');const s=await r(n,e,d);o(s,new Uint8Array(t.buffer,t.byteOffset,t.byteLength)),l=s}else f=t.byteLength,l=i._malloc(f),r.push(l),i.HEAPU8.set(new Uint8Array(t.buffer,t.byteOffset,f),l)}else f=t.byteLength,l=i._malloc(f),r.push(l),i.HEAPU8.set(new Uint8Array(t.buffer,t.byteOffset,f),l)}}const w=i.stackSave(),m=i.stackAlloc(4*d.length);try{d.forEach((e,t)=>i.setValue(m+t*u,e,4===u?"i32":"i64"));const e=i._OrtCreateTensor(ze(c),l,f,m,d.length,Ke(h));0===e&&ke(`Can't create tensor for input/output. session=${n}, index=${s}.`),t.push(e)}finally{i.stackRestore(w)}},Vt=async(e,t,r,n,o,s)=>{const a=Ne(),i=a.PTR_SIZE,u=Pt.get(e);if(!u)throw new Error(`cannot run inference. invalid session id: ${e}`);const c=u[0],d=u[1],p=u[2],l=u[3],f=u[4],h=u[5],w=t.length,m=n.length;let y=0,g=[];const b=[],v=[],T=[],E=a.stackSave(),I=a.stackAlloc(w*i),A=a.stackAlloc(w*i),C=a.stackAlloc(m*i),x=a.stackAlloc(m*i);try{[y,g]=Pe(s),L("wasm prepareInputOutputTensor");for(let n=0;n<w;n++)await Ft(r[n],b,T,e,d[t[n]],t[n],f);for(let t=0;t<m;t++)await Ft(o[t],v,T,e,p[n[t]],w+n[t],f);$("wasm prepareInputOutputTensor");for(let e=0;e<w;e++)a.setValue(I+e*i,b[e],"*"),a.setValue(A+e*i,d[t[e]],"*");for(let e=0;e<m;e++)a.setValue(C+e*i,v[e],"*"),a.setValue(x+e*i,p[n[e]],"*");if(l&&!h){const{handle:r,outputPreferredLocations:s,outputPreferredLocationsEncoded:i}=l;if(d.length!==w)throw new Error(`input count from feeds (${w}) is expected to be always equal to model's input count (${d.length}).`);L("wasm bindInputsOutputs");for(let n=0;n<w;n++){const o=t[n];0!==await a._OrtBindInput(r,d[o],b[n])&&ke(`Can't bind input[${n}] for session=${e}.`)}for(let t=0;t<m;t++){const u=n[t],c=o[t]?.[3];c?0!==a._OrtBindOutput(r,p[u],v[t],0)&&ke(`Can't bind pre-allocated output[${t}] for session=${e}.`):0!==a._OrtBindOutput(r,p[u],0,i[u])&&ke(`Can't bind output[${t}] to ${s[t]} for session=${e}.`)}$("wasm bindInputsOutputs"),Pt.set(e,[c,d,p,l,f,!0])}let u;a.jsepOnRunStart?.(c),a.webnnOnRunStart?.(c),u=l?await a._OrtRunWithBinding(c,l.handle,m,C,y):await a._OrtRun(c,A,I,w,x,m,C,y),0!==u&&ke("failed to call OrtRun().");const E=[],O=[];L("wasm ProcessOutputTensor");for(let t=0;t<m;t++){const r=Number(a.getValue(C+t*i,"*"));if(r===v[t]){E.push(o[t]);continue}const s=a.stackSave(),u=a.stackAlloc(4*i);let c,d=!1,p=0;try{0!==a._OrtGetTensorData(r,u,u+i,u+2*i,u+3*i)&&ke(`Can't access output tensor data on index ${t}.`);const o=4===i?"i32":"i64",s=Number(a.getValue(u,o));p=a.getValue(u+i,"*");const f=a.getValue(u+2*i,"*"),h=Number(a.getValue(u+3*i,o)),w=[];for(let e=0;e<h;e++)w.push(Number(a.getValue(f+e*i,o)));0!==a._OrtFree(f)&&ke("Can't free memory for tensor dims.");const m=w.reduce((e,t)=>e*t,1);c=He(s);const y=l?.outputPreferredLocations[n[t]];if("string"===c){if("gpu-buffer"===y||"ml-tensor"===y)throw new Error("String tensor is not supported on GPU.");const e=[];for(let t=0;t<m;t++){const r=a.getValue(p+t*i,"*"),n=a.getValue(p+(t+1)*i,"*"),o=t===m-1?void 0:n-r;e.push(a.UTF8ToString(r,o))}E.push([c,w,e,"cpu"])}else if("gpu-buffer"===y&&m>0){const t=a.webgpuGetBuffer;if(!t)throw new Error('preferredLocation "gpu-buffer" is not supported without using WebGPU.');const n=t(p),o=qe(s,m);if(void 0===o||!Ye(c))throw new Error(`Unsupported data type: ${c}`);d=!0;{a.webgpuRegisterBuffer(n,e,p);const t=a.webgpuCreateDownloader(n,o,e);E.push([c,w,{gpuBuffer:n,download:async()=>{const e=await t();return new(Ze(c))(e)},dispose:()=>{0!==a._OrtReleaseTensor(r)&&ke("Can't release tensor.")}},"gpu-buffer"])}}else if("ml-tensor"===y&&m>0){const t=a.webnnEnsureTensor,n=a.webnnIsGraphInputOutputTypeSupported;if(!t||!n)throw new Error('preferredLocation "ml-tensor" is not supported without using WebNN.');if(void 0===qe(s,m)||!Je(c))throw new Error(`Unsupported data type: ${c}`);if(!n(e,c,!1))throw new Error(`preferredLocation "ml-tensor" for ${c} output is not supported by current WebNN Context.`);const o=await t(e,p,s,w,!1);d=!0,E.push([c,w,{mlTensor:o,download:a.webnnCreateMLTensorDownloader(p,c),dispose:()=>{a.webnnReleaseTensorId(p),a._OrtReleaseTensor(r)}},"ml-tensor"])}else if("ml-tensor-cpu-output"===y&&m>0){const e=a.webnnCreateMLTensorDownloader(p,c)(),t=E.length;d=!0,O.push((async()=>{const n=[t,await e];return a.webnnReleaseTensorId(p),a._OrtReleaseTensor(r),n})()),E.push([c,w,[],"cpu"])}else{const e=new(Ze(c))(m);new Uint8Array(e.buffer,e.byteOffset,e.byteLength).set(a.HEAPU8.subarray(p,p+e.byteLength)),E.push([c,w,e,"cpu"])}}finally{a.stackRestore(s),"string"===c&&p&&a._free(p),d||a._OrtReleaseTensor(r)}}l&&!f&&(0!==a._OrtClearBoundOutputs(l.handle)&&ke("Can't clear bound outputs."),Pt.set(e,[c,d,p,l,f,!1]));for(const[e,t]of await Promise.all(O))E[e][2]=t;return $("wasm ProcessOutputTensor"),E}finally{a.webnnOnRunEnd?.(c),a.stackRestore(E),r.forEach(e=>{e&&"gpu-buffer"===e[3]&&a.webgpuUnregisterBuffer(e[2].gpuBuffer)}),o.forEach(e=>{e&&"gpu-buffer"===e[3]&&a.webgpuUnregisterBuffer(e[2].gpuBuffer)}),b.forEach(e=>a._OrtReleaseTensor(e)),v.forEach(e=>a._OrtReleaseTensor(e)),T.forEach(e=>a._free(e)),0!==y&&a._OrtReleaseRunOptions(y),g.forEach(e=>a._free(e))}},zt=e=>{const t=Ne(),r=Pt.get(e);if(!r)throw new Error("invalid session id");const n=r[0],o=t._OrtEndProfiling(n);0===o&&ke("Can't get an profile file name."),t._OrtFree(o)},Ht=e=>{const t=[];for(const r of e){const e=r[2];!Array.isArray(e)&&"buffer"in e&&t.push(e.buffer)}return t}}}),br=_({"web/lib/wasm/proxy-wrapper.ts"(){de(),gr(),At(),It(),qt=()=>!!u.wasm.proxy&&"undefined"!=typeof document,Xt=!1,Yt=!1,Jt=!1,er=new Map,tr=(e,t)=>{const r=er.get(e);r?r.push(t):er.set(e,[t])},rr=()=>{if(Xt||!Yt||Jt||!Zt)throw new Error("worker not ready")},nr=e=>{switch(e.data.type){case"init-wasm":Xt=!1,e.data.err?(Jt=!0,Qt[1](e.data.err)):(Yt=!0,Qt[0]()),Kt&&(URL.revokeObjectURL(Kt),Kt=void 0);break;case"init-ep":case"copy-from":case"create":case"release":case"run":case"end-profiling":{const t=er.get(e.data.type);e.data.err?t.shift()[1](e.data.err):t.shift()[0](e.data.out);break}}},or=async()=>{if(!Yt){if(Xt)throw new Error("multiple calls to 'initWasm()' detected.");if(Jt)throw new Error("previous call to 'initWasm()' failed.");if(Xt=!0,qt())return new Promise((e,t)=>{Zt?.terminate(),Ee().then(([r,n])=>{try{(Zt=n).onerror=e=>t(e),Zt.onmessage=nr,Qt=[e,t];const o={type:"init-wasm",in:u};if(!o.in.wasm.wasmPaths&&r){const e=we();e&&(o.in.wasm.wasmPaths=e)}Zt.postMessage(o),Kt=r}catch(e){t(e)}},t)});try{await Me(u.wasm),await St(u),Yt=!0}catch(e){throw Jt=!0,e}finally{Xt=!1}}},sr=async e=>{if(qt())return rr(),new Promise((t,r)=>{tr("init-ep",[t,r]);const n={type:"init-ep",in:{epName:e,env:u}};Zt.postMessage(n)});await kt(u,e)},ar=async e=>qt()?(rr(),new Promise((t,r)=>{tr("copy-from",[t,r]);const n={type:"copy-from",in:{buffer:e}};Zt.postMessage(n,[e.buffer])})):Dt(e),ir=async(e,t)=>{if(qt()){if(t?.preferredOutputLocation)throw new Error('session option "preferredOutputLocation" is not supported for proxy.');return rr(),new Promise((r,n)=>{tr("create",[r,n]);const o={type:"create",in:{model:e,options:{...t}}},s=[];e instanceof Uint8Array&&s.push(e.buffer),Zt.postMessage(o,s)})}return Wt(e,t)},ur=async e=>{if(qt())return rr(),new Promise((t,r)=>{tr("release",[t,r]);const n={type:"release",in:e};Zt.postMessage(n)});jt(e)},cr=async(e,t,r,n,o,s)=>{if(qt()){if(r.some(e=>"cpu"!==e[3]))throw new Error("input tensor on GPU is not supported for proxy.");if(o.some(e=>e))throw new Error("pre-allocated output tensor is not supported for proxy.");return rr(),new Promise((o,a)=>{tr("run",[o,a]);const i=r,u={type:"run",in:{sessionId:e,inputIndices:t,inputs:i,outputIndices:n,options:s}};Zt.postMessage(u,Ht(i))})}return Vt(e,t,r,n,o,s)},dr=async e=>{if(qt())return rr(),new Promise((t,r)=>{tr("end-profiling",[t,r]);const n={type:"end-profiling",in:e};Zt.postMessage(n)});zt(e)}}}),vr=_({"web/lib/wasm/session-handler-inference.ts"(){de(),br(),Ut(),pe(),Lt(),pr=(e,t)=>{switch(e.location){case"cpu":return[e.type,e.dims,e.data,"cpu"];case"gpu-buffer":return[e.type,e.dims,{gpuBuffer:e.gpuBuffer},"gpu-buffer"];case"ml-tensor":return[e.type,e.dims,{mlTensor:e.mlTensor},"ml-tensor"];default:throw new Error(`invalid data location: ${e.location} for ${t()}`)}},lr=e=>{switch(e[3]){case"cpu":return new A(e[0],e[2],e[1]);case"gpu-buffer":{const t=e[0];if(!Ye(t))throw new Error(`not supported data type: ${t} for deserializing GPU tensor`);const{gpuBuffer:r,download:n,dispose:o}=e[2];return A.fromGpuBuffer(r,{dataType:t,dims:e[1],download:n,dispose:o})}case"ml-tensor":{const t=e[0];if(!Je(t))throw new Error(`not supported data type: ${t} for deserializing MLTensor tensor`);const{mlTensor:r,download:n,dispose:o}=e[2];return A.fromMLTensor(r,{dataType:t,dims:e[1],download:n,dispose:o})}default:throw new Error(`invalid data location: ${e[3]}`)}},fr=class{async fetchModelAndCopyToWasmMemory(e){return ar(await Qe(e))}async loadModel(e,t){let r;O(),r="string"==typeof e?ae?await Qe(e):await this.fetchModelAndCopyToWasmMemory(e):e,[this.sessionId,this.inputNames,this.outputNames,this.inputMetadata,this.outputMetadata]=await ir(r,t),U()}async dispose(){return ur(this.sessionId)}async run(e,t,r){O();const n=[],o=[];Object.entries(e).forEach(e=>{const t=e[0],r=e[1],s=this.inputNames.indexOf(t);if(-1===s)throw new Error(`invalid input '${t}'`);n.push(r),o.push(s)});const s=[],a=[];Object.entries(t).forEach(e=>{const t=e[0],r=e[1],n=this.outputNames.indexOf(t);if(-1===n)throw new Error(`invalid output '${t}'`);s.push(r),a.push(n)});const i=n.map((e,t)=>pr(e,()=>`input "${this.inputNames[o[t]]}"`)),u=s.map((e,t)=>e?pr(e,()=>`output "${this.outputNames[a[t]]}"`):null),c=await cr(this.sessionId,o,i,a,u,r),d={};for(let e=0;e<c.length;e++)d[this.outputNames[a[e]]]=s[e]??lr(c[e]);return U(),d}startProfiling(){}endProfiling(){dr(this.sessionId)}}}}),Tr={};G(Tr,{OnnxruntimeWebAssemblyBackend:()=>wr,initializeFlags:()=>hr,wasmBackend:()=>mr});var Er=_({"web/lib/backend-wasm.ts"(){de(),br(),vr(),hr=()=>{("number"!=typeof u.wasm.initTimeout||u.wasm.initTimeout<0)&&(u.wasm.initTimeout=0);const e=u.wasm.simd;if("boolean"!=typeof e&&void 0!==e&&"fixed"!==e&&"relaxed"!==e&&(console.warn(`Property "env.wasm.simd" is set to unknown value "${e}". Reset it to \`false\` and ignore SIMD feature checking.`),u.wasm.simd=!1),"boolean"!=typeof u.wasm.proxy&&(u.wasm.proxy=!1),"boolean"!=typeof u.wasm.trace&&(u.wasm.trace=!1),"number"!=typeof u.wasm.numThreads||!Number.isInteger(u.wasm.numThreads)||u.wasm.numThreads<=0)if("undefined"==typeof self||self.crossOriginIsolated){const e="undefined"==typeof navigator?P("node:os").cpus().length:navigator.hardwareConcurrency;u.wasm.numThreads=Math.min(4,Math.ceil((e||1)/2))}else u.wasm.numThreads=1},mr=new(wr=class{async init(e){hr(),await or(),await sr(e)}async createInferenceSessionHandler(e,t){const r=new fr;return await r.loadModel(e,t),r}})}}),Ir={};G(Ir,{InferenceSession:()=>M,TRACE:()=>C,TRACE_EVENT_BEGIN:()=>L,TRACE_EVENT_END:()=>$,TRACE_FUNC_BEGIN:()=>O,TRACE_FUNC_END:()=>U,Tensor:()=>A,default:()=>Ar,env:()=>u,registerBackend:()=>r}),de(),de(),de();var Ar=se;{const e=(Er(),D(Tr)).wasmBackend;r("webgpu",e,5),r("webnn",e,5),r("cpu",e,10),r("wasm",e,10)}return Object.defineProperty(u.versions,"web",{value:"1.23.0",enumerable:!0}),D(Ir)})();"object"==typeof exports&&"object"==typeof module&&(module.exports=ort);