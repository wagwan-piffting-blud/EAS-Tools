/*! For license information please see ort.mjs.LICENSE.txt */
var e,t,n,i,r,s,a,o,u,d,l,p,c,h,f,m,g,_,w,y,$,b,v,x,k,S,I,T,z,E,C,O,A,B=Object.defineProperty,R=Object.getOwnPropertyDescriptor,D=Object.getOwnPropertyNames,M=Object.prototype.hasOwnProperty,U=(e=>"undefined"!=typeof require?require:"undefined"!=typeof Proxy?new Proxy(e,{get:(e,t)=>("undefined"!=typeof require?require:e)[t]}):e)(function(e){if("undefined"!=typeof require)return require.apply(this,arguments);throw Error('Dynamic require of "'+e+'" is not supported')}),P=(e,t)=>function(){return e&&(t=(0,e[D(e)[0]])(e=0)),t},q=(e,t)=>{for(var n in t)B(e,n,{get:t[n],enumerable:!0})},N=e=>((e,t,n,i)=>{if(t&&"object"==typeof t||"function"==typeof t)for(let n of D(t))M.call(e,n)||undefined===n||B(e,n,{get:()=>t[n],enumerable:!(i=R(t,n))||i.enumerable});return e})(B({},"__esModule",{value:!0}),e),V=P({"common/dist/esm/backend-impl.js"(){e=new Map,t=[],n=(n,i,r)=>{if(i&&"function"==typeof i.init&&"function"==typeof i.createInferenceSessionHandler){const s=e.get(n);if(void 0===s)e.set(n,{backend:i,priority:r});else{if(s.priority>r)return;if(s.priority===r&&s.backend!==i)throw new Error(`cannot register backend "${n}" using priority ${r}`)}if(r>=0){const i=t.indexOf(n);-1!==i&&t.splice(i,1);for(let i=0;i<t.length;i++)if(e.get(t[i]).priority<=r)return void t.splice(i,0,n);t.push(n)}return}throw new TypeError("not a valid backend")},i=async t=>{const n=e.get(t);if(!n)return"backend not found.";if(n.initialized)return n.backend;if(n.aborted)return n.error;{const e=!!n.initPromise;try{return e||(n.initPromise=n.backend.init(t)),await n.initPromise,n.initialized=!0,n.backend}catch(t){return e||(n.error=`${t}`,n.aborted=!0),n.error}finally{delete n.initPromise}}},r=async e=>{const n=e.executionProviders||[],r=n.map(e=>"string"==typeof e?e:e.name),s=0===r.length?t:r;let a;const o=[],u=new Set;for(const e of s){const t=await i(e);"string"==typeof t?o.push({name:e,err:t}):(a||(a=t),a===t&&u.add(e))}if(!a)throw new Error(`no available backend found. ERR: ${o.map(e=>`[${e.name}] ${e.err}`).join(", ")}`);for(const{name:e,err:t}of o)r.includes(e)&&console.warn(`removing requested execution provider "${e}" from session options because it is not available: ${t}`);const d=n.filter(e=>u.has("string"==typeof e?e:e.name));return[a,new Proxy(e,{get:(e,t)=>"executionProviders"===t?d:Reflect.get(e,t)})]}}}),L=P({"common/dist/esm/backend.js"(){V()}}),G=P({"common/dist/esm/version.js"(){s="1.23.0"}}),W=P({"common/dist/esm/env-impl.js"(){G(),a="warning",o={wasm:{},webgl:{},webgpu:{},versions:{common:s},set logLevel(e){if(void 0!==e){if("string"!=typeof e||-1===["verbose","info","warning","error","fatal"].indexOf(e))throw new Error(`Unsupported logging level: ${e}`);a=e}},get logLevel(){return a}},Object.defineProperty(o,"logLevel",{enumerable:!0})}}),j=P({"common/dist/esm/env.js"(){W(),u=o}}),H=P({"common/dist/esm/tensor-conversion-impl.js"(){d=(e,t)=>{const n="undefined"!=typeof document?document.createElement("canvas"):new OffscreenCanvas(1,1);n.width=e.dims[3],n.height=e.dims[2];const i=n.getContext("2d");if(null!=i){let r,s;void 0!==t?.tensorLayout&&"NHWC"===t.tensorLayout?(r=e.dims[2],s=e.dims[3]):(r=e.dims[3],s=e.dims[2]);const a=void 0!==t?.format?t.format:"RGB",o=t?.norm;let u,d;void 0===o||void 0===o.mean?u=[255,255,255,255]:"number"==typeof o.mean?u=[o.mean,o.mean,o.mean,o.mean]:(u=[o.mean[0],o.mean[1],o.mean[2],0],void 0!==o.mean[3]&&(u[3]=o.mean[3])),void 0===o||void 0===o.bias?d=[0,0,0,0]:"number"==typeof o.bias?d=[o.bias,o.bias,o.bias,o.bias]:(d=[o.bias[0],o.bias[1],o.bias[2],0],void 0!==o.bias[3]&&(d[3]=o.bias[3]));const l=s*r;let p=0,c=l,h=2*l,f=-1;"RGBA"===a?(p=0,c=l,h=2*l,f=3*l):"RGB"===a?(p=0,c=l,h=2*l):"RBG"===a&&(p=0,h=l,c=2*l);for(let t=0;t<s;t++)for(let n=0;n<r;n++){const r=(e.data[p++]-d[0])*u[0],s=(e.data[c++]-d[1])*u[1],a=(e.data[h++]-d[2])*u[2],o=-1===f?255:(e.data[f++]-d[3])*u[3];i.fillStyle="rgba("+r+","+s+","+a+","+o+")",i.fillRect(n,t,1,1)}if("toDataURL"in n)return n.toDataURL();throw new Error("toDataURL is not supported")}throw new Error("Can not access image data")},l=(e,t)=>{const n="undefined"!=typeof document?document.createElement("canvas").getContext("2d"):new OffscreenCanvas(1,1).getContext("2d");let i;if(null==n)throw new Error("Can not access image data");{let r,s,a;void 0!==t?.tensorLayout&&"NHWC"===t.tensorLayout?(r=e.dims[2],s=e.dims[1],a=e.dims[3]):(r=e.dims[3],s=e.dims[2],a=e.dims[1]);const o=void 0!==t&&void 0!==t.format?t.format:"RGB",u=t?.norm;let d,l;void 0===u||void 0===u.mean?d=[255,255,255,255]:"number"==typeof u.mean?d=[u.mean,u.mean,u.mean,u.mean]:(d=[u.mean[0],u.mean[1],u.mean[2],255],void 0!==u.mean[3]&&(d[3]=u.mean[3])),void 0===u||void 0===u.bias?l=[0,0,0,0]:"number"==typeof u.bias?l=[u.bias,u.bias,u.bias,u.bias]:(l=[u.bias[0],u.bias[1],u.bias[2],0],void 0!==u.bias[3]&&(l[3]=u.bias[3]));const p=s*r;if(void 0!==t&&(void 0!==t.format&&4===a&&"RGBA"!==t.format||3===a&&"RGB"!==t.format&&"BGR"!==t.format))throw new Error("Tensor format doesn't match input tensor dims");const c=4;let h=0,f=1,m=2,g=3,_=0,w=p,y=2*p,$=-1;"RGBA"===o?(_=0,w=p,y=2*p,$=3*p):"RGB"===o?(_=0,w=p,y=2*p):"RBG"===o&&(_=0,y=p,w=2*p),i=n.createImageData(r,s);for(let t=0;t<s*r;h+=c,f+=c,m+=c,g+=c,t++)i.data[h]=(e.data[_++]-l[0])*d[0],i.data[f]=(e.data[w++]-l[1])*d[1],i.data[m]=(e.data[y++]-l[2])*d[2],i.data[g]=-1===$?255:(e.data[$++]-l[3])*d[3]}return i}}}),F=P({"common/dist/esm/tensor-factory-impl.js"(){Q(),p=(e,t)=>{if(void 0===e)throw new Error("Image buffer must be defined");if(void 0===t.height||void 0===t.width)throw new Error("Image height and width must be defined");if("NHWC"===t.tensorLayout)throw new Error("NHWC Tensor layout is not supported yet");const{height:n,width:i}=t,r=t.norm??{mean:255,bias:0};let s,a;s="number"==typeof r.mean?[r.mean,r.mean,r.mean,r.mean]:[r.mean[0],r.mean[1],r.mean[2],r.mean[3]??255],a="number"==typeof r.bias?[r.bias,r.bias,r.bias,r.bias]:[r.bias[0],r.bias[1],r.bias[2],r.bias[3]??0];const o=void 0!==t.format?t.format:"RGBA",u=void 0!==t.tensorFormat&&void 0!==t.tensorFormat?t.tensorFormat:"RGB",d=n*i,l="RGBA"===u?new Float32Array(4*d):new Float32Array(3*d);let p=4,c=0,h=1,f=2,m=3,g=0,_=d,w=2*d,y=-1;"RGB"===o&&(p=3,c=0,h=1,f=2,m=-1),"RGBA"===u?y=3*d:"RBG"===u?(g=0,w=d,_=2*d):"BGR"===u&&(w=0,_=d,g=2*d);for(let t=0;t<d;t++,c+=p,f+=p,h+=p,m+=p)l[g++]=(e[c]+a[0])/s[0],l[_++]=(e[h]+a[1])/s[1],l[w++]=(e[f]+a[2])/s[2],-1!==y&&-1!==m&&(l[y++]=(e[m]+a[3])/s[3]);return new x("float32",l,"RGBA"===u?[1,4,n,i]:[1,3,n,i])},c=async(e,t)=>{const n="undefined"!=typeof HTMLImageElement&&e instanceof HTMLImageElement,i="undefined"!=typeof ImageData&&e instanceof ImageData,r="undefined"!=typeof ImageBitmap&&e instanceof ImageBitmap,s="string"==typeof e;let a,o=t??{};const u=()=>{if("undefined"!=typeof document)return document.createElement("canvas");if("undefined"!=typeof OffscreenCanvas)return new OffscreenCanvas(1,1);throw new Error("Canvas is not supported")},d=e=>"undefined"!=typeof HTMLCanvasElement&&e instanceof HTMLCanvasElement||e instanceof OffscreenCanvas?e.getContext("2d"):null;if(n){const n=u();n.width=e.width,n.height=e.height;const i=d(n);if(null==i)throw new Error("Can not access image data");{let n=e.height,r=e.width;if(void 0!==t&&void 0!==t.resizedHeight&&void 0!==t.resizedWidth&&(n=t.resizedHeight,r=t.resizedWidth),void 0!==t){if(o=t,void 0!==t.tensorFormat)throw new Error("Image input config format must be RGBA for HTMLImageElement");o.tensorFormat="RGBA",o.height=n,o.width=r}else o.tensorFormat="RGBA",o.height=n,o.width=r;i.drawImage(e,0,0),a=i.getImageData(0,0,r,n).data}}else{if(!i){if(r){if(void 0===t)throw new Error("Please provide image config with format for Imagebitmap");const n=u();n.width=e.width,n.height=e.height;const i=d(n);if(null!=i){const t=e.height,n=e.width;return i.drawImage(e,0,0,n,t),a=i.getImageData(0,0,n,t).data,o.height=t,o.width=n,p(a,o)}throw new Error("Can not access image data")}if(s)return new Promise((t,n)=>{const i=u(),r=d(i);if(!e||!r)return n();const s=new Image;s.crossOrigin="Anonymous",s.src=e,s.onload=()=>{i.width=s.width,i.height=s.height,r.drawImage(s,0,0,i.width,i.height);const e=r.getImageData(0,0,i.width,i.height);o.height=i.height,o.width=i.width,t(p(e.data,o))}});throw new Error("Input data provided is not supported - aborted tensor creation")}{let n,i;if(void 0!==t&&void 0!==t.resizedWidth&&void 0!==t.resizedHeight?(n=t.resizedHeight,i=t.resizedWidth):(n=e.height,i=e.width),void 0!==t&&(o=t),o.format="RGBA",o.height=n,o.width=i,void 0!==t){const t=u();t.width=i,t.height=n;const r=d(t);if(null==r)throw new Error("Can not access image data");r.putImageData(e,0,0),a=r.getImageData(0,0,i,n).data}else a=e.data}}if(void 0!==a)return p(a,o);throw new Error("Input data provided is not supported - aborted tensor creation")},h=(e,t)=>{const{width:n,height:i,download:r,dispose:s}=t;return new x({location:"texture",type:"float32",texture:e,dims:[1,i,n,4],download:r,dispose:s})},f=(e,t)=>{const{dataType:n,dims:i,download:r,dispose:s}=t;return new x({location:"gpu-buffer",type:n??"float32",gpuBuffer:e,dims:i,download:r,dispose:s})},m=(e,t)=>{const{dataType:n,dims:i,download:r,dispose:s}=t;return new x({location:"ml-tensor",type:n??"float32",mlTensor:e,dims:i,download:r,dispose:s})},g=(e,t,n)=>new x({location:"cpu-pinned",type:e,data:t,dims:n??[t.length]})}}),K=P({"common/dist/esm/tensor-impl-type-mapping.js"(){_=new Map([["float32",Float32Array],["uint8",Uint8Array],["int8",Int8Array],["uint16",Uint16Array],["int16",Int16Array],["int32",Int32Array],["bool",Uint8Array],["float64",Float64Array],["uint32",Uint32Array],["int4",Uint8Array],["uint4",Uint8Array]]),w=new Map([[Float32Array,"float32"],[Uint8Array,"uint8"],[Int8Array,"int8"],[Uint16Array,"uint16"],[Int16Array,"int16"],[Int32Array,"int32"],[Float64Array,"float64"],[Uint32Array,"uint32"]]),y=!1,$=()=>{if(!y){y=!0;const e="undefined"!=typeof BigInt64Array&&BigInt64Array.from,t="undefined"!=typeof BigUint64Array&&BigUint64Array.from,n=globalThis.Float16Array,i=void 0!==n&&n.from;e&&(_.set("int64",BigInt64Array),w.set(BigInt64Array,"int64")),t&&(_.set("uint64",BigUint64Array),w.set(BigUint64Array,"uint64")),i?(_.set("float16",n),w.set(n,"float16")):_.set("float16",Uint16Array)}}}}),Z=P({"common/dist/esm/tensor-utils-impl.js"(){Q(),b=e=>{let t=1;for(let n=0;n<e.length;n++){const i=e[n];if("number"!=typeof i||!Number.isSafeInteger(i))throw new TypeError(`dims[${n}] must be an integer, got: ${i}`);if(i<0)throw new RangeError(`dims[${n}] must be a non-negative integer, got: ${i}`);t*=i}return t},v=(e,t)=>{switch(e.location){case"cpu":return new x(e.type,e.data,t);case"cpu-pinned":return new x({location:"cpu-pinned",data:e.data,type:e.type,dims:t});case"texture":return new x({location:"texture",texture:e.texture,type:e.type,dims:t});case"gpu-buffer":return new x({location:"gpu-buffer",gpuBuffer:e.gpuBuffer,type:e.type,dims:t});case"ml-tensor":return new x({location:"ml-tensor",mlTensor:e.mlTensor,type:e.type,dims:t});default:throw new Error(`tensorReshape: tensor location ${e.location} is not supported`)}}}}),Q=P({"common/dist/esm/tensor-impl.js"(){H(),F(),K(),Z(),x=class{constructor(e,t,n){let i,r;if($(),"object"==typeof e&&"location"in e)switch(this.dataLocation=e.location,i=e.type,r=e.dims,e.location){case"cpu-pinned":{const t=_.get(i);if(!t)throw new TypeError(`unsupported type "${i}" to create tensor from pinned buffer`);if(!(e.data instanceof t))throw new TypeError(`buffer should be of type ${t.name}`);this.cpuData=e.data;break}case"texture":if("float32"!==i)throw new TypeError(`unsupported type "${i}" to create tensor from texture`);this.gpuTextureData=e.texture,this.downloader=e.download,this.disposer=e.dispose;break;case"gpu-buffer":if("float32"!==i&&"float16"!==i&&"int32"!==i&&"int64"!==i&&"uint32"!==i&&"uint8"!==i&&"bool"!==i&&"uint4"!==i&&"int4"!==i)throw new TypeError(`unsupported type "${i}" to create tensor from gpu buffer`);this.gpuBufferData=e.gpuBuffer,this.downloader=e.download,this.disposer=e.dispose;break;case"ml-tensor":if("float32"!==i&&"float16"!==i&&"int32"!==i&&"int64"!==i&&"uint32"!==i&&"uint64"!==i&&"int8"!==i&&"uint8"!==i&&"bool"!==i&&"uint4"!==i&&"int4"!==i)throw new TypeError(`unsupported type "${i}" to create tensor from MLTensor`);this.mlTensorData=e.mlTensor,this.downloader=e.download,this.disposer=e.dispose;break;default:throw new Error(`Tensor constructor: unsupported location '${this.dataLocation}'`)}else{let s,a;if("string"==typeof e)if(i=e,a=n,"string"===e){if(!Array.isArray(t))throw new TypeError("A string tensor's data must be a string array.");s=t}else{const n=_.get(e);if(void 0===n)throw new TypeError(`Unsupported tensor type: ${e}.`);if(Array.isArray(t)){if("float16"===e&&n===Uint16Array||"uint4"===e||"int4"===e)throw new TypeError(`Creating a ${e} tensor from number array is not supported. Please use ${n.name} as data.`);s="uint64"===e||"int64"===e?n.from(t,BigInt):n.from(t)}else if(t instanceof n)s=t;else if(t instanceof Uint8ClampedArray){if("uint8"!==e)throw new TypeError("A Uint8ClampedArray tensor's data must be type of uint8");s=Uint8Array.from(t)}else{if(!("float16"===e&&t instanceof Uint16Array&&n!==Uint16Array))throw new TypeError(`A ${i} tensor's data must be type of ${n}`);s=new globalThis.Float16Array(t.buffer,t.byteOffset,t.length)}}else if(a=t,Array.isArray(e)){if(0===e.length)throw new TypeError("Tensor type cannot be inferred from an empty array.");const t=typeof e[0];if("string"===t)i="string",s=e;else{if("boolean"!==t)throw new TypeError(`Invalid element type of data array: ${t}.`);i="bool",s=Uint8Array.from(e)}}else if(e instanceof Uint8ClampedArray)i="uint8",s=Uint8Array.from(e);else{const t=w.get(e.constructor);if(void 0===t)throw new TypeError(`Unsupported type for tensor data: ${e.constructor}.`);i=t,s=e}if(void 0===a)a=[s.length];else if(!Array.isArray(a))throw new TypeError("A tensor's dims must be a number array");r=a,this.cpuData=s,this.dataLocation="cpu"}const s=b(r);if(this.cpuData&&s!==this.cpuData.length&&("uint4"!==i&&"int4"!==i||Math.ceil(s/2)!==this.cpuData.length))throw new Error(`Tensor's size(${s}) does not match data length(${this.cpuData.length}).`);this.type=i,this.dims=r,this.size=s}static async fromImage(e,t){return c(e,t)}static fromTexture(e,t){return h(e,t)}static fromGpuBuffer(e,t){return f(e,t)}static fromMLTensor(e,t){return m(e,t)}static fromPinnedBuffer(e,t,n){return g(e,t,n)}toDataURL(e){return d(this,e)}toImageData(e){return l(this,e)}get data(){if(this.ensureValid(),!this.cpuData)throw new Error("The data is not on CPU. Use `getData()` to download GPU data to CPU, or use `texture` or `gpuBuffer` property to access the GPU data directly.");return this.cpuData}get location(){return this.dataLocation}get texture(){if(this.ensureValid(),!this.gpuTextureData)throw new Error("The data is not stored as a WebGL texture.");return this.gpuTextureData}get gpuBuffer(){if(this.ensureValid(),!this.gpuBufferData)throw new Error("The data is not stored as a WebGPU buffer.");return this.gpuBufferData}get mlTensor(){if(this.ensureValid(),!this.mlTensorData)throw new Error("The data is not stored as a WebNN MLTensor.");return this.mlTensorData}async getData(e){switch(this.ensureValid(),this.dataLocation){case"cpu":case"cpu-pinned":return this.data;case"texture":case"gpu-buffer":case"ml-tensor":if(!this.downloader)throw new Error("The current tensor is not created with a specified data downloader.");if(this.isDownloading)throw new Error("The current tensor is being downloaded.");try{this.isDownloading=!0;const t=await this.downloader();return this.downloader=void 0,this.dataLocation="cpu",this.cpuData=t,e&&this.disposer&&(this.disposer(),this.disposer=void 0),t}finally{this.isDownloading=!1}default:throw new Error(`cannot get data from location: ${this.dataLocation}`)}}dispose(){if(this.isDownloading)throw new Error("The current tensor is being downloaded.");this.disposer&&(this.disposer(),this.disposer=void 0),this.cpuData=void 0,this.gpuTextureData=void 0,this.gpuBufferData=void 0,this.mlTensorData=void 0,this.downloader=void 0,this.isDownloading=void 0,this.dataLocation="none"}ensureValid(){if("none"===this.dataLocation)throw new Error("The tensor is disposed.")}reshape(e){if(this.ensureValid(),this.downloader||this.disposer)throw new Error("Cannot reshape a tensor that owns GPU resource.");return v(this,e)}}}}),X=P({"common/dist/esm/tensor.js"(){Q(),k=x}}),Y=P({"common/dist/esm/trace.js"(){W(),S=(e,t)=>{(void 0===o.trace?o.wasm.trace:o.trace)&&console.timeStamp(`${e}::ORT::${t}`)},I=(e,t)=>{const n=(new Error).stack?.split(/\r\n|\r|\n/g)||[];let i=!1;for(let r=0;r<n.length;r++){if(i&&!n[r].includes("TRACE_FUNC")){let i=`FUNC_${e}::${n[r].trim().split(" ")[1]}`;return t&&(i+=`::${t}`),void S("CPU",i)}n[r].includes("TRACE_FUNC")&&(i=!0)}},T=e=>{(void 0===o.trace?o.wasm.trace:o.trace)&&I("BEGIN",e)},z=e=>{(void 0===o.trace?o.wasm.trace:o.trace)&&I("END",e)},E=e=>{(void 0===o.trace?o.wasm.trace:o.trace)&&console.time(`ORT::${e}`)},C=e=>{(void 0===o.trace?o.wasm.trace:o.trace)&&console.timeEnd(`ORT::${e}`)}}}),J=P({"common/dist/esm/inference-session-impl.js"(){V(),X(),Y(),O=class e{constructor(e){this.handler=e}async run(e,t,n){T(),E("InferenceSession.run");const i={};let r={};if("object"!=typeof e||null===e||e instanceof k||Array.isArray(e))throw new TypeError("'feeds' must be an object that use input names as keys and OnnxValue as corresponding values.");let s=!0;if("object"==typeof t){if(null===t)throw new TypeError("Unexpected argument[1]: cannot be null.");if(t instanceof k)throw new TypeError("'fetches' cannot be a Tensor");if(Array.isArray(t)){if(0===t.length)throw new TypeError("'fetches' cannot be an empty array.");s=!1;for(const e of t){if("string"!=typeof e)throw new TypeError("'fetches' must be a string array or an object.");if(-1===this.outputNames.indexOf(e))throw new RangeError(`'fetches' contains invalid output name: ${e}.`);i[e]=null}if("object"==typeof n&&null!==n)r=n;else if(void 0!==n)throw new TypeError("'options' must be an object.")}else{let e=!1;const a=Object.getOwnPropertyNames(t);for(const n of this.outputNames)if(-1!==a.indexOf(n)){const r=t[n];(null===r||r instanceof k)&&(e=!0,s=!1,i[n]=r)}if(e){if("object"==typeof n&&null!==n)r=n;else if(void 0!==n)throw new TypeError("'options' must be an object.")}else r=t}}else if(void 0!==t)throw new TypeError("Unexpected argument[1]: must be 'fetches' or 'options'.");for(const t of this.inputNames)if(void 0===e[t])throw new Error(`input '${t}' is missing in 'feeds'.`);if(s)for(const e of this.outputNames)i[e]=null;const a=await this.handler.run(e,i,r),o={};for(const e in a)if(Object.hasOwnProperty.call(a,e)){const t=a[e];o[e]=t instanceof k?t:new k(t.type,t.data,t.dims)}return C("InferenceSession.run"),z(),o}async release(){return this.handler.dispose()}static async create(t,n,i,s){let a;T(),E("InferenceSession.create");let o={};if("string"==typeof t){if(a=t,"object"==typeof n&&null!==n)o=n;else if(void 0!==n)throw new TypeError("'options' must be an object.")}else if(t instanceof Uint8Array){if(a=t,"object"==typeof n&&null!==n)o=n;else if(void 0!==n)throw new TypeError("'options' must be an object.")}else{if(!(t instanceof ArrayBuffer||"undefined"!=typeof SharedArrayBuffer&&t instanceof SharedArrayBuffer))throw new TypeError("Unexpected argument[0]: must be 'path' or 'buffer'.");{const e=t;let r=0,u=t.byteLength;if("object"==typeof n&&null!==n)o=n;else if("number"==typeof n){if(r=n,!Number.isSafeInteger(r))throw new RangeError("'byteOffset' must be an integer.");if(r<0||r>=e.byteLength)throw new RangeError(`'byteOffset' is out of range [0, ${e.byteLength}).`);if(u=t.byteLength-r,"number"==typeof i){if(u=i,!Number.isSafeInteger(u))throw new RangeError("'byteLength' must be an integer.");if(u<=0||r+u>e.byteLength)throw new RangeError(`'byteLength' is out of range (0, ${e.byteLength-r}].`);if("object"==typeof s&&null!==s)o=s;else if(void 0!==s)throw new TypeError("'options' must be an object.")}else if(void 0!==i)throw new TypeError("'byteLength' must be a number.")}else if(void 0!==n)throw new TypeError("'options' must be an object.");a=new Uint8Array(e,r,u)}}const[u,d]=await r(o),l=await u.createInferenceSessionHandler(a,d);return C("InferenceSession.create"),z(),new e(l)}startProfiling(){this.handler.startProfiling()}endProfiling(){this.handler.endProfiling()}get inputNames(){return this.handler.inputNames}get outputNames(){return this.handler.outputNames}get inputMetadata(){return this.handler.inputMetadata}get outputMetadata(){return this.handler.outputMetadata}}}}),ee=P({"common/dist/esm/inference-session.js"(){J(),A=O}}),te=P({"common/dist/esm/tensor-conversion.js"(){}}),ne=P({"common/dist/esm/tensor-factory.js"(){}}),ie=P({"common/dist/esm/onnx-model.js"(){}}),re=P({"common/dist/esm/onnx-value.js"(){}}),se={};q(se,{InferenceSession:()=>A,TRACE:()=>S,TRACE_EVENT_BEGIN:()=>E,TRACE_EVENT_END:()=>C,TRACE_FUNC_BEGIN:()=>T,TRACE_FUNC_END:()=>z,Tensor:()=>k,env:()=>u,registerBackend:()=>n});var ae,oe,ue,de,le=P({"common/dist/esm/index.js"(){L(),j(),ee(),X(),te(),ne(),Y(),ie(),re()}}),pe=P({"web/lib/wasm/wasm-utils-env.ts"(){ae=!1}}),ce={};q(ce,{default:()=>de});var he,fe,me,ge,_e,we,ye,$e,be,ve,xe,ke,Se,Ie,Te,ze,Ee,Ce,Oe,Ae,Be,Re,De,Me,Ue,Pe,qe,Ne,Ve,Le,Ge,We,je,He,Fe,Ke,Ze,Qe,Xe,Ye,Je,et,tt,nt,it,rt,st,at,ot,ut,dt,lt,pt,ct,ht,ft,mt,gt,_t,wt,yt,$t,bt,vt,xt,kt,St,It,Tt,zt,Et,Ct,Ot,At,Bt,Rt,Dt,Mt,Ut,Pt,qt,Nt,Vt,Lt,Gt,Wt,jt,Ht,Ft,Kt,Zt,Qt,Xt,Yt,Jt,en,tn,nn,rn,sn,an,on,un,dn,ln,pn,cn,hn,fn,mn,gn,_n,wn,yn,$n,bn,vn,xn,kn,Sn,In,Tn,zn,En,Cn,On,An,Bn,Rn,Dn,Mn,Un,Pn,qn,Nn,Vn,Ln,Gn,Wn,jn,Hn,Fn,Kn,Zn,Qn,Xn,Yn,Jn,ei,ti,ni,ii,ri,si,ai,oi,ui,di,li,pi,ci,hi,fi,mi,gi,_i,wi,yi,$i,bi,vi,xi,ki,Si,Ii,Ti,zi,Ei,Ci,Oi,Ai,Bi,Ri,Di,Mi,Ui,Pi,qi,Ni,Vi,Li,Gi,Wi,ji,Hi,Fi,Ki,Zi,Qi,Xi,Yi,Ji,er,tr,nr,ir,rr,sr,ar,or,ur,dr,lr,pr,cr,hr,fr,mr,gr,_r,wr,yr,$r,br,vr,xr,kr,Sr,Ir,Tr,zr,Er,Cr,Or,Ar,Br,Rr,Dr,Mr,Ur,Pr,qr,Nr,Vr,Lr,Gr,Wr,jr,Hr,Fr,Kr,Zr,Qr,Xr,Yr,Jr,es,ts,ns,is,rs,ss,as,os,us,ds,ls,ps,cs,hs,fs,ms,gs,_s,ws,ys,$s,bs,vs,xs,ks,Ss,Is,Ts,zs,Es,Cs,Os,As,Bs,Rs,Ds,Ms,Us,Ps,qs,Ns,Vs,Ls,Gs,Ws,js,Hs,Fs,Ks,Zs,Qs,Xs,Ys,Js,ea,ta,na,ia,ra,sa,aa,oa,ua,da,la,pa,ca,ha,fa,ma,ga,_a,wa,ya,$a,ba,va,xa,ka,Sa,Ia,Ta,za,Ea,Ca,Oa,Aa,Ba,Ra,Da,Ma,Ua,Pa,qa,Na,Va,La,Ga,Wa,ja,Ha,Fa,Ka,Za,Qa,Xa,Ya,Ja,eo,to,no,io,ro,so,ao,oo,uo,lo,po,co,ho,fo,mo,go,_o,wo,yo,$o,bo,vo,xo,ko,So,Io,To,zo,Eo,Co,Oo,Ao,Bo,Ro,Do,Mo,Uo,Po,qo,No,Vo,Lo,Go,Wo,jo,Ho,Fo,Ko,Zo,Qo,Xo,Yo,Jo,eu,tu,nu,iu,ru,su,au,ou,uu,du,lu,pu,cu,hu,fu,mu,gu,_u,wu,yu,$u,bu,vu,xu,ku,Su,Iu,Tu,zu,Eu,Cu,Ou,Au,Bu,Ru,Du,Mu,Uu,Pu,qu,Nu,Vu,Lu,Gu,Wu,ju,Hu,Fu,Ku,Zu,Qu,Xu,Yu=P({"web/lib/wasm/proxy-worker/main.ts"(){sp(),ed(),Ju(),oe="ort-wasm-proxy-worker",(ue=globalThis.self?.name===oe)&&(self.onmessage=e=>{const{type:t,in:n}=e.data;try{switch(t){case"init-wasm":Be(n.wasm).then(()=>{vl(n).then(()=>{postMessage({type:t})},e=>{postMessage({type:t,err:e})})},e=>{postMessage({type:t,err:e})});break;case"init-ep":{const{epName:e,env:i}=n;xl(i,e).then(()=>{postMessage({type:t})},e=>{postMessage({type:t,err:e})});break}case"copy-from":{const{buffer:e}=n,i=Tl(e);postMessage({type:t,out:i});break}case"create":{const{model:e,options:i}=n;zl(e,i).then(e=>{postMessage({type:t,out:e})},e=>{postMessage({type:t,err:e})});break}case"release":El(n),postMessage({type:t});break;case"run":{const{sessionId:e,inputIndices:i,inputs:r,outputIndices:s,options:a}=n;Ol(e,i,r,s,new Array(s.length).fill(null),a).then(e=>{e.some(e=>"cpu"!==e[3])?postMessage({type:t,err:"Proxy does not support non-cpu tensor location."}):postMessage({type:t,out:e},Bl([...r,...e]))},e=>{postMessage({type:t,err:e})});break}case"end-profiling":Al(n),postMessage({type:t})}}catch(e){postMessage({type:t,err:e})}}),de=ue?null:e=>new Worker(e??me,{type:"module",name:oe})}}),Ju=P({"web/lib/wasm/wasm-utils-import.ts"(){pe(),he=ae||"undefined"==typeof location?void 0:location.origin,fe=import.meta.url>"file:"&&import.meta.url<"file;",me=(()=>{if(!ae){if(fe){const e=URL;return new URL(new e("ort.mjs",import.meta.url).href,he).href}return import.meta.url}})(),ge=()=>{if(me&&!me.startsWith("blob:"))return me.substring(0,me.lastIndexOf("/")+1)},_e=(e,t)=>{try{const n=t??me;return(n?new URL(e,n):new URL(e)).origin===he}catch{return!1}},we=(e,t)=>{const n=t??me;try{return(n?new URL(e,n):new URL(e)).href}catch{return}},ye=(e,t)=>`${t??"./"}${e}`,$e=async e=>{const t=await fetch(e,{credentials:"same-origin"}),n=await t.blob();return URL.createObjectURL(n)},be=async e=>(await import(e)).default,ve=(Yu(),N(ce)).default,xe=async()=>{if(!me)throw new Error("Failed to load proxy worker: cannot determine the script source URL.");if(_e(me))return[void 0,ve()];const e=await $e(me);return[e,ve(e)]},ke=void 0,Se=async(e,t,n,i)=>{let r=ke;if(r)if(me)r=_e(me);else{if(!i||n)throw new Error("cannot determine the script source URL.");r=!0}if(r)return[void 0,ke];{const i="ort-wasm-simd-threaded.jsep.mjs",r=e??we(i,t),s=!ae&&n&&r&&!_e(r,t),a=s?await $e(r):r??ye(i,t);return[s?a:void 0,await be(a)]}}}}),ed=P({"web/lib/wasm/wasm-factory.ts"(){Ju(),Te=!1,ze=!1,Ee=!1,Ce=()=>{if("undefined"==typeof SharedArrayBuffer)return!1;try{return"undefined"!=typeof MessageChannel&&(new MessageChannel).port1.postMessage(new SharedArrayBuffer(1)),WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,5,4,1,3,1,1,10,11,1,9,0,65,0,254,16,2,0,26,11]))}catch(e){return!1}},Oe=()=>{try{return WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,4,1,96,0,0,3,2,1,0,10,30,1,28,0,65,0,253,15,253,12,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,253,186,1,26,11]))}catch(e){return!1}},Ae=()=>{try{return WebAssembly.validate(new Uint8Array([0,97,115,109,1,0,0,0,1,5,1,96,0,1,123,3,2,1,0,10,19,1,17,0,65,1,253,15,65,2,253,15,65,3,253,15,253,147,2,11]))}catch(e){return!1}},Be=async e=>{if(Te)return Promise.resolve();if(ze)throw new Error("multiple calls to 'initializeWebAssembly()' detected.");if(Ee)throw new Error("previous call to 'initializeWebAssembly()' failed.");ze=!0;const t=e.initTimeout;let n=e.numThreads;if(!1===e.simd);else if("relaxed"===e.simd){if(!Ae())throw new Error("Relaxed WebAssembly SIMD is not supported in the current environment.")}else if(!Oe())throw new Error("WebAssembly SIMD is not supported in the current environment.");const i=Ce();n>1&&!i&&("undefined"==typeof self||self.crossOriginIsolated||console.warn("env.wasm.numThreads is set to "+n+", but this will not work unless you enable crossOriginIsolated mode. See https://web.dev/cross-origin-isolation-guide/ for more info."),console.warn("WebAssembly multi-threading is not supported in the current environment. Falling back to single-threading."),e.numThreads=n=1);const r=e.wasmPaths,s="string"==typeof r?r:void 0,a=r?.mjs,o=a?.href??a,u=r?.wasm,d=u?.href??u,l=e.wasmBinary,[p,c]=await Se(o,s,n>1,!!l||!!d);let h=!1;const f=[];if(t>0&&f.push(new Promise(e=>{setTimeout(()=>{h=!0,e()},t)})),f.push(new Promise((e,t)=>{const i={numThreads:n};if(l)i.wasmBinary=l;else if(d||s)i.locateFile=e=>d??s+e;else if(o&&0!==o.indexOf("blob:"))i.locateFile=e=>new URL(e,o).href;else if(p){const e=ge();e&&(i.locateFile=t=>e+t)}c(i).then(t=>{ze=!1,Te=!0,Ie=t,e(),p&&URL.revokeObjectURL(p)},e=>{ze=!1,Ee=!0,t(e)})})),await Promise.race(f),h)throw new Error(`WebAssembly backend initializing failed due to timeout: ${t}ms`)},Re=()=>{if(Te&&Ie)return Ie;throw new Error("WebAssembly is not initialized yet.")}}}),td=P({"web/lib/wasm/wasm-utils.ts"(){ed(),De=(e,t)=>{const n=Re(),i=n.lengthBytesUTF8(e)+1,r=n._malloc(i);return n.stringToUTF8(e,r,i),t.push(r),r},Me=(e,t,n,i)=>{if("object"==typeof e&&null!==e){if(n.has(e))throw new Error("Circular reference in options");n.add(e)}Object.entries(e).forEach(([e,r])=>{const s=t?t+e:e;if("object"==typeof r)Me(r,s+".",n,i);else if("string"==typeof r||"number"==typeof r)i(s,r.toString());else{if("boolean"!=typeof r)throw new Error("Can't handle extra config type: "+typeof r);i(s,r?"1":"0")}})},Ue=e=>{const t=Re(),n=t.stackSave();try{const n=t.PTR_SIZE,i=t.stackAlloc(2*n);t._OrtGetLastError(i,i+n);const r=Number(t.getValue(i,4===n?"i32":"i64")),s=t.getValue(i+n,"*"),a=s?t.UTF8ToString(s):"";throw new Error(`${e} ERROR_CODE: ${r}, ERROR_MESSAGE: ${a}`)}finally{t.stackRestore(n)}}}}),nd=P({"web/lib/wasm/run-options.ts"(){ed(),td(),Pe=e=>{const t=Re();let n=0;const i=[],r=e||{};try{if(void 0===e?.logSeverityLevel)r.logSeverityLevel=2;else if("number"!=typeof e.logSeverityLevel||!Number.isInteger(e.logSeverityLevel)||e.logSeverityLevel<0||e.logSeverityLevel>4)throw new Error(`log severity level is not valid: ${e.logSeverityLevel}`);if(void 0===e?.logVerbosityLevel)r.logVerbosityLevel=0;else if("number"!=typeof e.logVerbosityLevel||!Number.isInteger(e.logVerbosityLevel))throw new Error(`log verbosity level is not valid: ${e.logVerbosityLevel}`);void 0===e?.terminate&&(r.terminate=!1);let s=0;return void 0!==e?.tag&&(s=De(e.tag,i)),n=t._OrtCreateRunOptions(r.logSeverityLevel,r.logVerbosityLevel,!!r.terminate,s),0===n&&Ue("Can't create run options."),void 0!==e?.extra&&Me(e.extra,"",new WeakSet,(e,r)=>{const s=De(e,i),a=De(r,i);0!==t._OrtAddRunConfigEntry(n,s,a)&&Ue(`Can't set a run config entry: ${e} - ${r}.`)}),[n,i]}catch(e){throw 0!==n&&t._OrtReleaseRunOptions(n),i.forEach(e=>t._free(e)),e}}}}),id=P({"web/lib/wasm/session-options.ts"(){ed(),td(),qe=e=>{switch(e){case"disabled":return 0;case"basic":return 1;case"extended":return 2;case"layout":return 3;case"all":return 99;default:throw new Error(`unsupported graph optimization level: ${e}`)}},Ne=e=>{switch(e){case"sequential":return 0;case"parallel":return 1;default:throw new Error(`unsupported execution mode: ${e}`)}},Ve=e=>{e.extra||(e.extra={}),e.extra.session||(e.extra.session={});const t=e.extra.session;t.use_ort_model_bytes_directly||(t.use_ort_model_bytes_directly="1"),e.executionProviders&&e.executionProviders.some(e=>"webgpu"===("string"==typeof e?e:e.name))&&(e.enableMemPattern=!1)},Le=(e,t,n,i)=>{const r=De(t,i),s=De(n,i);0!==Re()._OrtAddSessionConfigEntry(e,r,s)&&Ue(`Can't set a session config entry: ${t} - ${n}.`)},Ge=async(e,t,n)=>{for(const i of t){let t="string"==typeof i?i:i.name;const r=[];switch(t){case"webnn":if(t="WEBNN","string"!=typeof i){const t=i,r=t?.deviceType;r&&Le(e,"deviceType",r,n)}break;case"webgpu":if(t="JS","string"!=typeof i){const t=i;if(t?.preferredLayout){if("NCHW"!==t.preferredLayout&&"NHWC"!==t.preferredLayout)throw new Error(`preferredLayout must be either 'NCHW' or 'NHWC': ${t.preferredLayout}`);Le(e,"preferredLayout",t.preferredLayout,n)}}break;case"wasm":case"cpu":continue;default:throw new Error(`not supported execution provider: ${t}`)}const s=De(t,n),a=r.length;let o=0,u=0;if(a>0){o=Re()._malloc(a*Re().PTR_SIZE),n.push(o),u=Re()._malloc(a*Re().PTR_SIZE),n.push(u);for(let e=0;e<a;e++)Re().setValue(o+e*Re().PTR_SIZE,r[e][0],"*"),Re().setValue(u+e*Re().PTR_SIZE,r[e][1],"*")}0!==await Re()._OrtAppendExecutionProvider(e,s,o,u,a)&&Ue(`Can't append execution provider: ${t}.`)}},We=async e=>{const t=Re();let n=0;const i=[],r=e||{};Ve(r);try{const e=qe(r.graphOptimizationLevel??"all"),s=Ne(r.executionMode??"sequential"),a="string"==typeof r.logId?De(r.logId,i):0,o=r.logSeverityLevel??2;if(!Number.isInteger(o)||o<0||o>4)throw new Error(`log severity level is not valid: ${o}`);const u=r.logVerbosityLevel??0;if(!Number.isInteger(u)||u<0||u>4)throw new Error(`log verbosity level is not valid: ${u}`);const d="string"==typeof r.optimizedModelFilePath?De(r.optimizedModelFilePath,i):0;if(n=t._OrtCreateSessionOptions(e,!!r.enableCpuMemArena,!!r.enableMemPattern,s,!!r.enableProfiling,0,a,o,u,d),0===n&&Ue("Can't create session options."),r.executionProviders&&await Ge(n,r.executionProviders,i),void 0!==r.enableGraphCapture){if("boolean"!=typeof r.enableGraphCapture)throw new Error(`enableGraphCapture must be a boolean value: ${r.enableGraphCapture}`);Le(n,"enableGraphCapture",r.enableGraphCapture.toString(),i)}if(r.freeDimensionOverrides)for(const[e,s]of Object.entries(r.freeDimensionOverrides)){if("string"!=typeof e)throw new Error(`free dimension override name must be a string: ${e}`);if("number"!=typeof s||!Number.isInteger(s)||s<0)throw new Error(`free dimension override value must be a non-negative integer: ${s}`);const r=De(e,i);0!==t._OrtAddFreeDimensionOverride(n,r,s)&&Ue(`Can't set a free dimension override: ${e} - ${s}.`)}return void 0!==r.extra&&Me(r.extra,"",new WeakSet,(e,t)=>{Le(n,e,t,i)}),[n,i]}catch(e){throw 0!==n&&0!==t._OrtReleaseSessionOptions(n)&&Ue("Can't release session options."),i.forEach(e=>t._free(e)),e}}}}),rd=P({"web/lib/wasm/wasm-common.ts"(){je=e=>{switch(e){case"int8":return 3;case"uint8":return 2;case"bool":return 9;case"int16":return 5;case"uint16":return 4;case"int32":return 6;case"uint32":return 12;case"float16":return 10;case"float32":return 1;case"float64":return 11;case"string":return 8;case"int64":return 7;case"uint64":return 13;case"int4":return 22;case"uint4":return 21;default:throw new Error(`unsupported data type: ${e}`)}},He=e=>{switch(e){case 3:return"int8";case 2:return"uint8";case 9:return"bool";case 5:return"int16";case 4:return"uint16";case 6:return"int32";case 12:return"uint32";case 10:return"float16";case 1:return"float32";case 11:return"float64";case 8:return"string";case 7:return"int64";case 13:return"uint64";case 22:return"int4";case 21:return"uint4";default:throw new Error(`unsupported data type: ${e}`)}},Fe=(e,t)=>{const n=[-1,4,1,1,2,2,4,8,-1,1,2,8,4,8,-1,-1,-1,-1,-1,-1,-1,.5,.5][e],i="number"==typeof t?t:t.reduce((e,t)=>e*t,1);return n>0?Math.ceil(i*n):void 0},Ke=e=>{switch(e){case"float16":return"undefined"!=typeof Float16Array&&Float16Array.from?Float16Array:Uint16Array;case"float32":return Float32Array;case"uint8":case"bool":return Uint8Array;case"int8":return Int8Array;case"uint16":return Uint16Array;case"int16":return Int16Array;case"int32":return Int32Array;case"float64":return Float64Array;case"uint32":return Uint32Array;case"int64":return BigInt64Array;case"uint64":return BigUint64Array;default:throw new Error(`unsupported type: ${e}`)}},Ze=e=>{switch(e){case"verbose":return 0;case"info":return 1;case"warning":return 2;case"error":return 3;case"fatal":return 4;default:throw new Error(`unsupported logging level: ${e}`)}},Qe=e=>"float32"===e||"float16"===e||"int32"===e||"int64"===e||"uint32"===e||"uint8"===e||"bool"===e||"uint4"===e||"int4"===e,Xe=e=>"float32"===e||"float16"===e||"int32"===e||"int64"===e||"uint32"===e||"uint64"===e||"int8"===e||"uint8"===e||"bool"===e||"uint4"===e||"int4"===e,Ye=e=>{switch(e){case"none":return 0;case"cpu":return 1;case"cpu-pinned":return 2;case"texture":return 3;case"gpu-buffer":return 4;case"ml-tensor":return 5;default:throw new Error(`unsupported data location: ${e}`)}}}}),sd=P({"web/lib/wasm/wasm-utils-load-file.ts"(){pe(),Je=async e=>{if("string"!=typeof e)return e instanceof Blob?new Uint8Array(await e.arrayBuffer()):e instanceof Uint8Array?e:new Uint8Array(e);if(!ae){const t=await fetch(e);if(!t.ok)throw new Error(`failed to load external data file: ${e}`);const n=t.headers.get("Content-Length"),i=n?parseInt(n,10):0;if(i<1073741824)return new Uint8Array(await t.arrayBuffer());{if(!t.body)throw new Error(`failed to load external data file: ${e}, no response body.`);const n=t.body.getReader();let r;try{r=new ArrayBuffer(i)}catch(e){if(!(e instanceof RangeError))throw e;{const e=Math.ceil(i/65536);r=new WebAssembly.Memory({initial:e,maximum:e}).buffer}}let s=0;for(;;){const{done:e,value:t}=await n.read();if(e)break;const i=t.byteLength;new Uint8Array(r,s,i).set(t),s+=i}return new Uint8Array(r,0,i)}}try{const{readFile:t}=U("node:fs/promises");return new Uint8Array(await t(e))}catch(t){if("ERR_FS_FILE_TOO_LARGE"===t.code){const{createReadStream:t}=U("node:fs"),n=t(e),i=[];for await(const e of n)i.push(e);return new Uint8Array(Buffer.concat(i))}throw t}}}}),ad=P({"web/lib/wasm/jsep/log.ts"(){rd(),et=["V","I","W","E","F"],tt=(e,t)=>{console.log(`[${et[e]},${(new Date).toISOString()}]${t}`)},rt=(e,t)=>{nt=e,it=t},st=(e,t)=>{const n=Ze(e);n>=Ze(nt)&&tt(n,"function"==typeof t?t():t)},at=(...e)=>{it&&st(...e)}}}),od=P({"web/lib/wasm/jsep/util.ts"(){ot=class{static calcMatMulShape(e,t){return e[1]!==t[0]?void 0:[e[0],t[1]]}},ut=class{static calcShape(e,t,n=!1){const i=e.length,r=t.length;if(0===i)return t;if(0===r)return e;const s=Math.max(e.length,t.length),a=new Array(s);if(n){if(i<2||r<2)return;const n=ot.calcMatMulShape([e[i-2],e[i-1]],[t[r-2],t[r-1]]);if(void 0===n)return;[a[s-2],a[s-1]]=n}for(let o=n?3:1;o<=s;o++){const n=i-o<0?1:e[i-o],u=r-o<0?1:t[r-o];if(n!==u&&n>1&&u>1)return;const d=Math.max(n,u);if(n&&u)a[s-o]=Math.max(n,u);else{if(d>1)return;a[s-o]=0}}return a}static isValidBroadcast(e,t){const n=e.length,i=t.length;if(n>i)return!1;for(let r=1;r<=n;r++)if(1!==e[n-r]&&e[n-r]!==t[i-r])return!1;return!0}},dt=class e{static size(t){return e.getSizeFromDimensionRange(t,0,t.length)}static convertShape(e,t=4){const n=e.length;if(0===n)return[];const i=new Array(n);let r=n-1;for(;r>=0;){if(e[r]%t===0){i[r]=e[r]/t;break}if(t%e[r]!==0)throw new Error("cannot convert shape");i[r]=1,t/=e[r],r--}for(r--;r>=0;r--)i[r]=e[r];return i}static sizeFromDimension(t,n){if(n<0||n>t.length)throw new Error(`invalid dimension of ${n} for sizeFromDimension as Tensor has ${t.length} dimensions.`);return e.getSizeFromDimensionRange(t,n,t.length)}static sizeToDimension(t,n){if(n<0||n>t.length)throw new Error(`invalid dimension of ${n} for sizeToDimension as Tensor has ${t.length} dimensions.`);return e.getSizeFromDimensionRange(t,0,n)}static getSizeFromDimensionRange(e,t,n){let i=1;for(let r=t;r<n;r++){if(e[r]<0)throw new Error("cannot get valid size from specified dimension range. Most likely the range contains negative values in them.");i*=Number(e[r])}return i}static computeStrides(e){const t=e.length;if(0===t)return[];if(1===t)return[1];const n=new Array(t);n[t-1]=1,n[t-2]=e[t-1];for(let i=t-3;i>=0;--i)n[i]=n[i+1]*e[i+1];return n}static normalizeAxis(e,t){if(e<-t&&e>=t)throw new Error("unsupported axis for this operation.");return e<0?e+t:e}static normalizeAxes(e,t){return e.map(n=>this.normalizeAxis(n,t??e.length))}static sortBasedOnPerm(e,t){return t?t.map(t=>e[t]):e.slice().reverse()}static padShape(e,t){const n=e.length;return e.map((e,i)=>e+t[i]+t[i+n])}static areEqual(e,t){return e.length===t.length&&e.every((e,n)=>e===t[n])}},lt=class e{static adjustPoolAttributes(e,t,n,i,r,s){if(!e&&n.length!==t.length-2)throw new Error("length of specified kernel shapes should be 2 less than length of input dimensions");if(e)for(let e=0;e<t.length-2;e++)e>=n.length?n.push(t[e+2]):n[e]=t[e+2];for(let e=0;e<n.length;e++)if(e<i.length){if(i[e]<0)throw new Error("strides should be greater than or equal to 1")}else i.push(1);for(let e=0;e<n.length;e++)if(e<r.length){if(r[e]<0)throw new Error("dilations should be greater than or equal to 1")}else r.push(1);for(let e=0;e<2*n.length;e++)if(e<s.length){if(s[e]<0)throw new Error("pad should be greater than or equal to 1")}else s.push(0);for(let e=0;e<n.length;e++){if(n[e]<=0)throw new Error("kernel shapes need to be greater than 0");if(s[e]>=n[e]||s[e+n.length]>=n[e])throw new Error("pads should be smaller than kernel")}}static adjustPadsBasedOnAutoPad(t,n,i,r,s,a,o){if(o){if(s.length!==2*(t.length-2))throw new Error("length of pads should be twice the length of data dimensions");if(n.length!==t.length-2)throw new Error("length of strides should be the length of data dimensions");if(r.length!==t.length-2)throw new Error("length of kernel shapes should be the length of data dimensions");for(let u=0;u<t.length-2;u++)e.adjustPadAndReturnShape(t[u+(a?1:2)],n[u],i[u],r[u],s,u,u+t.length-2,o)}}static computePoolOutputShape(t,n,i,r,s,a,o){if(n.length<=0)throw new Error("input shape must be of size greater than 0");const u=[n[0],n[1]];return e.computeShapeHelper(t,n,u,i,r,s,a,o),u}static computeConvOutputShape(t,n,i,r,s,a,o){if(t.length<=0||n.length<=0)throw new Error("invalid input tensor dims or invalid filter tensor dims");const u=[t[0],n[0]];return e.computeShapeHelper(!1,t,u,i,r,s,a,o),u}static computeShapeHelper(t,n,i,r,s,a,o,u){if(t)for(let e=0;e<n.length-2;e++)i.push(1);else for(let t=0;t<n.length-2;t++)i.push(e.adjustPadAndReturnShape(n[t+2],r[t],s[t],a[t],o,t,t+n.length-2,u))}static adjustPadAndReturnShape(e,t,n,i,r,s,a,o){const u=n*(i-1)+1;if(!o||"NOTSET"===o)return Math.floor((e+r[s]+r[a]-u)/t+1);switch(o){case"VALID":return r[s]=0,r[a]=0,Math.floor((e-u)/t+1);case"SAME_LOWER":case"SAME_UPPER":if(1!==n)throw new Error("Dilation not supported for SAME_UPPER or SAME_LOWER");{const n=((e+t-1)/t-1)*t+i-e;return r[s]="SAME_LOWER"===o?Math.floor((n+1)/2):Math.floor(n/2),r[a]=n-r[s],Math.floor((e+n-i)/t+1)}default:throw new Error("Unsupported AutoPad type")}}},pt=class{static getShapeOfGemmResult(e,t,n,i,r){if(2!==e.length||2!==n.length)throw new Error("shape need to be of size 2");let s,a,o;t?(s=e[1],a=e[0]):(s=e[0],a=e[1]);let u=-1;if(i?(o=n[0],u=1):(o=n[1],u=0),n[u]!==a)throw new Error("dimension mismatch");if(s<=0||o<=0||a<=0)throw new Error("invalid shape specified");if(r&&!ut.isValidBroadcast(r,[s,o]))throw new Error("gemm: invalid bias shape for broadcast");return[s,o,a]}},ct=-34028234663852886e22,ht=34028234663852886e22}}),ud=P({"web/lib/wasm/jsep/tensor-view.ts"(){rd(),ft=(e,t)=>new(Ke(t))(e)}}),dd=P({"web/lib/wasm/jsep/webnn/tensor-manager.ts"(){rd(),ad(),mt=new Map([["float32",32],["float16",16],["int32",32],["uint32",32],["int64",64],["uint64",64],["int8",8],["uint8",8],["int4",4],["uint4",4]]),gt=(e,t)=>{if("int32"===t)return e;const n=mt.get(t);if(!n)throw new Error(`WebNN backend does not support data type: ${t}`);const i=n/8;if(e.byteLength%i!==0)throw new Error(`Invalid Uint8Array length - must be a multiple of ${i}.`);const r=e.byteLength/i,s=new(Ke(t))(e.buffer,e.byteOffset,r);switch(t){case"int64":case"uint64":{const e=new Int32Array(r);for(let t=0;t<r;t++){const n=s[t];if(n>2147483647n||n<-2147483648n)throw new Error("Can not convert int64 data to int32 - value out of range.");e[t]=Number(n)}return new Uint8Array(e.buffer)}case"int8":case"uint8":case"uint32":{if("uint32"===t&&s.some(e=>e>2147483647))throw new Error("Can not convert uint32 data to int32 - value out of range.");const e=Int32Array.from(s,Number);return new Uint8Array(e.buffer)}default:throw new Error(`Unsupported data conversion from ${t} to 'int32'`)}},_t=(e,t)=>{if("int32"===t)return e;if(e.byteLength%4!=0)throw new Error("Invalid Uint8Array length - must be a multiple of 4 (int32).");const n=e.byteLength/4,i=new Int32Array(e.buffer,e.byteOffset,n);switch(t){case"int64":{const e=BigInt64Array.from(i,BigInt);return new Uint8Array(e.buffer)}case"uint64":{if(i.some(e=>e<0))throw new Error("Can not convert int32 data to uin64 - negative value found.");const e=BigUint64Array.from(i,BigInt);return new Uint8Array(e.buffer)}case"int8":{if(i.some(e=>e<-128||e>127))throw new Error("Can not convert int32 data to int8 - value out of range.");const e=Int8Array.from(i,Number);return new Uint8Array(e.buffer)}case"uint8":if(i.some(e=>e<0||e>255))throw new Error("Can not convert int32 data to uint8 - value out of range.");return Uint8Array.from(i,Number);case"uint32":{if(i.some(e=>e<0))throw new Error("Can not convert int32 data to uint32 - negative value found.");const e=Uint32Array.from(i,Number);return new Uint8Array(e.buffer)}default:throw new Error(`Unsupported data conversion from 'int32' to ${t}`)}},wt=1,yt=()=>wt++,$t=new Map([["int8","int32"],["uint8","int32"],["uint32","int32"],["int64","int32"]]),bt=(e,t)=>{const n=mt.get(e);if(!n)throw new Error(`WebNN backend does not support data type: ${e}`);return t.length>0?Math.ceil(t.reduce((e,t)=>e*t)*n/8):0},vt=class{constructor(e){this.isDataConverted=!1;const{sessionId:t,context:n,tensor:i,dataType:r,shape:s,fallbackDataType:a}=e;this.sessionId=t,this.mlContext=n,this.mlTensor=i,this.dataType=r,this.tensorShape=s,this.fallbackDataType=a}get tensor(){return this.mlTensor}get type(){return this.dataType}get fallbackType(){return this.fallbackDataType}get shape(){return this.tensorShape}get byteLength(){return bt(this.dataType,this.tensorShape)}destroy(){at("verbose",()=>"[WebNN] TensorWrapper.destroy"),this.mlTensor.destroy()}write(e){this.mlContext.writeTensor(this.mlTensor,e)}async read(e){if(this.fallbackDataType){const t=await this.mlContext.readTensor(this.mlTensor),n=_t(new Uint8Array(t),this.dataType);return e?void(e instanceof ArrayBuffer?new Uint8Array(e):new Uint8Array(e.buffer,e.byteOffset,e.byteLength)).set(n):n.buffer}return e?this.mlContext.readTensor(this.mlTensor,e):this.mlContext.readTensor(this.mlTensor)}canReuseTensor(e,t,n){return this.mlContext===e&&this.dataType===t&&this.tensorShape.length===n.length&&this.tensorShape.every((e,t)=>e===n[t])}setIsDataConverted(e){this.isDataConverted=e}},xt=class{constructor(e,t){this.tensorManager=e,this.wrapper=t}get tensorWrapper(){return this.wrapper}releaseTensor(){this.tensorWrapper&&(this.tensorManager.releaseTensor(this.tensorWrapper),this.wrapper=void 0)}async ensureTensor(e,t,n,i){const r=this.tensorManager.getMLContext(e);let s;if(!r.opSupportLimits().input.dataTypes.includes(t)){if(s=$t.get(t),!s||!r.opSupportLimits().input.dataTypes.includes(s))throw new Error(`WebNN backend does not support data type: ${t}`);at("verbose",()=>`[WebNN] TensorIdTracker.ensureTensor: fallback dataType from ${t} to ${s}`)}if(this.wrapper){if(this.wrapper.canReuseTensor(r,t,n))return this.wrapper.tensor;if(i){if(this.wrapper.byteLength!==bt(t,n))throw new Error("Unable to copy data to tensor with different size.");this.activeUpload=new Uint8Array(await this.wrapper.read())}this.tensorManager.releaseTensor(this.wrapper)}const a="undefined"==typeof MLTensorUsage?void 0:MLTensorUsage.READ|MLTensorUsage.WRITE;return this.wrapper=await this.tensorManager.getCachedTensor(e,t,n,a,!0,!0,s),i&&this.activeUpload&&(this.wrapper.write(this.activeUpload),this.activeUpload=void 0),this.wrapper.tensor}upload(e){let t=e;if(this.wrapper){if(this.wrapper.fallbackType){if("int32"!==this.wrapper.fallbackType)throw new Error(`Unsupported fallback data type: ${this.wrapper.fallbackType}`);t=gt(e,this.wrapper.type),this.wrapper.setIsDataConverted(!0)}if(e.byteLength===this.wrapper.byteLength)return void this.wrapper.write(t);at("verbose",()=>"Data size does not match tensor size. Releasing tensor."),this.releaseTensor()}this.activeUpload?this.activeUpload.set(t):this.activeUpload=new Uint8Array(t)}async download(e){if(this.activeUpload){const t=this.wrapper?.isDataConverted?_t(this.activeUpload,this.wrapper?.type):this.activeUpload;return e?void(e instanceof ArrayBuffer?new Uint8Array(e).set(t):new Uint8Array(e.buffer,e.byteOffset,e.byteLength).set(t)):t.buffer}if(!this.wrapper)throw new Error("Tensor has not been created.");return e?this.wrapper.read(e):this.wrapper.read()}},kt=class{constructor(e){this.backend=e,this.tensorTrackersById=new Map,this.freeTensors=[],this.externalTensors=new Set}getMLContext(e){const t=this.backend.getMLContext(e);if(!t)throw new Error("MLContext not found for session.");return t}reserveTensorId(){const e=yt();return this.tensorTrackersById.set(e,new xt(this)),e}releaseTensorId(e){const t=this.tensorTrackersById.get(e);t&&(this.tensorTrackersById.delete(e),t.tensorWrapper&&this.releaseTensor(t.tensorWrapper))}async ensureTensor(e,t,n,i,r){at("verbose",()=>`[WebNN] TensorManager.ensureTensor {tensorId: ${t}, dataType: ${n}, shape: ${i}, copyOld: ${r}}`);const s=this.tensorTrackersById.get(t);if(!s)throw new Error("Tensor not found.");return s.ensureTensor(e,n,i,r)}upload(e,t){const n=this.tensorTrackersById.get(e);if(!n)throw new Error("Tensor not found.");n.upload(t)}async download(e,t){at("verbose",()=>`[WebNN] TensorManager.download {tensorId: ${e}, dstBuffer: ${t?.byteLength}}`);const n=this.tensorTrackersById.get(e);if(!n)throw new Error("Tensor not found.");return n.download(t)}releaseTensorsForSession(e){for(const t of this.freeTensors)t.sessionId===e&&t.destroy();this.freeTensors=this.freeTensors.filter(t=>t.sessionId!==e)}registerTensor(e,t,n,i){const r=this.getMLContext(e),s=yt(),a=new vt({sessionId:e,context:r,tensor:t,dataType:n,shape:i});return this.tensorTrackersById.set(s,new xt(this,a)),this.externalTensors.add(a),s}async getCachedTensor(e,t,n,i,r,s,a){const o=this.getMLContext(e);for(const[i,r]of this.freeTensors.entries())if(r.canReuseTensor(o,t,n)){at("verbose",()=>`[WebNN] Reusing tensor {dataType: ${t}, ${a?`fallbackDataType: ${a},`:""} shape: ${n}`);const r=this.freeTensors.splice(i,1)[0];return r.sessionId=e,r}at("verbose",()=>`[WebNN] MLContext.createTensor {dataType: ${t}, ${a?`fallbackDataType: ${a},`:""} shape: ${n}}`);const u=await o.createTensor({dataType:a??t,shape:n,dimensions:n,usage:i,writable:r,readable:s});return new vt({sessionId:e,context:o,tensor:u,dataType:t,shape:n,fallbackDataType:a})}releaseTensor(e){this.externalTensors.has(e)&&this.externalTensors.delete(e),this.freeTensors.push(e)}},St=(...e)=>new kt(...e)}}),ld=P({"web/lib/wasm/jsep/backend-webnn.ts"(){rd(),ed(),ud(),dd(),ad(),It=new Map([[1,"float32"],[10,"float16"],[6,"int32"],[12,"uint32"],[7,"int64"],[13,"uint64"],[22,"int4"],[21,"uint4"],[3,"int8"],[2,"uint8"],[9,"uint8"]]),Tt=(e,t)=>{if(e===t)return!0;if(void 0===e||void 0===t)return!1;const n=Object.keys(e).sort(),i=Object.keys(t).sort();return n.length===i.length&&n.every((n,r)=>n===i[r]&&e[n]===t[n])},zt=class{constructor(e){this.tensorManager=St(this),this.mlContextBySessionId=new Map,this.sessionIdsByMLContext=new Map,this.mlContextCache=[],this.sessionGraphInputs=new Map,this.sessionGraphOutputs=new Map,this.temporaryGraphInputs=[],this.temporaryGraphOutputs=[],this.temporarySessionTensorIds=new Map,rt(e.logLevel,!!e.debug)}get currentSessionId(){if(void 0===this.activeSessionId)throw new Error("No active session");return this.activeSessionId}onRunStart(e){at("verbose",()=>`[WebNN] onRunStart {sessionId: ${e}}`),this.activeSessionId=e}onRunEnd(e){at("verbose",()=>`[WebNN] onRunEnd {sessionId: ${e}}`);const t=this.temporarySessionTensorIds.get(e);if(t){for(const e of t)at("verbose",()=>`[WebNN] releasing temporary tensor {tensorId: ${e}}`),this.tensorManager.releaseTensorId(e);this.temporarySessionTensorIds.delete(e),this.activeSessionId=void 0}}async createMLContext(e){if(e instanceof GPUDevice){const t=this.mlContextCache.findIndex(t=>t.gpuDevice===e);if(-1!==t)return this.mlContextCache[t].mlContext;{const t=await navigator.ml.createContext(e);return this.mlContextCache.push({gpuDevice:e,mlContext:t}),t}}if(void 0===e){const e=this.mlContextCache.findIndex(e=>void 0===e.options&&void 0===e.gpuDevice);if(-1!==e)return this.mlContextCache[e].mlContext;{const e=await navigator.ml.createContext();return this.mlContextCache.push({mlContext:e}),e}}const t=this.mlContextCache.findIndex(t=>Tt(t.options,e));if(-1!==t)return this.mlContextCache[t].mlContext;{const t=await navigator.ml.createContext(e);return this.mlContextCache.push({options:e,mlContext:t}),t}}registerMLContext(e,t){this.mlContextBySessionId.set(e,t);let n=this.sessionIdsByMLContext.get(t);n||(n=new Set,this.sessionIdsByMLContext.set(t,n)),n.add(e),this.temporaryGraphInputs.length>0&&(this.sessionGraphInputs.set(e,this.temporaryGraphInputs),this.temporaryGraphInputs=[]),this.temporaryGraphOutputs.length>0&&(this.sessionGraphOutputs.set(e,this.temporaryGraphOutputs),this.temporaryGraphOutputs=[])}onReleaseSession(e){this.sessionGraphInputs.delete(e),this.sessionGraphOutputs.delete(e);const t=this.mlContextBySessionId.get(e);if(!t)return;this.tensorManager.releaseTensorsForSession(e),this.mlContextBySessionId.delete(e);const n=this.sessionIdsByMLContext.get(t);if(n.delete(e),0===n.size){this.sessionIdsByMLContext.delete(t);const e=this.mlContextCache.findIndex(e=>e.mlContext===t);-1!==e&&this.mlContextCache.splice(e,1)}}getMLContext(e){return this.mlContextBySessionId.get(e)}reserveTensorId(){return this.tensorManager.reserveTensorId()}releaseTensorId(e){at("verbose",()=>`[WebNN] releaseTensorId {tensorId: ${e}}`),this.tensorManager.releaseTensorId(e)}async ensureTensor(e,t,n,i,r){const s=It.get(n);if(!s)throw new Error(`Unsupported ONNX data type: ${n}`);return this.tensorManager.ensureTensor(e??this.currentSessionId,t,s,i,r)}async createTemporaryTensor(e,t,n){at("verbose",()=>`[WebNN] createTemporaryTensor {onnxDataType: ${t}, shape: ${n}}`);const i=It.get(t);if(!i)throw new Error(`Unsupported ONNX data type: ${t}`);const r=this.tensorManager.reserveTensorId();await this.tensorManager.ensureTensor(e,r,i,n,!1);const s=this.temporarySessionTensorIds.get(e);return s?s.push(r):this.temporarySessionTensorIds.set(e,[r]),r}uploadTensor(e,t){if(!Re().shouldTransferToMLTensor)throw new Error("Trying to upload to a MLTensor while shouldTransferToMLTensor is false");at("verbose",()=>`[WebNN] uploadTensor {tensorId: ${e}, data: ${t.byteLength}}`),this.tensorManager.upload(e,t)}async downloadTensor(e,t){return this.tensorManager.download(e,t)}createMLTensorDownloader(e,t){return async()=>{const n=await this.tensorManager.download(e);return ft(n,t)}}registerMLTensor(e,t,n,i){const r=It.get(n);if(!r)throw new Error(`Unsupported ONNX data type: ${n}`);const s=this.tensorManager.registerTensor(e,t,r,i);return at("verbose",()=>`[WebNN] registerMLTensor {tensor: ${t}, dataType: ${r}, dimensions: ${i}} -> {tensorId: ${s}}`),s}registerMLConstant(e,t,n,i,r,s,a=!1){if(!s)throw new Error("External mounted files are not available.");let o=e;e.startsWith("./")&&(o=e.substring(2));const u=s.get(o);if(!u)throw new Error(`File with name ${o} not found in preloaded files.`);if(t+n>u.byteLength)throw new Error("Out of bounds: data offset and length exceed the external file data size.");const d=u.slice(t,t+n).buffer;let l;switch(r.dataType){case"float32":l=new Float32Array(d);break;case"float16":l="undefined"!=typeof Float16Array&&Float16Array.from?new Float16Array(d):new Uint16Array(d);break;case"int32":l=new Int32Array(d);break;case"uint32":l=new Uint32Array(d);break;case"int64":if(a){const e=gt(new Uint8Array(d),"int64");l=new Int32Array(e.buffer),r.dataType="int32"}else l=new BigInt64Array(d);break;case"uint64":l=new BigUint64Array(d);break;case"int8":l=new Int8Array(d);break;case"int4":case"uint4":case"uint8":l=new Uint8Array(d);break;default:throw new Error(`Unsupported data type: ${r.dataType} in creating WebNN Constant from external data.`)}return at("verbose",()=>`[WebNN] registerMLConstant {dataType: ${r.dataType}, shape: ${r.shape}}} ${a?"(Note: it was int64 data type and registered to int32 as workaround)":""}`),i.constant(r,l)}registerGraphInput(e){this.temporaryGraphInputs.push(e)}registerGraphOutput(e){this.temporaryGraphOutputs.push(e)}isGraphInput(e,t){const n=this.sessionGraphInputs.get(e);return!!n&&n.includes(t)}isGraphOutput(e,t){const n=this.sessionGraphOutputs.get(e);return!!n&&n.includes(t)}isGraphInputOutputTypeSupported(e,t,n=!0){const i=this.mlContextBySessionId.get(e),r=It.get(je(t));return void 0!==r&&(n?!!i?.opSupportLimits().input.dataTypes.includes(r):!!i?.opSupportLimits().output.dataTypes.includes(r))}flush(){}}}}),pd=P({"web/lib/wasm/jsep/webgpu/types.ts"(){}}),cd=P({"web/lib/wasm/jsep/webgpu/gpu-data-manager.ts"(){ad(),pd(),Et=new Map([[64,250],[128,200],[256,200],[512,200],[2048,230],[4096,200],[8192,50],[16384,50],[32768,50],[65536,50],[131072,50],[262144,50],[524288,50],[1048576,50],[2097152,30],[4194304,20],[8388608,10],[12582912,10],[16777216,10],[26214400,15],[33554432,22],[44236800,2],[58982400,6],[67108864,6],[134217728,6],[167772160,6]]),Ct=[],Ot=e=>16*Math.ceil(Number(e)/16),At=e=>{for(let t=0;t<Ct.length;t++){const n=Ct[t];if(e<=n)return n}return 16*Math.ceil(e/16)},Bt=1,Rt=()=>Bt++,Dt=async(e,t,n,i)=>{const r=Ot(n),s=e.device.createBuffer({size:r,usage:GPUBufferUsage.COPY_DST|GPUBufferUsage.MAP_READ});try{const a=e.getCommandEncoder();e.endComputePass(),a.copyBufferToBuffer(t,0,s,0,r),e.flush(),await s.mapAsync(GPUMapMode.READ);const o=s.getMappedRange();if(i){const e=i();return e.set(new Uint8Array(o,0,n)),e}return new Uint8Array(o.slice(0,n))}finally{s.destroy()}},Mt=class{constructor(e){this.backend=e,this.storageCache=new Map,this.freeBuffers=new Map,this.freeUniformBuffers=new Map,this.buffersPending=[],this.capturedPendingBuffers=new Map;for(const[e]of Et)Ct.push(e),this.freeBuffers.set(e,[]),this.freeUniformBuffers.set(e,[]);this.sessionCount=0}upload(e,t){const n=t.buffer,i=t.byteOffset,r=t.byteLength,s=Ot(r),a=this.storageCache.get(e);if(!a)throw new Error("gpu data for uploading does not exist");if(Number(a.originalSize)!==r)throw new Error(`inconsistent data size. gpu data size=${a.originalSize}, data size=${r}`);const o=this.backend.device.createBuffer({mappedAtCreation:!0,size:s,usage:GPUBufferUsage.MAP_WRITE|GPUBufferUsage.COPY_SRC}),u=o.getMappedRange();new Uint8Array(u).set(new Uint8Array(n,i,r)),o.unmap();const d=this.backend.device.createCommandEncoder();d.copyBufferToBuffer(o,0,a.gpuData.buffer,0,s),this.backend.device.queue.submit([d.finish()]),o.destroy(),at("verbose",()=>`[WebGPU] GpuDataManager.upload(id=${e})`)}memcpy(e,t){const n=this.storageCache.get(e);if(!n)throw new Error("source gpu data for memcpy does not exist");const i=this.storageCache.get(t);if(!i)throw new Error("destination gpu data for memcpy does not exist");if(n.originalSize!==i.originalSize)throw new Error("inconsistent source and destination gpu data size");const r=Ot(n.originalSize),s=this.backend.getCommandEncoder();this.backend.endComputePass(),s.copyBufferToBuffer(n.gpuData.buffer,0,i.gpuData.buffer,0,r)}registerExternalBuffer(e,t,n){let i;if(n){if(i=n[0],e===n[1])return at("verbose",()=>`[WebGPU] GpuDataManager.registerExternalBuffer(size=${t}) => id=${i}, buffer is the same, skip.`),i;if(this.backend.capturedCommandList.has(this.backend.currentSessionId))throw new Error("Registering a different external buffer under graph capture mode is not supported yet.\n             Please use the previous external buffer!")}else i=Rt();return this.storageCache.set(i,{gpuData:{id:i,type:0,buffer:e},originalSize:t}),at("verbose",()=>`[WebGPU] GpuDataManager.registerExternalBuffer(size=${t}) => id=${i}, registered.`),i}unregisterExternalBuffer(e){void 0!==e&&(this.storageCache.delete(e),at("verbose",()=>`[WebGPU] GpuDataManager.unregisterExternalBuffer() => id=${e}`))}create(e,t=GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST){const n=At(e);let i;const r=(t&GPUBufferUsage.STORAGE)===GPUBufferUsage.STORAGE,s=(t&GPUBufferUsage.UNIFORM)===GPUBufferUsage.UNIFORM;if(r||s){const e=(r?this.freeBuffers:this.freeUniformBuffers).get(n);i=e&&e.length>0?e.pop():this.backend.device.createBuffer({size:n,usage:t})}else i=this.backend.device.createBuffer({size:n,usage:t});const a={id:Rt(),type:0,buffer:i};return this.storageCache.set(a.id,{gpuData:a,originalSize:Number(e)}),at("verbose",()=>`[WebGPU] GpuDataManager.create(size=${e}) => id=${a.id}`),a}get(e){return this.storageCache.get(e)?.gpuData}release(e){const t="bigint"==typeof e?Number(e):e,n=this.storageCache.get(t);if(!n){if(0===this.storageCache.size)return 0;throw new Error("releasing data does not exist")}return at("verbose",()=>`[WebGPU] GpuDataManager.release(id=${t}), gpuDataId=${n.gpuData.id}`),this.storageCache.delete(t),this.buffersPending.push(n.gpuData.buffer),n.originalSize}async download(e,t){const n=this.storageCache.get(Number(e));if(!n)throw new Error("data does not exist");await Dt(this.backend,n.gpuData.buffer,n.originalSize,t)}refreshPendingBuffers(){if(0!==this.buffersPending.length)if("default"===this.backend.sessionStatus){for(const e of this.buffersPending){const t=Et.get(e.size);if((e.usage&GPUBufferUsage.STORAGE)===GPUBufferUsage.STORAGE){const n=this.freeBuffers.get(e.size)||[];void 0===t||n.length>=t?e.destroy():n.push(e)}else if((e.usage&GPUBufferUsage.UNIFORM)===GPUBufferUsage.UNIFORM){const n=this.freeUniformBuffers.get(e.size)||[];void 0===t||n.length>=t?e.destroy():n.push(e)}else e.destroy()}this.buffersPending=[]}else{let e=this.capturedPendingBuffers.get(this.backend.currentSessionId);e||(e=[],this.capturedPendingBuffers.set(this.backend.currentSessionId,e));for(const t of this.buffersPending)e.push(t);this.buffersPending=[]}}dispose(){this.freeBuffers.forEach(e=>{e.forEach(e=>{e.destroy()})}),this.freeUniformBuffers.forEach(e=>{e.forEach(e=>{e.destroy()})}),this.storageCache.forEach(e=>{e.gpuData.buffer.destroy()}),this.capturedPendingBuffers.forEach(e=>{e.forEach(e=>{e.destroy()})}),this.storageCache=new Map,this.freeBuffers=new Map,this.freeUniformBuffers=new Map,this.capturedPendingBuffers=new Map}onCreateSession(){this.sessionCount+=1}onReleaseSession(e){const t=this.capturedPendingBuffers.get(e);t&&(t.forEach(e=>{e.destroy()}),this.capturedPendingBuffers.delete(e)),this.sessionCount-=1,0===this.sessionCount&&(at("warning",()=>"[WebGPU] Clearing webgpu buffer cache"),this.storageCache.forEach(e=>{e.gpuData.buffer.destroy()}),this.storageCache=new Map)}},Ut=(...e)=>new Mt(...e)}}),hd=P({"web/lib/wasm/jsep/webgpu/attribute-with-cache-key.ts"(){Pt=class{constructor(e){Object.assign(this,e)}get cacheKey(){return this.key||(this.key=Object.getOwnPropertyNames(this).sort().map(e=>`${this[e]}`).join(";")),this.key}},qt=e=>new Pt(e)}}),fd=P({"web/lib/wasm/jsep/webgpu/ops/common.ts"(){rd(),od(),Nt=64,Vt=(e,t)=>{if(3===t)throw new Error("vec3 has same alignment as vec4, use vec4 instead");switch(Number(e)){case 10:return t>1?`vec${t}<f16>`:"f16";case 1:return t>1?`vec${t}<f32>`:"f32";case 6:return t>1?`vec${t}<i32>`:"i32";case 12:return t>1?`vec${t}<u32>`:"u32";case 7:if(t>1)throw new Error("currently not supported vecX of uint64 yet");return["vec2<u32>","i32"];case 13:if(t>1)throw new Error("currently not supported vecX of uint64 yet");return["vec2<u32>","u32"];case 9:if(4!==t)throw new Error("bool must be vec4");return["u32","vec4<bool>"];case 22:return"i32";case 21:return"u32";default:throw new Error(`Unknown data type: ${e}`)}},Lt=(e,t=1)=>{const n=Vt(e,t);return"string"==typeof n?n:n[0]},Gt=(e,t=1)=>{const n=Vt(e,t);return"string"==typeof n?n:n[1]},Wt=(...e)=>{const t=[];return e.forEach(e=>{0!==e.length&&t.push({type:12,data:e},{type:12,data:dt.computeStrides(e)})}),t},jt=e=>e%4==0?4:e%2==0?2:1,Ht=(e="f32",t,n="0")=>t&&1!==t?`vec${t}<${e}>(${n})`:`${e}(${n})`,Ft=(e,t,n)=>"f32"===e?n:1===t?`f32(${n})`:`vec${t}<f32>(${n})`,Kt=(e,t)=>4===t?`(${e}.x + ${e}.y + ${e}.z + ${e}.w)`:2===t?`(${e}.x + ${e}.y)`:3===t?`(${e}.x + ${e}.y + ${e}.z)`:e,Zt=(e,t,n,i)=>e.startsWith("uniforms.")&&n>4?"string"==typeof t?"f16"===i?`${e}[(${t}) / 8][(${t}) % 8 / 4][(${t}) % 8 % 4]`:`${e}[(${t}) / 4][(${t}) % 4]`:"f16"===i?`${e}[${Math.floor(t/8)}][${Math.floor(t%8/4)}][${t%8%4}]`:`${e}[${Math.floor(t/4)}][${t%4}]`:n>1?`${e}[${t}]`:e,Qt=(e,t,n,i,r)=>{const s="number"==typeof n,a=s?n:n.length,o=[...new Array(a).keys()],u=a<2?"u32":a<=4?`vec${a}<u32>`:`array<u32, ${a}>`,d=Vt(t,r),l="string"==typeof d?d:d[1],p="string"==typeof d?d:d[0],c={indices:u,value:l,storage:p,tensor:t},h=e=>"string"==typeof e?e:`${e}u`,f={offsetToIndices:!1,indicesToOffset:!1,broadcastedIndicesToOffset:!1,set:!1,setByIndices:!1,get:!1,getByIndices:!1},m=s?"uniforms.":"",g=`${m}${e}_shape`,_=`${m}${e}_strides`;let w="";for(let e=0;e<a-1;e++)w+=`\n    let dim${e} = current / ${Zt(_,e,a)};\n    let rest${e} = current % ${Zt(_,e,a)};\n    indices[${e}] = dim${e};\n    current = rest${e};\n    `;w+=`indices[${a-1}] = current;`;const y=a<2?"":`\n  fn o2i_${e}(offset: u32) -> ${c.indices} {\n    var indices: ${c.indices};\n    var current = offset;\n    ${w}\n    return indices;\n  }`,$=[];if(a>=2)for(let e=a-1;e>=0;e--)$.push(`${Zt(_,e,a)} * (indices[${e}])`);const b=a<2?"":`\n  fn i2o_${e}(indices: ${c.indices}) -> u32 {\n    return ${$.join("+")};\n  }`,v=(...e)=>0===a?"0u":`${c.indices}(${e.map(h).join(",")})`,x=(e,t)=>a<2?`${e}`:`${Zt(e,t,a)}`,k={},S=(t,n)=>(()=>{if(c.storage===c.value)return`${e}[${t}]=${n};`;if("vec2<u32>"===c.storage&&"i32"===c.value)return`${e}[${t}]=vec2<u32>(u32(${n}), select(0u, 0xFFFFFFFFu, ${n} < 0));`;if("vec2<u32>"===c.storage&&"u32"===c.value)return`${e}[${t}]=vec2<u32>(u32(${n}), 0u);`;if("u32"===c.storage&&"vec4<bool>"===c.value)return`${e}[${t}]=dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(${n}));`;throw new Error(`not supported combination of storage type ${c.storage} and value type ${c.value} yet`)})(),I=t=>(()=>{if(c.storage===c.value)return`${e}[${t}]`;if("vec2<u32>"===c.storage&&"i32"===c.value)return`i32(${e}[${t}].x)`;if("vec2<u32>"===c.storage&&"u32"===c.value)return`u32(${e}[${t}].x)`;if("u32"===c.storage&&"vec4<bool>"===c.value)return`vec4<bool>(bool(${e}[${t}] & 0xFFu), bool(${e}[${t}] & 0xFF00u), bool(${e}[${t}] & 0xFF0000u), bool(${e}[${t}] & 0xFF000000u))`;throw new Error(`not supported combination of storage type ${c.storage} and value type ${c.value} yet`)})(),T=a<2?"":`\n  fn get_${e}ByIndices(indices: ${c.indices}) -> ${l} {\n    return ${I(`i2o_${e}(indices)`)};\n  }`,z=a<2?"":(()=>{const t=o.map(e=>`d${e}: u32`).join(", "),n=o.map(e=>`d${e}`).join(", ");return`\n  fn get_${e}(${t}) -> ${l} {\n    return get_${e}ByIndices(${v(n)});\n  }`})(),E=a<2?"":`\n  fn set_${e}ByIndices(indices: ${c.indices}, value: ${l}) {\n    ${S(`i2o_${e}(indices)`,"value")}\n  }`,C=a<2?"":(()=>{const t=o.map(e=>`d${e}: u32`).join(", "),n=o.map(e=>`d${e}`).join(", ");return`\n  fn set_${e}(${t}, value: ${l}) {\n    set_${e}ByIndices(${v(n)}, value);\n  }`})();return{impl:()=>{const e=[];let t=!1;return f.offsetToIndices&&(e.push(y),t=!0),f.indicesToOffset&&(e.push(b),t=!0),f.broadcastedIndicesToOffset&&(Object.values(k).forEach(t=>e.push(t)),t=!0),f.set&&(e.push(C),t=!0),f.setByIndices&&(e.push(E),t=!0),f.get&&(e.push(z),t=!0),f.getByIndices&&(e.push(T),t=!0),!s&&t&&e.unshift(`const ${g} = ${c.indices}(${n.join(",")});`,`const ${_} = ${c.indices}(${dt.computeStrides(n).join(",")});`),e.join("\n")},type:c,offsetToIndices:t=>(f.offsetToIndices=!0,a<2?t:`o2i_${e}(${t})`),indicesToOffset:t=>(f.indicesToOffset=!0,a<2?t:`i2o_${e}(${t})`),broadcastedIndicesToOffset:(t,n)=>{f.broadcastedIndicesToOffset=!0;const i=`${n.name}broadcastedIndicesTo${e}Offset`;if(i in k)return`${i}(${t})`;const r=[];for(let e=a-1;e>=0;e--){const t=n.indicesGet("outputIndices",e+n.rank-a);r.push(`${x(_,e)} * (${t} % ${x(g,e)})`)}return k[i]=`fn ${i}(outputIndices: ${n.type.indices}) -> u32 {\n             return ${r.length>0?r.join("+"):"0u"};\n           }`,`${i}(${t})`},indices:v,indicesGet:x,indicesSet:(e,t,n)=>a<2?`${e}=${n};`:`${Zt(e,t,a)}=${n};`,set:(...t)=>{if(t.length!==a+1)throw new Error(`indices length must be ${a}`);const n=t[a];if("string"!=typeof n)throw new Error("value must be string");const i=t.slice(0,a).map(h).join(",");return 0===a?S("0u",n):1===a?S(i[0],n):(f.set=!0,f.setByIndices=!0,f.indicesToOffset=!0,`set_${e}(${i}, ${n})`)},setByOffset:S,setByIndices:(t,n)=>a<2?S(t,n):(f.setByIndices=!0,f.indicesToOffset=!0,`set_${e}ByIndices(${t}, ${n});`),get:(...t)=>{if(t.length!==a)throw new Error(`indices length must be ${a}`);const n=t.map(h).join(",");return 0===a?I("0u"):1===a?I(n[0]):(f.get=!0,f.getByIndices=!0,f.indicesToOffset=!0,`get_${e}(${n})`)},getByOffset:I,getByIndices:t=>a<2?I(t):(f.getByIndices=!0,f.indicesToOffset=!0,`get_${e}ByIndices(${t})`),usage:i,name:e,strides:_,shape:g,rank:a}},Xt=(e,t,n,i=1)=>Qt(e,t,n,"input",i),Yt=(e,t,n,i=1)=>Qt(e,t,n,"output",i),Jt=(e,t,n)=>Qt(e,t,n,"atomicOutput",1),en=(e,t,n,i=1)=>Qt(e,t,n,"internal",i),tn=class{constructor(e,t){this.normalizedDispatchGroup=e,this.limits=t,this.internalVariables=[],this.variables=[],this.uniforms=[],this.variableIndex=0}guardAgainstOutOfBoundsWorkgroupSizes(e){return`if (global_idx >= ${"number"==typeof e?`${e}u`:e}) { return; }`}mainStart(e=Nt){const t="number"==typeof e?e:e[0],n="number"==typeof e?1:e[1],i="number"==typeof e?1:e[2];if(t>this.limits.maxComputeWorkgroupSizeX||n>this.limits.maxComputeWorkgroupSizeY||i>this.limits.maxComputeWorkgroupSizeZ)throw new Error(`workgroup size [${t}, ${n}, ${i}] exceeds the maximum workgroup size [${this.limits.maxComputeWorkgroupSizeX}, ${this.limits.maxComputeWorkgroupSizeY}, ${this.limits.maxComputeWorkgroupSizeZ}].`);if(t*n*i>this.limits.maxComputeInvocationsPerWorkgroup)throw new Error(`workgroup size [${t}, ${n}, ${i}] exceeds the maximum workgroup invocations ${this.limits.maxComputeInvocationsPerWorkgroup}.`);const r=1===this.normalizedDispatchGroup[1]&&1===this.normalizedDispatchGroup[2];return`@compute @workgroup_size(${t}, ${n}, ${i})\n  fn main(${r?"@builtin(global_invocation_id) global_id : vec3<u32>,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(local_invocation_index) local_idx : u32,\n    @builtin(local_invocation_id) local_id : vec3<u32>":"@builtin(global_invocation_id) global_id : vec3<u32>,\n                                             @builtin(local_invocation_id) local_id : vec3<u32>,\n    @builtin(local_invocation_index) local_idx : u32,\n    @builtin(workgroup_id) workgroup_id : vec3<u32>,\n    @builtin(num_workgroups) num_workgroups : vec3<u32>"}) {\n    ${r?"let global_idx = global_id.x;\n         let workgroup_index = workgroup_id.x;":`let workgroup_index = workgroup_id.z * num_workgroups[0] * num_workgroups[1] +\n             workgroup_id.y * num_workgroups[0] + workgroup_id.x;\n         let global_idx = workgroup_index * ${t*n*i}u + local_idx;`}\n  `}appendVariableUniforms(e){0!==e.rank&&(e.shape.startsWith("uniforms.")&&this.uniforms.push({name:e.shape.replace("uniforms.",""),type:"u32",length:e.rank}),e.strides.startsWith("uniforms.")&&this.uniforms.push({name:e.strides.replace("uniforms.",""),type:"u32",length:e.rank}))}declareVariable(e,t){if("internal"===e.usage)throw new Error("cannot use internal variable with declareVariable(). use registerInternalVariables() instead.");this.variables.push(e),this.appendVariableUniforms(e);const n="input"===e.usage?"read":"read_write",i="atomicOutput"===e.usage?"atomic<i32>":e.type.storage;return`@group(0) @binding(${t}) var<storage, ${n}> ${e.name}: array<${i}>;`}declareVariables(...e){return e.map(e=>this.declareVariable(e,this.variableIndex++)).join("\n")}registerInternalVariable(e){if("internal"!==e.usage)throw new Error("cannot use input or output variable with registerInternalVariable(). use declareVariables() instead.");this.internalVariables.push(e),this.appendVariableUniforms(e)}registerInternalVariables(...e){return e.forEach(e=>this.registerInternalVariable(e)),this}registerUniform(e,t,n=1){return this.uniforms.push({name:e,type:t,length:n}),this}registerUniforms(e){return this.uniforms=this.uniforms.concat(e),this}uniformDeclaration(){if(0===this.uniforms.length)return"";const e=[];for(const{name:t,type:n,length:i}of this.uniforms)if(i&&i>4)"f16"===n?e.push(`@align(16) ${t}:array<mat2x4<${n}>, ${Math.ceil(i/8)}>`):e.push(`${t}:array<vec4<${n}>, ${Math.ceil(i/4)}>`);else{const r=null==i||1===i?n:`vec${i}<${n}>`;e.push(`${t}:${r}`)}return`\n      struct Uniforms { ${e.join(", ")} };\n      @group(0) @binding(${this.variableIndex}) var<uniform> uniforms: Uniforms;`}get additionalImplementations(){return this.uniformDeclaration()+this.variables.map(e=>e.impl()).join("\n")+this.internalVariables.map(e=>e.impl()).join("\n")}get variablesInfo(){if(0!==this.uniforms.length)return this.uniforms.map(e=>{return[(t=e.type,[12,10,1,6][["u32","f16","f32","i32"].indexOf(t)]),e.length??1];var t})}},nn=(e,t)=>new tn(e,t)}}),md=P({"web/lib/wasm/jsep/webgpu/ops/transpose.ts"(){rd(),od(),hd(),fd(),rn=(e,t)=>{if(!e||1!==e.length)throw new Error("Transpose requires 1 input.");if(0!==t.length&&t.length!==e[0].dims.length)throw new Error(`perm size ${t.length} does not match input rank ${e[0].dims.length}`)},sn=(e,t)=>0!==t.length?t:[...new Array(e).keys()].reverse(),an=(e,t)=>dt.sortBasedOnPerm(e,sn(e.length,t)),on=(e,t,n,i)=>{let r=`fn perm(i: ${i.type.indices}) -> ${n.type.indices} {\n    var a: ${n.type.indices};`;for(let n=0;n<t;++n)r+=`a[${e[n]}]=i[${n}];`;return r+"return a;}"},un=(e,t)=>{const n=[],i=[];for(let r=0;r<e.length;++r)1!==e[r]&&n.push(e[r]),1!==e[t[r]]&&i.push(t[r]);return{newShape:n,newPerm:i}},dn=(e,t)=>{let n=0;for(let i=0;i<e.length;++i)if(1!==t[e[i]]){if(e[i]<n)return!1;n=e[i]}return!0},ln=(e,t)=>{const n=e.dataType,i=e.dims.length,r=sn(i,t),s=an(e.dims,r);let a,o=e.dims,u=s;if(i<2||dn(r,e.dims))return a=e=>{const t=Xt("input",n,o,4),i=Yt("output",n,u,4);return`\n  ${e.registerUniform("output_size","u32").declareVariables(t,i)}\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n    output[global_idx] = input[global_idx];\n  }`},{name:"TransposeCopy",shaderCache:{inputDependencies:["type"]},getRunData:()=>{const t=dt.size(s);return{outputs:[{dims:s,dataType:e.dataType}],dispatchGroup:{x:Math.ceil(t/64/4)},programUniforms:[{type:12,data:Math.ceil(t/4)}]}},getShaderSource:a};const{newShape:d,newPerm:l}=un(e.dims,r),p=dt.areEqual(l,[2,3,1]),c=dt.areEqual(l,[3,1,2]);if(2===d.length||p||c){o=p?[d[0],d[1]*d[2]]:c?[d[0]*d[1],d[2]]:d,u=[o[1],o[0]];const t=16;return a=e=>{const i=Xt("a",n,o.length),r=Yt("output",n,u.length);return`\n  ${e.registerUniform("output_size","u32").declareVariables(i,r)}\n  var<workgroup> tile : array<array<${r.type.value}, ${t+1}>, ${t}>;\n  ${e.mainStart([t,t,1])}\n    let stride = (uniforms.output_shape[1] - 1) / ${t} + 1;\n    let workgroup_id_x = workgroup_index % stride;\n    let workgroup_id_y = workgroup_index / stride;\n    let input_col = workgroup_id_y * ${t}u + local_id.x;\n    let input_row = workgroup_id_x * ${t}u + local_id.y;\n    if (input_row < uniforms.a_shape[0] && input_col < uniforms.a_shape[1]) {\n      tile[local_id.y][local_id.x] = ${i.getByIndices(`${i.type.indices}(input_row, input_col)`)};\n    }\n    workgroupBarrier();\n\n    let output_col = workgroup_id_x * ${t}u + local_id.x;\n    let output_row = workgroup_id_y * ${t}u + local_id.y;\n    if (output_row < uniforms.output_shape[0] && output_col < uniforms.output_shape[1]) {\n      ${r.setByIndices(`${r.type.indices}(output_row, output_col)`,"tile[local_id.x][local_id.y]")}\n    }\n  }`},{name:"TransposeShared",shaderCache:{inputDependencies:["type"]},getRunData:()=>{const n=dt.size(s);return{outputs:[{dims:s,dataType:e.dataType}],dispatchGroup:{x:Math.ceil(u[1]/t),y:Math.ceil(u[0]/t)},programUniforms:[{type:12,data:n},...Wt(o,u)]}},getShaderSource:a}}return a=e=>{const t=Xt("a",n,o.length),s=Yt("output",n,u.length);return`\n  ${e.registerUniform("output_size","u32").declareVariables(t,s)}\n\n  ${on(r,i,t,s)}\n\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n\n    let indices = ${s.offsetToIndices("global_idx")};\n    let aIndices = perm(indices);\n\n    ${s.setByOffset("global_idx",t.getByIndices("aIndices"))}\n  }`},{name:"Transpose",shaderCache:{hint:`${t}`,inputDependencies:["rank"]},getRunData:()=>{const t=dt.size(s);return{outputs:[{dims:s,dataType:e.dataType}],dispatchGroup:{x:Math.ceil(t/64)},programUniforms:[{type:12,data:t},...Wt(o,u)]}},getShaderSource:a}},pn=(e,t)=>{rn(e.inputs,t.perm),e.compute(ln(e.inputs[0],t.perm))},cn=e=>qt({perm:e.perm})}}),gd=P({"web/lib/wasm/jsep/webgpu/ops/reduce-shared.ts"(){rd(),od(),fd(),_d(),md(),hn={max:"select(bestValue, candidate, candidate > bestValue)",min:"select(bestValue, candidate, candidate < bestValue)",mean:"bestValue + candidate",sum:"bestValue + candidate",prod:"bestValue * candidate",sumSquare:"bestValue + candidate * candidate",logSumExp:"bestValue + exp(candidate)",l1:"bestValue + abs(candidate)",l2:"bestValue + candidate * candidate",logSum:"bestValue + candidate"},fn={max:"select(bestValue, candidate, candidate > bestValue)",min:"select(bestValue, candidate, candidate < bestValue)",mean:"bestValue + candidate",sum:"bestValue + candidate",prod:"bestValue * candidate",sumSquare:"bestValue + candidate",logSumExp:"bestValue + candidate",l1:"bestValue + candidate",l2:"bestValue + candidate",logSum:"bestValue + candidate"},mn={max:"_A[offset]",min:"_A[offset]",mean:"0",sum:"0",prod:"1",sumSquare:"0",logSumExp:"0",l1:"0",l2:"0",logSum:"0"},gn={max:"bestValue",min:"bestValue",sum:"bestValue",prod:"bestValue",sumSquare:"bestValue",logSumExp:"log(bestValue)",l1:"bestValue",l2:"sqrt(bestValue)",logSum:"log(bestValue)"},_n=(e,t)=>{const n=[];for(let i=t-e;i<t;++i)n.push(i);return n},wn=(e,t)=>{const n=[],i=e.length;for(let r=0;r<i;r++)-1===t.indexOf(r)&&n.push(e[r]);return[n,t.map(t=>e[t])]},yn=(e,t)=>{const n=e.length+t.length,i=[];let r=0;for(let s=0;s<n;s++)-1===t.indexOf(s)?i.push(e[r++]):i.push(1);return i},$n=(e,t)=>{for(let n=0;n<e.length;++n)if(e[e.length-n-1]!==t-1-n)return!1;return!0},bn=(e,t)=>{const n=[];if(!$n(e,t)){for(let i=0;i<t;++i)-1===e.indexOf(i)&&n.push(i);e.forEach(e=>n.push(e))}return n},vn=(e,t,n,i,r,s,a)=>{const o=n[0].dims,u=dt.size(s),d=dt.size(a),l=Xt("_A",n[0].dataType,o),p=Yt("output",r,s);let c=64;1===u&&(c=256);const h=`\n          var<workgroup> aBestValues : array<f32, ${c}>;\n       `;return{name:e,shaderCache:{hint:`${t};${c}`,inputDependencies:["type"]},getShaderSource:e=>`\n        ${e.registerUniform("reduceSize","u32").declareVariables(l,p)}\n        ${h}\n        fn DIV_CEIL(a : u32, b : u32) -> u32 {\n          return ((a - 1u) / b + 1u);\n         }\n         ${e.mainStart(c)}\n\n          let outputIndex = global_idx / ${c};\n          let offset = outputIndex * uniforms.reduceSize;\n\n          var bestValue = f32(${mn[i]});\n          let Length = uniforms.reduceSize;\n          for (var k = local_idx; k < Length; k = k + ${c}) {\n           let candidate = f32(${l.getByOffset("offset + k")});\n           bestValue = ${hn[i]};\n          }\n          aBestValues[local_idx] = bestValue;\n          workgroupBarrier();\n\n         var reduceSize = min(Length, ${c}u);\n         for (var currentSize = reduceSize / 2u; reduceSize > 1u;\n             currentSize = reduceSize / 2u) {\n           let interval = DIV_CEIL(reduceSize, 2u);\n           if (local_idx < currentSize) {\n            let candidate = aBestValues[local_idx + interval];\n            bestValue = ${fn[i]};\n            aBestValues[local_idx] = bestValue;\n           }\n           reduceSize = interval;\n           workgroupBarrier();\n         }\n\n         if (local_idx == 0u) {\n          ${p.setByOffset("outputIndex","mean"===i?`${p.type.storage}(bestValue / f32(uniforms.reduceSize))`:`${p.type.storage}(${gn[i]})`)};\n         }\n        }`,getRunData:()=>({outputs:[{dims:s,dataType:r}],dispatchGroup:{x:u},programUniforms:[{type:12,data:d}]})}},xn=(e,t,n,i)=>{const r=1===e.inputs.length?n:Un(e.inputs,n);let s=r.axes;0!==s.length||r.noopWithEmptyAxes||(s=e.inputs[0].dims.map((e,t)=>t));const a=dt.normalizeAxes(s,e.inputs[0].dims.length);let o=a,u=e.inputs[0];const d=bn(o,e.inputs[0].dims.length);d.length>0&&(u=e.compute(ln(e.inputs[0],d),{inputs:[0],outputs:[-1]})[0],o=_n(o.length,u.dims.length));const[l,p]=wn(u.dims,o);let c=l;r.keepDims&&(c=yn(l,a)),e.compute(vn(t,r.cacheKey,[u],i,e.inputs[0].dataType,c,p),{inputs:[u]})},kn=(e,t)=>{xn(e,"ReduceMeanShared",t,"mean")},Sn=(e,t)=>{xn(e,"ReduceL1Shared",t,"l1")},In=(e,t)=>{xn(e,"ReduceL2Shared",t,"l2")},Tn=(e,t)=>{xn(e,"ReduceLogSumExpShared",t,"logSumExp")},zn=(e,t)=>{xn(e,"ReduceMaxShared",t,"max")},En=(e,t)=>{xn(e,"ReduceMinShared",t,"min")},Cn=(e,t)=>{xn(e,"ReduceProdShared",t,"prod")},On=(e,t)=>{xn(e,"ReduceSumShared",t,"sum")},An=(e,t)=>{xn(e,"ReduceSumSquareShared",t,"sumSquare")},Bn=(e,t)=>{xn(e,"ReduceLogSumShared",t,"logSum")}}}),_d=P({"web/lib/wasm/jsep/webgpu/ops/reduce.ts"(){rd(),od(),hd(),fd(),gd(),Rn=e=>{if(!e||0===e.length||e.length>2)throw new Error("Reduce op requires 1 or 2 inputs.");if(2===e.length&&1!==e[1].dims.length)throw new Error("Invalid axes input dims.")},Dn=e=>["","",`var value = ${e.getByIndices("input_indices")};`,""],Mn=(e,t,n,i,r,s,a=!1,o=!1)=>{const u=[],d=n[0].dims,l=d.length,p=dt.normalizeAxes(r,l),c=!o&&0===p.length;d.forEach((e,t)=>{c||p.indexOf(t)>=0?a&&u.push(1):u.push(e)});const h=u.length,f=dt.size(u);return{name:e,shaderCache:t,getShaderSource:e=>{const t=[],r=Xt("_A",n[0].dataType,l),o=Yt("output",s,h),u=i(r,o,p);let f=u[2];for(let e=0,n=0;e<l;e++)c||p.indexOf(e)>=0?(a&&n++,f=`for(var j${e}: u32 = 0; j${e} < ${d[e]}; j${e}++) {\n                  ${u[2].includes("last_index")?`let last_index = j${e};`:""}\n                  ${r.indicesSet("input_indices",e,`j${e}`)}\n                  ${f}\n                }`):(t.push(`${r.indicesSet("input_indices",e,o.indicesGet("output_indices",n))};`),n++);return`\n\n        ${e.registerUniform("output_size","u32").declareVariables(r,o)}\n\n        ${e.mainStart()}\n          ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n          var input_indices: ${r.type.indices};\n          let output_indices = ${o.offsetToIndices("global_idx")};\n\n          ${t.join("\n")}\n          ${u[0]}       // init ops for reduce max/min\n          ${u[1]}\n          ${f}\n          ${u[3]}\n          ${4===u.length?o.setByOffset("global_idx","value"):u.slice(4).join("\n")}\n        }`},getRunData:()=>({outputs:[{dims:u,dataType:s}],dispatchGroup:{x:Math.ceil(f/64)},programUniforms:[{type:12,data:f},...Wt(d,u)]})}},Un=(e,t)=>{const n=[];return e[1].dims[0]>0&&e[1].getBigInt64Array().forEach(e=>n.push(Number(e))),qt({axes:n,keepDims:t.keepDims,noopWithEmptyAxes:t.noopWithEmptyAxes})},Pn=(e,t,n,i)=>{const r=e.inputs,s=1===r.length?n:Un(r,n);e.compute(Mn(t,{hint:s.cacheKey,inputDependencies:["rank"]},[r[0]],s.noopWithEmptyAxes&&0===s.axes.length?Dn:i,s.axes,r[0].dataType,s.keepDims,s.noopWithEmptyAxes),{inputs:[0]})},qn=(e,t)=>{Rn(e.inputs),Pn(e,"ReduceLogSum",t,(e,t)=>[`var value = ${t.type.storage}(0);`,"",`value += ${e.getByIndices("input_indices")};`,"value = log(value);"])},Nn=(e,t)=>{Rn(e.inputs),Pn(e,"ReduceL1",t,(e,t)=>[`var value = ${t.type.storage}(0);`,"",`value += abs(${e.getByIndices("input_indices")});`,""])},Vn=(e,t)=>{Rn(e.inputs),Pn(e,"ReduceL2",t,(e,t)=>[`var t = ${t.type.value}(0); var value = ${t.type.value}(0);`,"",`t = ${e.getByIndices("input_indices")}; value += (t * t);`,"value = sqrt(value);"])},Ln=(e,t)=>{Rn(e.inputs),Pn(e,"ReduceLogSumExp",t,(e,t)=>[`var value = ${t.type.storage}(0);`,"",`value += exp(${e.getByIndices("input_indices")});`,"value = log(value);"])},Gn=(e,t)=>{Rn(e.inputs),Pn(e,"ReduceMax",t,(e,t,n)=>{const i=[];for(let t=0;t<e.rank;t++)(n.indexOf(t)>=0||0===n.length)&&i.push(e.indicesSet("input_indices",t,0));return[`${i.join("\n")}`,`var value = ${e.getByIndices("input_indices")};`,`value = max(value, ${e.getByIndices("input_indices")});`,""]})},Wn=(e,t)=>{Rn(e.inputs),Pn(e,"ReduceMean",t,(t,n,i)=>{let r=1;for(let n=0;n<t.rank;n++)(i.indexOf(n)>=0||0===i.length)&&(r*=e.inputs[0].dims[n]);return["var sum = f32(0);","",`sum += f32(${t.getByIndices("input_indices")});`,`let value = ${n.type.value}(sum / ${r});`]})},jn=(e,t)=>{Rn(e.inputs),Pn(e,"ReduceMin",t,(e,t,n)=>{const i=[];for(let t=0;t<e.rank;t++)(n.indexOf(t)>=0||0===n.length)&&i.push(`input_indices[${t}] = 0;`);return[`${i.join("\n")}`,`var value = ${e.getByIndices("input_indices")};`,`value = min(value, ${e.getByIndices("input_indices")});`,""]})},Hn=(e,t)=>{Rn(e.inputs),Pn(e,"ReduceProd",t,(e,t)=>[`var value = ${t.type.storage}(1);`,"",`value *= ${e.getByIndices("input_indices")};`,""])},Fn=(e,t)=>{Rn(e.inputs),Pn(e,"ReduceSum",t,(e,t)=>[`var value = ${t.type.storage}(0);`,"",`value += ${e.getByIndices("input_indices")};`,""])},Kn=(e,t)=>{Rn(e.inputs),Pn(e,"ReduceSumSquare",t,(e,t)=>[`var t = ${t.type.value}(0); var value = ${t.type.value}(0);`,"",`t = ${e.getByIndices("input_indices")}; value += t * t;`,""])},Zn=(e,t,n)=>{if(0===t.length)return n;let i=1,r=1;for(let n=0;n<t.length;n++)-1===t.indexOf(n)?i*=e[n]:r*=e[n];return r<32&&i>1024},Qn=(e,t)=>{Zn(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Wn(e,t):kn(e,t)},Xn=(e,t)=>{Zn(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Nn(e,t):Sn(e,t)},Yn=(e,t)=>{Zn(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Vn(e,t):In(e,t)},Jn=(e,t)=>{Zn(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Ln(e,t):Tn(e,t)},ei=(e,t)=>{Zn(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Gn(e,t):zn(e,t)},ti=(e,t)=>{Zn(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?jn(e,t):En(e,t)},ni=(e,t)=>{Zn(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Hn(e,t):Cn(e,t)},ii=(e,t)=>{Zn(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Fn(e,t):On(e,t)},ri=(e,t)=>{Zn(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?Kn(e,t):An(e,t)},si=(e,t)=>{Zn(e.inputs[0].dims,t.axes,t.noopWithEmptyAxes)?qn(e,t):Bn(e,t)}}}),wd=P({"web/lib/wasm/jsep/webgpu/ops/argminmax.ts"(){rd(),hd(),_d(),ai=e=>{if(!e||0===e.length||e.length>2)throw new Error("ArgMinMaxOp op requires 1 or 2 inputs.");if(1!==e[0].dataType)throw new Error("Invalid input type.")},oi=(e,t)=>{ai(e.inputs),e.compute(Mn("ArgMin",{hint:t.cacheKey,inputDependencies:["rank"]},[e.inputs[0]],(e,n,i)=>{const r=[];for(let t=0;t<e.rank;t++)(i.indexOf(t)>=0||0===i.length)&&r.push(`input_indices[${t}] = 0;`);return[`${r.join("\n")}`,`var value = ${e.getByIndices("input_indices")};\nvar best_index : i32 = 0;`,`if (${e.getByIndices("input_indices")} ${t.selectLastIndex>0?"<=":"<"} value) {\n         value = ${e.getByIndices("input_indices")};\n         best_index = i32(last_index);\n       }`,"",n.setByOffset("global_idx","best_index")]},[t.axis],7,t.keepDims),{inputs:[0]})},ui=(e,t)=>{ai(e.inputs),e.compute(Mn("argMax",{hint:t.cacheKey,inputDependencies:["rank"]},[e.inputs[0]],(e,n,i)=>{const r=[];for(let t=0;t<e.rank;t++)(i.indexOf(t)>=0||0===i.length)&&r.push(`input_indices[${t}] = 0;`);return[`${r.join("\n")}`,`var value = ${e.getByIndices("input_indices")};\nvar best_index : i32 = 0;`,`if (${e.getByIndices("input_indices")} ${t.selectLastIndex>0?">=":">"} value) {\n         value = ${e.getByIndices("input_indices")};\n         best_index = i32(last_index);\n       }`,"",n.setByOffset("global_idx","best_index")]},[t.axis],7,t.keepDims),{inputs:[0]})},di=e=>qt(e)}}),yd=P({"web/lib/wasm/jsep/webgpu/ops/attention.ts"(){rd(),od(),pd(),fd(),li=(e,t)=>{const n=e[0],i=e[1],r=e[2],s=e[3],a=e[4],o=e[5];if(a&&o)throw new Error("Attention cannot have both past and attention_bias");if(3!==n.dims.length)throw new Error('Input "input" must have 3 dimensions');const u=n.dims[0],d=n.dims[1],l=n.dims[2];if(1!==r.dims.length)throw new Error('Input "bias" is expected to have 1 dimensions');if(2!==i.dims.length)throw new Error('Input "weights" is expected to have 2 dimensions');if(i.dims[0]!==l)throw new Error("Input 1 dimension 0 should have same length as dimension 2 of input 0");if(r.dims[0]!==i.dims[1])throw new Error('Input "bias" dimension 0 should have same length as dimension 1 of input "weights"');let p=r.dims[0]/3,c=p,h=c;if(t.qkvHiddenSizes.length>0){if(3!==t.qkvHiddenSizes.length)throw new Error("qkv_hidden_sizes attribute should have 3 elements");for(const e of t.qkvHiddenSizes)if(e%t.numHeads!==0)throw new Error("qkv_hidden_sizes should be divisible by num_heads");p=t.qkvHiddenSizes[0],c=t.qkvHiddenSizes[1],h=t.qkvHiddenSizes[2]}const f=d;if(p!==c)throw new Error("qkv_hidden_sizes first element should be same as the second");if(r.dims[0]!==p+c+h)throw new Error('Input "bias" dimension 0 should have same length as sum of Q/K/V hidden sizes');let m=0;if(a){if(c!==h)throw new Error('Input "past" expect k_hidden_size == v_hidden_size');if(5!==a.dims.length)throw new Error('Input "past" must have 5 dimensions');if(2!==a.dims[0])throw new Error('Input "past" first dimension must be 2');if(a.dims[1]!==u)throw new Error('Input "past" second dimension must be batch_size');if(a.dims[2]!==t.numHeads)throw new Error('Input "past" third dimension must be num_heads');if(a.dims[4]!==c/t.numHeads)throw new Error('Input "past" fifth dimension must be k_hidden_size / num_heads');t.pastPresentShareBuffer||(m=a.dims[3])}const g=f+m;if(s)throw new Error("Mask not supported");if(a)throw new Error("past is not supported");if(o){if(4!==o.dims.length)throw new Error('Input "attention_bias" must have 4 dimensions');if(o.dims[0]!==u||o.dims[1]!==t.numHeads||o.dims[2]!==d||o.dims[3]!==g)throw new Error('Expect "attention_bias" shape (batch_size, num_heads, sequence_length, total_sequence_length)')}return{batchSize:u,sequenceLength:d,pastSequenceLength:m,kvSequenceLength:f,totalSequenceLength:g,maxSequenceLength:-1,inputHiddenSize:l,hiddenSize:p,vHiddenSize:h,headSize:Math.floor(p/t.numHeads),vHeadSize:Math.floor(h/t.numHeads),numHeads:t.numHeads,isUnidirectional:!1,pastPresentShareBuffer:!1,maskFilterValue:t.maskFilterValue,maskType:0,scale:t.scale,broadcastResPosBias:!1,passPastInKv:!1,qkvFormat:1}},pi=(e,t,n)=>t&&e?`\n      let total_sequence_length_input = u32(${t.getByOffset("0")});\n      let present_sequence_length = max(total_sequence_length_input, uniforms.past_sequence_length);\n      let is_subsequent_prompt: bool = sequence_length > 1 && sequence_length != total_sequence_length_input;\n      let is_first_prompt: bool = is_subsequent_prompt == false && sequence_length == total_sequence_length_input;\n      total_sequence_length = u32(${e?.getByOffset("batchIdx")}) + 1;\n      var past_sequence_length: u32 = 0;\n      if (is_first_prompt == false) {\n        past_sequence_length = total_sequence_length - sequence_length;\n      }\n       `:`\n    ${n?"let past_sequence_length = uniforms.past_sequence_length":""};\n    let present_sequence_length = total_sequence_length;\n    `,ci=(e,t,n,i,r,s,a,o)=>{const u=jt(a?1:s);let d=64;const l=s/u;l<d&&(d=32);const p=Math.ceil(s/u/d),c=[{type:12,data:t},{type:12,data:n},{type:12,data:i},{type:12,data:r},{type:12,data:l},{type:12,data:p}],h=Lt(e.dataType,u),f=Gt(1,u),m=["type"];return a&&m.push("type"),o&&m.push("type"),{name:"AttentionProbsSoftmax",shaderCache:{hint:`${d};${h};${u}`,inputDependencies:m},getShaderSource:t=>{const n=Yt("x",e.dataType,e.dims,u),i=[n],r=a?Xt("seq_lens",a.dataType,a.dims):void 0;r&&i.push(r);const s=o?Xt("total_sequence_length_input",o.dataType,o.dims):void 0;s&&i.push(s);const l=Gt(e.dataType);return`\n  var<workgroup> thread_max: array<f32, ${d}>;\n  var<workgroup> thread_sum: array<f32, ${d}>;\n  ${t.registerUniforms([{name:"batch_size",type:"u32"},{name:"num_heads",type:"u32"},{name:"past_sequence_length",type:"u32"},{name:"sequence_length",type:"u32"},{name:"total_sequence_length",type:"u32"},{name:"elements_per_thread",type:"u32"}]).declareVariables(...i)}\n  ${t.mainStart([d,1,1])}\n    let batchIdx = workgroup_id.z / uniforms.num_heads;\n    let headIdx = workgroup_id.z % uniforms.num_heads;\n    let sequence_length = uniforms.sequence_length;\n    var total_sequence_length = uniforms.total_sequence_length;\n    ${pi(r,s,!1)}\n    let local_offset = local_idx * uniforms.elements_per_thread;\n    let offset = (global_idx / ${d}) * uniforms.total_sequence_length + local_offset;\n    let seq_causal_length = ${a?"u32(past_sequence_length + workgroup_id.y + 1)":"total_sequence_length"};\n    var thread_max_vector = ${f}(-3.402823e+38f);\n    for (var i: u32 = 0; i < uniforms.elements_per_thread && i + local_offset < seq_causal_length; i++) {\n      thread_max_vector = max(${f}(x[offset + i]), thread_max_vector);\n    }\n    thread_max[local_idx] = ${(()=>{switch(u){case 1:return"thread_max_vector";case 2:return"max(thread_max_vector.x, thread_max_vector.y)";case 4:return"max(max(thread_max_vector.x, thread_max_vector.y), max(thread_max_vector.z, thread_max_vector.w))";default:throw new Error(`Unsupported components: ${u}`)}})()};\n    workgroupBarrier();\n\n    var max_value =  f32(-3.402823e+38f);\n    for (var i = 0u; i < ${d}; i++) {\n      max_value = max(thread_max[i], max_value);\n    }\n\n    var sum_vector = ${f}(0);\n    for (var i: u32 = 0; i < uniforms.elements_per_thread && i + local_offset < seq_causal_length; i++) {\n      sum_vector += exp(${f}(x[offset + i]) - max_value);\n    }\n    thread_sum[local_idx] = ${(()=>{switch(u){case 1:return"sum_vector";case 2:return"sum_vector.x + sum_vector.y";case 4:return"sum_vector.x + sum_vector.y + sum_vector.z + sum_vector.w";default:throw new Error(`Unsupported components: ${u}`)}})()};\n    workgroupBarrier();\n\n    var sum: f32 = 0;\n    for (var i = 0u; i < ${d}; i++) {\n      sum += thread_sum[i];\n    }\n\n    if (sum == 0) {\n      for (var i: u32 = 0; i < uniforms.elements_per_thread && i + local_offset < seq_causal_length; i++) {\n        x[offset + i] = ${n.type.value}(${l}(1.0) / ${l}(seq_causal_length));\n      }\n    } else {\n      for (var i: u32 = 0; i < uniforms.elements_per_thread && i + local_offset < seq_causal_length; i++) {\n        var f32input = ${f}(x[offset + i]);\n        x[offset + i] = ${n.type.value}(exp(f32input - max_value) / sum);\n      }\n    }\n      ${a?`\n        for (var total_seq_id: u32 = seq_causal_length; total_seq_id + local_offset < uniforms.total_sequence_length; total_seq_id++) {\n          x[offset + total_seq_id] = ${n.type.value}(${l}(0));\n        }`:""};\n  }`},getRunData:()=>({outputs:[],dispatchGroup:{x:1,y:r,z:t*n},programUniforms:c})}},hi=(e,t,n,i,r,s,a,o,u)=>{const d=a+s.kvSequenceLength,l=[s.batchSize,s.numHeads,s.sequenceLength,d],p=e>1&&i,c=s.kvNumHeads?s.kvNumHeads:s.numHeads,h=p?[s.batchSize,c,d,s.headSize]:void 0,f=s.nReps?s.nReps:1,m=0===s.scale?1/Math.sqrt(s.headSize):s.scale,g=jt(s.headSize),_=s.headSize/g,w={x:Math.ceil(d/12),y:Math.ceil(s.sequenceLength/12),z:s.batchSize*s.numHeads},y=[{type:12,data:s.sequenceLength},{type:12,data:_},{type:12,data:d},{type:12,data:s.numHeads},{type:12,data:s.headSize},{type:1,data:m},{type:12,data:a},{type:12,data:s.kvSequenceLength},{type:12,data:f}],$=p&&i&&dt.size(i.dims)>0,b=["type","type"];$&&b.push("type"),r&&b.push("type"),o&&b.push("type"),u&&b.push("type");const v=[{dims:l,dataType:t.dataType,gpuDataType:0}];return p&&v.push({dims:h,dataType:t.dataType,gpuDataType:0}),{name:"AttentionProbs",shaderCache:{hint:`${g};${void 0!==r};${void 0!==i};${e}`,inputDependencies:b},getRunData:()=>({outputs:v,dispatchGroup:w,programUniforms:y}),getShaderSource:e=>{const s=Xt("q",t.dataType,t.dims,g),a=[s,Xt("key",n.dataType,n.dims,g)];if($){const e=Xt("past_key",i.dataType,i.dims,g);a.push(e)}r&&a.push(Xt("attention_bias",r.dataType,r.dims));const d=o?Xt("seq_lens",o.dataType,o.dims):void 0;d&&a.push(d);const c=u?Xt("total_sequence_length_input",u.dataType,u.dims):void 0;c&&a.push(c);const m=Yt("output",t.dataType,l),_=[m];p&&_.push(Yt("present_key",t.dataType,h,g));const w=Gt(1,g);return`\n  const TILE_SIZE = 12u;\n\n  var<workgroup> tileQ: array<${s.type.storage}, 144>;\n  var<workgroup> tileK: array<${s.type.storage}, 144>;\n  ${e.registerUniforms([{name:"M",type:"u32"},{name:"K",type:"u32"},{name:"N",type:"u32"},{name:"num_heads",type:"u32"},{name:"head_size",type:"u32"},{name:"alpha",type:"f32"},{name:"past_sequence_length",type:"u32"},{name:"kv_sequence_length",type:"u32"},{name:"n_reps",type:"u32"}]).declareVariables(...a,..._)}\n  ${e.mainStart([12,12,1])}\n    // x holds the N and y holds the M\n    let headIdx = workgroup_id.z % uniforms.num_heads;\n    let kvHeadIdx = ${1===f?"headIdx":"headIdx / uniforms.n_reps"};\n    let kv_num_heads = ${1===f?"uniforms.num_heads":"uniforms.num_heads / uniforms.n_reps"};\n    let batchIdx = workgroup_id.z / uniforms.num_heads;\n    let m = workgroup_id.y * TILE_SIZE;\n    let n = workgroup_id.x * TILE_SIZE;\n    let sequence_length = uniforms.M;\n    var total_sequence_length = uniforms.N;\n    ${pi(d,c,!0)}\n    let absKvHeadIdx = batchIdx * kv_num_heads + kvHeadIdx;\n    let qOffset = workgroup_id.z * uniforms.M * uniforms.K + m * uniforms.K;\n    ${$&&p?"let pastKeyOffset = absKvHeadIdx * uniforms.past_sequence_length * uniforms.K;":""};\n    let kOffset = absKvHeadIdx * uniforms.kv_sequence_length * uniforms.K;\n    ${p?"let presentKeyOffset = absKvHeadIdx * uniforms.N * uniforms.K;":""}\n    var value = ${w}(0);\n    for (var w: u32 = 0u; w < uniforms.K; w += TILE_SIZE) {\n      if (global_id.y < uniforms.M && w + local_id.x < uniforms.K) {\n        tileQ[TILE_SIZE * local_id.y + local_id.x] = q[qOffset + local_id.y * uniforms.K + w + local_id.x];\n      }\n      if (n + local_id.y < uniforms.N && w + local_id.x < uniforms.K) {\n        var idx = TILE_SIZE * local_id.y + local_id.x;\n      ${$&&p?"\n              if (n + local_id.y < past_sequence_length) {\n                tileK[idx] = past_key[pastKeyOffset + (n + local_id.y) * uniforms.K + w + local_id.x];\n              } else if (n + local_id.y - past_sequence_length < uniforms.kv_sequence_length) {\n                tileK[idx] = key[kOffset + (n + local_id.y - past_sequence_length) * uniforms.K + w + local_id.x];\n              }":"\n          if (n + local_id.y < uniforms.kv_sequence_length) {\n            tileK[idx] = key[kOffset + (n + local_id.y) * uniforms.K + w + local_id.x];\n          }"}\n      ${p?"if (n + local_id.y < present_sequence_length) {\n        present_key[presentKeyOffset + (n + local_id.y) * uniforms.K + w + local_id.x] = tileK[idx];\n      }":""}\n      }\n      workgroupBarrier();\n\n      for (var k: u32 = 0u; k < TILE_SIZE && w+k < uniforms.K; k++) {\n          value += ${w}(tileQ[TILE_SIZE * local_id.y + k] * tileK[TILE_SIZE * local_id.x + k]);\n      }\n\n      workgroupBarrier();\n    }\n\n    if (global_id.y < uniforms.M && global_id.x < total_sequence_length) {\n      let headOffset = workgroup_id.z * uniforms.M * uniforms.N;\n      let outputIdx = headOffset + global_id.y * uniforms.N + global_id.x;\n      var sum: f32 = ${(()=>{switch(g){case 1:return"value";case 2:return"value.x + value.y";case 4:return"value.x + value.y + value.z + value.w";default:throw new Error(`Unsupported components: ${g}`)}})()};\n        output[outputIdx] = ${m.type.value} (sum * uniforms.alpha) + ${r?"attention_bias[outputIdx]":"0.0"};\n    }\n  }`}}},fi=(e,t,n,i,r,s,a=void 0,o=void 0)=>{const u=s+r.kvSequenceLength,d=r.nReps?r.nReps:1,l=r.vHiddenSize*d,p=e>1&&i,c=r.kvNumHeads?r.kvNumHeads:r.numHeads,h=p?[r.batchSize,c,u,r.headSize]:void 0,f=[r.batchSize,r.sequenceLength,l],m={x:Math.ceil(r.vHeadSize/12),y:Math.ceil(r.sequenceLength/12),z:r.batchSize*r.numHeads},g=[{type:12,data:r.sequenceLength},{type:12,data:u},{type:12,data:r.vHeadSize},{type:12,data:r.numHeads},{type:12,data:r.headSize},{type:12,data:l},{type:12,data:s},{type:12,data:r.kvSequenceLength},{type:12,data:d}],_=p&&i&&dt.size(i.dims)>0,w=["type","type"];_&&w.push("type"),a&&w.push("type"),o&&w.push("type");const y=[{dims:f,dataType:t.dataType,gpuDataType:0}];return p&&y.push({dims:h,dataType:t.dataType,gpuDataType:0}),{name:"AttentionScore",shaderCache:{hint:`${void 0!==i};${e}`,inputDependencies:w},getRunData:()=>({outputs:y,dispatchGroup:m,programUniforms:g}),getShaderSource:e=>{const r=Xt("probs",t.dataType,t.dims),s=[r,Xt("v",n.dataType,n.dims)];_&&s.push(Xt("past_value",i.dataType,i.dims));const u=a?Xt("seq_lens",a.dataType,a.dims):void 0;a&&s.push(u);const l=o?Xt("total_sequence_length_input",o.dataType,o.dims):void 0;o&&s.push(l);const c=[Yt("output",t.dataType,f)];return p&&c.push(Yt("present_value",t.dataType,h)),`\n  const TILE_SIZE = 12u;\n  var<workgroup> tileQ: array<${r.type.value}, 144>;\n  var<workgroup> tileV: array<${r.type.value}, 144>;\n  ${e.registerUniforms([{name:"M",type:"u32"},{name:"K",type:"u32"},{name:"N",type:"u32"},{name:"num_heads",type:"u32"},{name:"head_size",type:"u32"},{name:"v_hidden_size",type:"u32"},{name:"past_sequence_length",type:"u32"},{name:"kv_sequence_length",type:"u32"},{name:"n_reps",type:"u32"}]).declareVariables(...s,...c)}\n  ${e.mainStart([12,12,1])}\n   let headIdx = workgroup_id.z % uniforms.num_heads;\n   let batchIdx = workgroup_id.z / uniforms.num_heads;\n   let kvHeadIdx = ${1===d?"headIdx":"headIdx / uniforms.n_reps"};\n   let kv_num_heads = ${1===d?"uniforms.num_heads":"uniforms.num_heads / uniforms.n_reps"};\n   let m = global_id.y;\n   let n = global_id.x;\n   let sequence_length = uniforms.M;\n   var total_sequence_length = uniforms.K;\n   ${pi(u,l,!0)}\n   let offsetA = workgroup_id.z * uniforms.M * uniforms.K + m * uniforms.K;\n   let absKvHeadIdx = batchIdx * kv_num_heads + kvHeadIdx; // kvHeadIdx is relative to the batch\n   ${_&&p?"let pastValueOffset = absKvHeadIdx * uniforms.N * uniforms.past_sequence_length + n;":""};\n   let vOffset = absKvHeadIdx * uniforms.N * uniforms.kv_sequence_length + n;\n   ${p?"let presentValueOffset = absKvHeadIdx * uniforms.N * uniforms.K + n;":""}\n   var value = ${r.type.storage}(0);\n   for (var w: u32 = 0u; w < uniforms.K; w += TILE_SIZE) {\n      if (m < uniforms.M && w + local_id.x < uniforms.K) {\n        tileQ[TILE_SIZE * local_id.y + local_id.x] = probs[offsetA + w + local_id.x];\n      }\n      if (n < uniforms.N && w + local_id.y < uniforms.K) {\n        var idx = TILE_SIZE * local_id.y + local_id.x;\n        ${_&&p?"\n        if (w + local_id.y < past_sequence_length) {\n          tileV[idx] = past_value[pastValueOffset + (w + local_id.y) * uniforms.N];\n        } else if (w + local_id.y - past_sequence_length < uniforms.kv_sequence_length) {\n          tileV[idx] = v[vOffset + (w + local_id.y - past_sequence_length) * uniforms.N];\n        }\n      ":"\n            if (w + local_id.y < uniforms.kv_sequence_length) {\n              tileV[idx] = v[vOffset + (w + local_id.y) * uniforms.N];\n            }"}\n        ${p?"\n            if (w + local_id.y < present_sequence_length) {\n          present_value[presentValueOffset + (w + local_id.y) * uniforms.N] = tileV[idx];\n        }":""}\n      }\n     workgroupBarrier();\n     for (var k: u32 = 0u; k < TILE_SIZE && w+k < total_sequence_length; k++) {\n       value += tileQ[TILE_SIZE * local_id.y + k] * tileV[TILE_SIZE * k + local_id.x];\n     }\n     workgroupBarrier();\n   }\n\n   // we need to transpose output from BNSH_v to BSND_v\n   if (m < uniforms.M && n < uniforms.N) {\n     let outputIdx = batchIdx * uniforms.M * uniforms.v_hidden_size + m * uniforms.v_hidden_size\n       + headIdx * uniforms.N + n;\n     output[outputIdx] = value;\n   }\n  }`}}},mi=(e,t,n,i,r,s,a,o,u,d,l=void 0,p=void 0)=>{const c=Math.min(e.outputCount,1+(a?1:0)+(o?1:0)),h=c>1?d.pastSequenceLength:0,f=h+d.kvSequenceLength,m=u&&dt.size(u.dims)>0?u:void 0,g=[t,n];c>1&&a&&dt.size(a.dims)>0&&g.push(a),m&&g.push(m),l&&g.push(l),p&&g.push(p);const _=e.compute(hi(c,t,n,a,m,d,h,l,p),{inputs:g,outputs:c>1?[-1,1]:[-1]})[0];e.compute(ci(_,d.batchSize,d.numHeads,h,d.sequenceLength,f,l,p),{inputs:l&&p?[_,l,p]:[_],outputs:[]});const w=[_,i];c>1&&o&&dt.size(o.dims)>0&&w.push(o),l&&w.push(l),p&&w.push(p),e.compute(fi(c,_,i,o,d,h,l,p),{inputs:w,outputs:c>1?[0,2]:[0]})},gi=(e,t)=>{const n=[t.batchSize,t.numHeads,t.sequenceLength,t.headSize],i=t.sequenceLength,r=t.inputHiddenSize,s=t.headSize,a={x:Math.ceil(t.headSize/12),y:Math.ceil(t.sequenceLength/12),z:t.batchSize*t.numHeads},o=[e.inputs[0],e.inputs[1],e.inputs[2]],u=[{type:12,data:i},{type:12,data:r},{type:12,data:s},{type:12,data:t.numHeads},{type:12,data:t.headSize},{type:12,data:t.hiddenSize},{type:12,data:t.hiddenSize+t.hiddenSize+t.vHiddenSize}];return e.compute({name:"AttentionPrepare",shaderCache:{inputDependencies:["type","type","type"]},getRunData:()=>({outputs:[{dims:n,dataType:e.inputs[0].dataType,gpuDataType:0},{dims:n,dataType:e.inputs[0].dataType,gpuDataType:0},{dims:n,dataType:e.inputs[0].dataType,gpuDataType:0}],dispatchGroup:a,programUniforms:u}),getShaderSource:e=>{const t=Yt("output_q",o[0].dataType,n),i=Yt("output_k",o[0].dataType,n),r=Yt("output_v",o[0].dataType,n),s=Xt("input",o[0].dataType,o[0].dims),a=Xt("weight",o[1].dataType,o[1].dims),u=Xt("bias",o[2].dataType,o[2].dims),d=s.type.storage;return`\n  const TILE_SIZE = 12u;\n  var<workgroup> tileInput: array<${d}, 144>;\n  var<workgroup> tileWeightQ: array<${d}, 144>;\n  var<workgroup> tileWeightK: array<${d}, 144>;\n  var<workgroup> tileWeightV: array<${d}, 144>;\n  ${e.registerUniforms([{name:"M",type:"u32"},{name:"K",type:"u32"},{name:"N",type:"u32"},{name:"num_heads",type:"u32"},{name:"head_size",type:"u32"},{name:"hidden_size",type:"u32"},{name:"ldb",type:"u32"}]).declareVariables(s,a,u,t,i,r)}\n  ${e.mainStart([12,12,1])}\n    let batchIndex = workgroup_id.z / uniforms.num_heads;\n    let headNumber = workgroup_id.z % uniforms.num_heads;\n    let m = global_id.y;\n    let n = global_id.x;\n\n    let inputOffset = batchIndex * (uniforms.M * uniforms.K) + m * uniforms.K;\n    let biasOffsetQ = headNumber * uniforms.head_size;\n    let biasOffsetK = uniforms.hidden_size + biasOffsetQ;\n    let biasOffsetV = uniforms.hidden_size + biasOffsetK;\n\n    var valueQ = ${d}(0);\n    var valueK = ${d}(0);\n    var valueV = ${d}(0);\n    for (var w: u32 = 0u; w < uniforms.K; w += TILE_SIZE) {\n      if (m < uniforms.M && w + local_id.x < uniforms.K) {\n        tileInput[TILE_SIZE * local_id.y + local_id.x] = input[inputOffset + w + local_id.x];\n      }\n      if (n < uniforms.N && w + local_id.y < uniforms.K) {\n        let offset = n + (w + local_id.y) * uniforms.ldb;\n        tileWeightQ[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetQ + offset];\n        tileWeightK[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetK + offset];\n        tileWeightV[TILE_SIZE * local_id.y + local_id.x] = weight[biasOffsetV + offset];\n      }\n      workgroupBarrier();\n      for (var k: u32 = 0u; k<TILE_SIZE && w+k < uniforms.K; k++) {\n        let inputTileOffset = TILE_SIZE * local_id.y + k;\n        let weightTileOffset = TILE_SIZE * k + local_id.x;\n        valueQ += tileInput[inputTileOffset] * tileWeightQ[weightTileOffset];\n        valueK += tileInput[inputTileOffset] * tileWeightK[weightTileOffset];\n        valueV += tileInput[inputTileOffset] * tileWeightV[weightTileOffset];\n      }\n\n      workgroupBarrier();\n    }\n\n    let headOffset = (m * uniforms.N + n) % uniforms.head_size;\n    valueQ += bias[headOffset + biasOffsetQ];\n    valueK += bias[headOffset + biasOffsetK];\n    valueV += bias[headOffset + biasOffsetV];\n\n    let offset = workgroup_id.z * uniforms.M * uniforms.N;\n    if (m < uniforms.M && n < uniforms.N) {\n      let outputIdx = offset + m * uniforms.N + n;\n      output_q[outputIdx] = valueQ;\n      output_k[outputIdx] = valueK;\n      output_v[outputIdx] = valueV;\n    }\n  }`}},{inputs:o,outputs:[-1,-1,-1]})},_i=(e,t)=>{const n=li(e.inputs,t),[i,r,s]=gi(e,n);return mi(e,i,r,s,e.inputs[4],void 0,void 0,void 0,e.inputs[5],n)}}}),$d=P({"web/lib/wasm/jsep/webgpu/ops/batch-norm.ts"(){le(),rd(),od(),hd(),fd(),wi=(e,t)=>{if(!e||5!==e.length)throw new Error("BatchNormalization requires 5 inputs");const n=(e,t,n)=>{const i=t.length;if(i!==e.length)throw new Error(`${n}: num dimensions != ${i}`);t.forEach((t,i)=>{if(t!==e[i])throw new Error(`${n}: dim[${i}] do not match`)})};if(e[0].dims.length>1){const i="NHWC"===t.format?t.spatial?e[0].dims.slice(-1):e[0].dims.slice(-1).concat(e[0].dims.slice(1,e[0].dims.length-1)):e[0].dims.slice(1,t.spatial?2:void 0);n(e[1].dims,i,"Invalid input scale"),n(e[2].dims,i,"Invalid input B"),n(e[3].dims,i,"Invalid input mean"),n(e[4].dims,i,"Invalid input var")}else n(e[1].dims,[1],"Invalid input scale"),n(e[2].dims,[1],"Invalid input B"),n(e[3].dims,[1],"Invalid input mean"),n(e[4].dims,[1],"Invalid input var")},yi=(e,t)=>{const{epsilon:n,spatial:i,format:r}=t,s=e[0].dims,a=i?jt(s[s.length-1]):1,o="NHWC"===r&&s.length>1?a:1,u=dt.size(s)/a,d=i,l=d?s.length:s,p=Xt("x",e[0].dataType,e[0].dims,a),c=Xt("scale",e[1].dataType,e[1].dims,o),h=Xt("bias",e[2].dataType,e[2].dims,o),f=Xt("inputMean",e[3].dataType,e[3].dims,o),m=Xt("inputVar",e[4].dataType,e[4].dims,o),g=Yt("y",e[0].dataType,l,a);return{name:"BatchNormalization",shaderCache:{hint:`${t.epsilon}_${t.format}_${i}_${a}`,inputDependencies:d?["rank","type","type","type","type"]:void 0},getShaderSource:e=>`\n  const epsilon = ${n};\n  ${e.registerUniform("outputSize","u32").declareVariables(p,c,h,f,m,g)}\n  ${e.mainStart()}\n  ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}\n    var outputIndices = ${g.offsetToIndices(`global_idx * ${a}`)};\n    ${(()=>{let e="";if(i)e=`let cOffset = ${1===s.length?"0u":"NHWC"===r?`outputIndices[${s.length-1}] / ${a}`:"outputIndices[1]"};`;else if("NCHW"===r)e=`\n            ${g.indicesSet("outputIndices","0","0")}\n            let cOffset = ${g.indicesToOffset("outputIndices")};`;else{e=`var cIndices = ${c.type.indices}(0);\n                       cIndices[0] = outputIndices[${s.length-1}];`;for(let t=1;t<c.rank;t++)e+=`cIndices[${t}] = outputIndices[${t}];`;e+=`let cOffset = ${c.indicesToOffset("cIndices")};`}return e})()}\n    let scale = ${c.getByOffset("cOffset")};\n    let bias = ${h.getByOffset("cOffset")};\n    let inputMean = ${f.getByOffset("cOffset")};\n    let inputVar = ${m.getByOffset("cOffset")};\n    let x = ${p.getByOffset("global_idx")};\n    let value = (x - inputMean) * inverseSqrt(inputVar + epsilon) * scale + bias;\n    ${g.setByOffset("global_idx","value")}\n  }`,getRunData:()=>({outputs:[{dims:e[0].dims,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(u/64)},programUniforms:d?[{type:12,data:u},...Wt(s)]:[{type:12,data:u}]})}},$i=e=>qt(e),bi=(e,t)=>{const{inputs:n,outputCount:i}=e,r=$i({...t,outputCount:i});if(u.webgpu.validateInputContent&&wi(n,r),t.trainingMode)throw new Error("BatchNormalization trainingMode is not supported yet.");e.compute(yi(n,r))}}}),bd=P({"web/lib/wasm/jsep/webgpu/ops/bias-add.ts"(){od(),fd(),vi=e=>{if(3!==e[0].dims.length)throw new Error("input should have 3 dimensions");if(![320,640,1280].includes(e[0].dims[2]))throw new Error("number of channels should be 320, 640 or 1280");if(1!==e[1].dims.length)throw new Error("bias is expected to have 1 dimensions");if(e[0].dims[2]!==e[1].dims[0])throw new Error("last dimension of input and bias are not the same")},xi=e=>{const t=e[0].dims,n=e[0].dims[2],i=dt.size(t)/4,r=e[0].dataType,s=Xt("input",r,t,4),a=Xt("bias",r,[n],4),o=Xt("residual",r,t,4),u=Yt("output",r,t,4);return{name:"BiasAdd",getRunData:()=>({outputs:[{dims:t,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(i/64)}}),getShaderSource:e=>`\n  const channels = ${n}u / 4;\n  ${e.declareVariables(s,a,o,u)}\n\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes(i)}\n    let value = ${s.getByOffset("global_idx")}\n      + ${a.getByOffset("global_idx % channels")} + ${o.getByOffset("global_idx")};\n    ${u.setByOffset("global_idx","value")}\n  }`}},ki=e=>{vi(e.inputs),e.compute(xi(e.inputs))}}}),vd=P({"web/lib/wasm/jsep/webgpu/ops/unary-op.ts"(){rd(),od(),hd(),fd(),Si=(e,t,n,i,r,s,a)=>{const o=Math.ceil(t/4);let u="";u="string"==typeof r?`${r}(a)`:r("a");const d=Xt("inputData",n,[o],4),l=Yt("outputData",i,[o],4),p=[{name:"vec_size",type:"u32"}];return a&&p.push(...a),`\n      ${e.registerUniforms(p).declareVariables(d,l)}\n\n  ${s??""}\n\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.vec_size")}\n\n    let a = ${d.getByOffset("global_idx")};\n    ${l.setByOffset("global_idx",u)}\n  }`},Ii=(e,t,n,i,r,s=e.dataType,a,o)=>{const u=[{type:12,data:Math.ceil(dt.size(e.dims)/4)}];return a&&u.push(...a),{name:t,shaderCache:{hint:r,inputDependencies:["type"]},getShaderSource:t=>Si(t,dt.size(e.dims),e.dataType,s,n,i,o),getRunData:t=>({outputs:[{dims:e.dims,dataType:s}],dispatchGroup:{x:Math.ceil(dt.size(t[0].dims)/64/4)},programUniforms:u})}},Ti=e=>{e.compute(Ii(e.inputs[0],"Abs","abs"))},zi=e=>{e.compute(Ii(e.inputs[0],"Acos","acos"))},Ei=e=>{e.compute(Ii(e.inputs[0],"Acosh","acosh"))},Ci=e=>{e.compute(Ii(e.inputs[0],"Asin","asin"))},Oi=e=>{e.compute(Ii(e.inputs[0],"Asinh","asinh"))},Ai=e=>{e.compute(Ii(e.inputs[0],"Atan","atan"))},Bi=e=>{e.compute(Ii(e.inputs[0],"Atanh","atanh"))},Ri=e=>qt(e),Di=(e,t)=>{let n;switch(t.to){case 10:n="vec4<f16>";break;case 1:n="vec4<f32>";break;case 12:n="vec4<u32>";break;case 6:n="vec4<i32>";break;case 9:n="vec4<bool>";break;default:throw new RangeError(`not supported type (specified in attribute 'to' from 'Cast' operator): ${t.to}`)}e.compute(Ii(e.inputs[0],"Cast",n,void 0,t.cacheKey,t.to))},Mi=e=>{let t,n;const i=e.length>=2&&0!==e[1].data,r=e.length>=3&&0!==e[2].data;switch(e[0].dataType){case 1:t=i?e[1].getFloat32Array()[0]:-34028234663852886e22,n=r?e[2].getFloat32Array()[0]:34028234663852886e22;break;case 10:t=i?e[1].getUint16Array()[0]:64511,n=r?e[2].getUint16Array()[0]:31743;break;default:throw new Error("Unsupport data type")}return qt({min:t,max:n})},Ui=(e,t)=>{const n=t||Mi(e.inputs),i=Gt(e.inputs[0].dataType);e.compute(Ii(e.inputs[0],"Clip",e=>`clamp(${e}, vec4<${i}>(uniforms.min), vec4<${i}>(uniforms.max))`,void 0,n.cacheKey,void 0,[{type:e.inputs[0].dataType,data:n.min},{type:e.inputs[0].dataType,data:n.max}],[{name:"min",type:i},{name:"max",type:i}]),{inputs:[0]})},Pi=e=>{e.compute(Ii(e.inputs[0],"Ceil","ceil"))},qi=e=>{e.compute(Ii(e.inputs[0],"Cos","cos"))},Ni=e=>{e.compute(Ii(e.inputs[0],"Cosh","cosh"))},Vi=e=>qt(e),Li=(e,t)=>{const n=Gt(e.inputs[0].dataType);e.compute(Ii(e.inputs[0],"Elu",e=>`elu_vf32(${e})`,`\n  const elu_alpha_ = ${n}(${t.alpha});\n\n  fn elu_f32(a: ${n}) -> ${n} {\n  return select((exp(a) - 1.0) * elu_alpha_, a, a >= 0.0);\n  }\n\n  fn elu_vf32(v: vec4<${n}>) -> vec4<${n}> {\n  return vec4(elu_f32(v.x), elu_f32(v.y), elu_f32(v.z), elu_f32(v.w));\n  }`,t.cacheKey))},Gi=(e="f32")=>`\nconst r0: ${e} = 0.3275911;\nconst r1: ${e} = 0.254829592;\nconst r2: ${e} = -0.284496736;\nconst r3: ${e} = 1.421413741;\nconst r4: ${e} = -1.453152027;\nconst r5: ${e} = 1.061405429;\n\nfn erf_vf32(v: vec4<${e}>) -> vec4<${e}> {\n  let absv = abs(v);\n  let x = 1.0 / (1.0 + r0 * absv);\n  return sign(v) * (1.0 - ((((r5 * x + r4) * x + r3) * x + r2) * x + r1) * x * exp(-absv * absv));\n}`,Wi=e=>{const t=Gt(e.inputs[0].dataType);e.compute(Ii(e.inputs[0],"Erf",e=>`erf_vf32(${e})`,Gi(t)))},ji=e=>{e.compute(Ii(e.inputs[0],"Exp","exp"))},Hi=e=>{e.compute(Ii(e.inputs[0],"Floor","floor"))},Fi=e=>{const t=Gt(e.inputs[0].dataType);e.compute(Ii(e.inputs[0],"Gelu",e=>`0.5 * ${e} * (1.0 + erf_vf32(${e} * 0.7071067811865475))`,Gi(t)))},Ki=(e,t)=>{const n=Gt(e.inputs[0].dataType);e.compute(Ii(e.inputs[0],"LeakyRelu",e=>`select(leaky_relu_alpha_ * ${e}, ${e}, ${e} >= vec4<${n}>(0.0))`,`const leaky_relu_alpha_ = ${n}(${t.alpha});`,t.cacheKey))},Zi=e=>{e.compute(Ii(e.inputs[0],"Not",e=>`!${e}`))},Qi=e=>{e.compute(Ii(e.inputs[0],"Neg",e=>`-${e}`))},Xi=e=>{e.compute(Ii(e.inputs[0],"Reciprocal",e=>`1.0/${e}`))},Yi=e=>{const t=Gt(e.inputs[0].dataType);e.compute(Ii(e.inputs[0],"Relu",e=>`select(vec4<${t}>(0.0), ${e}, ${e} > vec4<${t}>(0.0))`))},Ji=e=>{e.compute(Ii(e.inputs[0],"Sigmoid",e=>`(1.0 / (1.0 + exp(-${e})))`))},er=e=>qt(e),tr=(e,t)=>{const n=Gt(e.inputs[0].dataType);e.compute(Ii(e.inputs[0],"HardSigmoid",e=>`max(vec4<${n}>(0.0), min(vec4<${n}>(1.0), ${t.alpha} * ${e} + vec4<${n}>(${t.beta})))`,void 0,t.cacheKey))},nr=e=>{e.compute(Ii(e.inputs[0],"Sin","sin"))},ir=e=>{e.compute(Ii(e.inputs[0],"Sinh","sinh"))},rr=e=>{e.compute(Ii(e.inputs[0],"Sqrt","sqrt"))},sr=e=>{e.compute(Ii(e.inputs[0],"Tan","tan"))},ar=e=>`sign(${e}) * (1 - exp(-2 * abs(${e}))) / (1 + exp(-2 * abs(${e})))`,or=e=>{e.compute(Ii(e.inputs[0],"Tanh",ar))},ur=(e="f32")=>`\nconst fast_gelu_a: ${e} = 0.5;\nconst fast_gelu_b: ${e} = 0.7978845608028654;\nconst fast_gelu_c: ${e} = 0.035677408136300125;\n\nfn tanh_v(v: vec4<${e}>) -> vec4<${e}> {\n  return ${ar("v")};\n}\n`,dr=e=>`(fast_gelu_a + fast_gelu_a * tanh_v(${e} * (fast_gelu_c * ${e} * ${e} + fast_gelu_b))) * ${e}`,lr=e=>{const t=Gt(e.inputs[0].dataType);e.compute(Ii(e.inputs[0],"FastGelu",dr,ur(t),void 0,e.inputs[0].dataType))},pr=(e,t)=>{const n=Gt(e.inputs[0].dataType);return e.compute(Ii(e.inputs[0],"ThresholdedRelu",e=>`select(vec4<${n}>(0.0), ${e}, ${e} > thresholded_relu_alpha_)`,`const thresholded_relu_alpha_ = vec4<${n}>(${t.alpha});`,t.cacheKey)),0},cr=e=>{e.compute(Ii(e.inputs[0],"Log","log"))},hr=(e,t)=>`\nconst alpha = vec4<${e}>(${t});\nconst one = ${e}(1.0);\nconst zero = ${e}(0.0);\n\nfn quick_gelu_impl(x: vec4<${e}>) -> vec4<${e}> {\n  let v = x *alpha;\n  var x1 : vec4<${e}>;\n  for (var i = 0; i < 4; i = i + 1) {\n    if (v[i] >= zero) {\n      x1[i] = one / (one + exp(-v[i]));\n    } else {\n      x1[i] = one - one / (one + exp(v[i]));\n    }\n  }\n  return x * x1;\n}\n`,fr=e=>`quick_gelu_impl(${e})`,mr=(e,t)=>{const n=Gt(e.inputs[0].dataType);e.compute(Ii(e.inputs[0],"QuickGelu",fr,hr(n,t.alpha),t.cacheKey,e.inputs[0].dataType))}}}),xd=P({"web/lib/wasm/jsep/webgpu/ops/bias-split-gelu.ts"(){od(),fd(),vd(),gr=e=>{if(3!==e[0].dims.length)throw new Error("input should have 3 dimensions");if(![2560,5120,10240].includes(e[0].dims[2]))throw new Error("hidden state should be 2560, 5120 or 10240");if(1!==e[1].dims.length)throw new Error("bias is expected to have 1 dimensions");if(e[0].dims[2]!==e[1].dims[0])throw new Error("last dimension of input and bias are not the same")},_r=e=>{const t=e[0].dims.slice();t[2]=t[2]/2;const n=Xt("input",e[0].dataType,e[0].dims,4),i=Xt("bias",e[0].dataType,[e[0].dims[2]],4),r=Yt("output",e[0].dataType,t,4),s=dt.size(t)/4,a=Lt(e[0].dataType);return{name:"BiasSplitGelu",getRunData:()=>({outputs:[{dims:t,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(s/64)}}),getShaderSource:t=>`\n  const M_SQRT2 = sqrt(2.0);\n  const halfChannels = ${e[0].dims[2]/4/2}u;\n\n  ${t.declareVariables(n,i,r)}\n\n  ${Gi(a)}\n\n  ${t.mainStart()}\n    ${t.guardAgainstOutOfBoundsWorkgroupSizes(s)}\n    let biasIdx = global_idx % halfChannels;\n    let batchIndex = global_idx / halfChannels;\n    let inputOffset = biasIdx + batchIndex * halfChannels * 2;\n    let valueLeft = input[inputOffset] + bias[biasIdx];\n    let valueRight = input[inputOffset + halfChannels] + bias[biasIdx + halfChannels];\n    let geluRight = valueRight * 0.5 * (erf_vf32(valueRight / M_SQRT2) + 1);\n\n    ${r.setByOffset("global_idx","valueLeft * geluRight")}\n  }`}},wr=e=>{gr(e.inputs),e.compute(_r(e.inputs))}}}),kd=P({"web/lib/wasm/jsep/webgpu/ops/binary-op.ts"(){rd(),od(),fd(),yr=(e,t,n,i,r,s,a,o,u,d,l,p)=>{let c,h;"string"==typeof o?c=h=(e,t)=>`${o}((${e}),(${t}))`:"function"==typeof o?c=h=o:(c=o.scalar,h=o.vector);const f=Yt("outputData",l,i.length,4),m=Xt("aData",u,t.length,4),g=Xt("bData",d,n.length,4);let _;if(r)if(s){const e=1===dt.size(t),i=1===dt.size(n),r=t.length>0&&t[t.length-1]%4==0,s=n.length>0&&n[n.length-1]%4==0;_=e||i?f.setByOffset("global_idx",h(e?`${m.type.value}(${m.getByOffset("0")}.x)`:m.getByOffset("global_idx"),i?`${g.type.value}(${g.getByOffset("0")}.x)`:g.getByOffset("global_idx"))):`\n            let outputIndices = ${f.offsetToIndices("global_idx * 4u")};\n            let offsetA = ${m.broadcastedIndicesToOffset("outputIndices",f)};\n            let offsetB = ${g.broadcastedIndicesToOffset("outputIndices",f)};\n            ${f.setByOffset("global_idx",h(a||r?m.getByOffset("offsetA / 4u"):`${m.type.value}(${m.getByOffset("offsetA / 4u")}[offsetA % 4u])`,a||s?g.getByOffset("offsetB / 4u"):`${g.type.value}(${g.getByOffset("offsetB / 4u")}[offsetB % 4u])`))}\n          `}else _=f.setByOffset("global_idx",h(m.getByOffset("global_idx"),g.getByOffset("global_idx")));else{if(!s)throw new Error("no necessary to use scalar implementation for element-wise binary op implementation.");const e=(e,t,n="")=>{const i=`aData[indexA${t}][componentA${t}]`,r=`bData[indexB${t}][componentB${t}]`;return`\n            let outputIndices${t} = ${f.offsetToIndices(`global_idx * 4u + ${t}u`)};\n            let offsetA${t} = ${m.broadcastedIndicesToOffset(`outputIndices${t}`,f)};\n            let offsetB${t} = ${g.broadcastedIndicesToOffset(`outputIndices${t}`,f)};\n            let indexA${t} = offsetA${t} / 4u;\n            let indexB${t} = offsetB${t} / 4u;\n            let componentA${t} = offsetA${t} % 4u;\n            let componentB${t} = offsetB${t} % 4u;\n            ${e}[${t}] = ${n}(${c(i,r)});\n          `};_=9===l?`\n            var data = vec4<u32>(0);\n            ${e("data",0,"u32")}\n            ${e("data",1,"u32")}\n            ${e("data",2,"u32")}\n            ${e("data",3,"u32")}\n            outputData[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`:`\n            ${e("outputData[global_idx]",0)}\n            ${e("outputData[global_idx]",1)}\n            ${e("outputData[global_idx]",2)}\n            ${e("outputData[global_idx]",3)}\n          `}return`\n        ${e.registerUniform("vec_size","u32").declareVariables(m,g,f)}\n\n        ${p??""}\n\n        ${e.mainStart()}\n        ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.vec_size")}\n        ${_}\n      }`},$r=(e,t,n,i,r,s,a=n.dataType)=>{const o=n.dims.map(e=>Number(e)??1),u=i.dims.map(e=>Number(e)??1),d=!dt.areEqual(o,u);let l=o,p=dt.size(o),c=!1,h=!1;const f=[d];if(d){const e=ut.calcShape(o,u,!1);if(!e)throw new Error("Can't perform binary op on the given tensors");l=e.slice(),p=dt.size(l);const t=1===dt.size(o),n=1===dt.size(u),i=o.length>0&&o[o.length-1]%4==0,r=u.length>0&&u[u.length-1]%4==0;f.push(t),f.push(n),f.push(i),f.push(r);let s=1;for(let e=1;e<l.length;e++){const t=o[o.length-e];if(t!==u[u.length-e])break;s*=t}s%4==0?(h=!0,c=!0):(t||n||i||r)&&(c=!0)}else c=!0;return f.push(c),{name:e,shaderCache:{hint:t+f.map(e=>e.toString()).join("_"),inputDependencies:["rank","rank"]},getShaderSource:e=>yr(e,o,u,l,c,d,h,r,n.dataType,i.dataType,a,s),getRunData:()=>({outputs:[{dims:l,dataType:a}],dispatchGroup:{x:Math.ceil(p/64/4)},programUniforms:[{type:12,data:Math.ceil(dt.size(l)/4)},...Wt(o,u,l)]})}},br=(e,t,n,i,r,s)=>{e.compute($r(t,r??"",e.inputs[0],e.inputs[1],n,i,s))},vr=e=>{br(e,"Add",(e,t)=>`${e}+${t}`)},xr=e=>{br(e,"Div",(e,t)=>`${e}/${t}`)},kr=e=>{br(e,"Equal",{scalar:(e,t)=>`u32(${e}==${t})`,vector:(e,t)=>`vec4<u32>(${e}==${t})`},void 0,void 0,9)},Sr=e=>{br(e,"Mul",(e,t)=>`${e}*${t}`)},Ir=e=>{const t=Xt("input",e.inputs[0].dataType,e.inputs[0].dims).type.value;br(e,"Pow",{scalar:(e,t)=>`pow_custom(${e},${t})`,vector:(e,t)=>`pow_vector_custom(${e},${t})`},`\n    fn pow_custom(a : ${t}, b : ${t}) -> ${t} {\n      if (b == ${t}(0.0)) {\n        return ${t}(1.0);\n      } else if (a < ${t}(0.0) && f32(b) != floor(f32(b))) {\n        return ${t}(pow(f32(a), f32(b))); // NaN\n      }\n      return select(sign(a), ${t}(1.0), round(f32(abs(b) % ${t}(2.0))) != 1.0) * ${t}(${"i32"===t?"round":""}(pow(f32(abs(a)), f32(b))));\n    }\n    fn pow_vector_custom(a : vec4<${t}>, b : vec4<${t}>) -> vec4<${t}> {\n      // TODO: implement vectorized pow\n      return vec4<${t}>(pow_custom(a.x, b.x), pow_custom(a.y, b.y), pow_custom(a.z, b.z), pow_custom(a.w, b.w));\n    }\n      `)},Tr=e=>{br(e,"Sub",(e,t)=>`${e}-${t}`)},zr=e=>{br(e,"Greater",{scalar:(e,t)=>`u32(${e}>${t})`,vector:(e,t)=>`vec4<u32>(${e}>${t})`},void 0,void 0,9)},Er=e=>{br(e,"Less",{scalar:(e,t)=>`u32(${e}<${t})`,vector:(e,t)=>`vec4<u32>(${e}<${t})`},void 0,void 0,9)},Cr=e=>{br(e,"GreaterOrEqual",{scalar:(e,t)=>`u32(${e}>=${t})`,vector:(e,t)=>`vec4<u32>(${e}>=${t})`},void 0,void 0,9)},Or=e=>{br(e,"LessOrEqual",{scalar:(e,t)=>`u32(${e}<=${t})`,vector:(e,t)=>`vec4<u32>(${e}<=${t})`},void 0,void 0,9)}}}),Sd=P({"web/lib/wasm/jsep/webgpu/ops/concat.ts"(){rd(),od(),hd(),fd(),Ar=(e,t)=>{if(!e||e.length<1)throw new Error("too few inputs");const n=e[0],i=n.dataType,r=n.dims.length;e.forEach((e,s)=>{if(0!==s){if(e.dataType!==i)throw new Error("input tensors should be one type");if(e.dims.length!==r)throw new Error("input tensors should have the same shape");e.dims.forEach((e,i)=>{if(i!==t&&e!==n.dims[i])throw new Error("non concat dimensions must match")})}})},Br=(e,t)=>`\n  fn calculateInputIndex(index: u32) -> u32 {\n    let sizeInConcatAxis = array<u32, ${e}u>(${t});\n    for (var i: u32 = 0u; i < ${e}; i += 1u ) {\n      if (index < sizeInConcatAxis[i]) {\n        return i;\n      }\n    }\n    return ${e}u;\n  }`,Rr=(e,t)=>{const n=e.length,i=[];for(let r=0;r<n;++r){const s=t.setByOffset("global_idx",e[r].getByIndices("indices"));1===n?i.push(s):0===r?i.push(`if (inputIndex == ${r}u) { ${s} }`):r===n-1?i.push(`else { ${s} }`):i.push(`else if (inputIndex == ${r}) { ${s} }`)}return i.join("\n")},Dr=(e,t,n,i)=>{const r=dt.size(n),s=new Array(e.length),a=new Array(e.length);let o=0;const u=[],d=[],l=[{type:12,data:r}];for(let n=0;n<e.length;++n)o+=e[n].dims[t],s[n]=o,d.push(e[n].dims.length),a[n]=Xt(`input${n}`,i,d[n]),u.push("rank"),l.push({type:12,data:s[n]});for(let t=0;t<e.length;++t)l.push(...Wt(e[t].dims));l.push(...Wt(n));const p=Yt("output",i,n.length),c=p.indicesGet("indices",t),h=Array.from(Array(s.length).keys()).map(e=>`uniforms.sizeInConcatAxis${e}`).join(",");return{name:"Concat",shaderCache:{hint:`${t}`,inputDependencies:u},getRunData:()=>({outputs:[{dims:n,dataType:i}],dispatchGroup:{x:Math.ceil(r/64)},programUniforms:l}),getShaderSource:t=>`\n\n  ${(()=>{t.registerUniform("outputSize","u32");for(let n=0;n<e.length;n++)t.registerUniform(`sizeInConcatAxis${n}`,"u32");return t.declareVariables(...a,p)})()}\n\n  ${Br(s.length,h)}\n\n  ${t.mainStart()}\n    ${t.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}\n\n    var indices = ${p.offsetToIndices("global_idx")};\n\n    let inputIndex = calculateInputIndex(${c});\n    if (inputIndex != 0u) {\n      let sizeInConcatAxis = array<u32, ${s.length}u>(${h});\n      ${c} -= sizeInConcatAxis[inputIndex - 1u];\n    }\n\n    ${Rr(a,p)}\n  }`}},Mr=(e,t)=>{const n=e.inputs,i=n[0].dims,r=dt.normalizeAxis(t.axis,i.length);Ar(n,r);const s=i.slice();s[r]=n.reduce((e,t)=>e+(t.dims.length>r?t.dims[r]:0),0);const a=n.filter(e=>dt.size(e.dims)>0);e.compute(Dr(a,r,s,n[0].dataType),{inputs:a})},Ur=e=>qt({axis:e.axis})}}),Id=P({"web/lib/wasm/jsep/webgpu/ops/fuse-utils.ts"(){rd(),od(),Pr=(e,t,n="f32")=>{switch(e.activation){case"Relu":return`value = max(value, ${t}(0.0));`;case"Sigmoid":return`value = (${t}(1.0) / (${t}(1.0) + exp(-value)));`;case"Clip":return`value = clamp(value, ${t}(${n}(uniforms.clip_min)), ${t}(${n}(uniforms.clip_max)));`;case"HardSigmoid":return`value = max(${t}(0.0), min(${t}(1.0), ${n}(uniforms.alpha) * value + ${n}(uniforms.beta)));`;case"LeakyRelu":return`value = select(${n}(uniforms.alpha) * value, value, value >= ${t}(0.0));`;case"Tanh":return"let e2x = exp(-2.0 * abs(value));\n              value = sign(value) * (1.0 - e2x) / (1.0 + e2x);\n        ";case"":return"";default:throw new Error(`Unsupported activation ${e.activation}`)}},qr=(e,t)=>{"Clip"===e.activation?t.push({type:1,data:e.clipMax},{type:1,data:e.clipMin}):"HardSigmoid"===e.activation?t.push({type:1,data:e.alpha},{type:1,data:e.beta}):"LeakyRelu"===e.activation&&t.push({type:1,data:e.alpha})},Nr=(e,t)=>{"Clip"===e.activation?t.push({name:"clip_max",type:"f32"},{name:"clip_min",type:"f32"}):"HardSigmoid"===e.activation?t.push({name:"alpha",type:"f32"},{name:"beta",type:"f32"}):"LeakyRelu"===e.activation&&t.push({name:"alpha",type:"f32"})},Vr=e=>{const t=e?.activation||"";if("HardSigmoid"===t){const[n,i]=e?.activation_params||[.2,.5];return{activation:t,alpha:n,beta:i}}if("Clip"===t){const[n,i]=e?.activation_params||[ct,ht];return{activation:t,clipMax:i,clipMin:n}}if("LeakyRelu"===t){const[n]=e?.activation_params||[.01];return{activation:t,alpha:n}}return{activation:t}}}}),Td=P({"web/lib/wasm/jsep/webgpu/ops/3rd-party/activation_util.ts"(){Lr=(e,t)=>{switch(e){case 1:return t;case 2:return`vec2<${t}>`;case 3:return`vec3<${t}>`;case 4:return`vec4<${t}>`;default:throw new Error(`${e}-component is not supported.`)}},Gr=e=>`\n      ${e?"value = value + getBiasByOutputCoords(coords);":""}\n      `}}),zd=P({"web/lib/wasm/jsep/webgpu/ops/3rd-party/conv_util.ts"(){Wr=e=>`\nfn getIndexFromCoords4D(coords : vec4<i32>, shape : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n      shape.y * shape.z * shape.w, shape.z * shape.w, shape.w, 1));\n}\nfn getOutputIndexFromCoords(coords : vec4<i32>) -> i32 {\n  return dot(coords, vec4<i32>(\n    i32(${e}.x), i32(${e}.y), i32(${e}.z), 1));\n}\n`}}),Ed=P({"web/lib/wasm/jsep/webgpu/ops/matmul-shaders.ts"(){rd(),od(),fd(),Id(),jr=(e,t,n,i,r)=>{const s=i-n;return`\n      ${Array.from({length:n}).map((n,a)=>`\n      if (${Zt(t.shape,a,t.rank)} != 1) {\n        ${t.indicesSet(e,a,Zt(r,a+s,i))}\n      } else {\n        ${t.indicesSet(e,a,0)}\n      }`).join("")}\n`},Hr=(e,t,n,i,r=!1,s)=>{const a=e[0].dims,o=e[1].dims,u=a[a.length-2],d=o[o.length-1],l=a[a.length-1],p=jt(d),c=jt(l),h=jt(u),f=dt.size(n)/p/h,m=e.length>2,g=i?i.slice(0,-2):n.slice(0,-2),_=[dt.size(g),u,d],w=[{type:12,data:f},{type:12,data:u},{type:12,data:d},{type:12,data:l}];return qr(t,w),w.push(...Wt(g,a,o)),m&&w.push(...Wt(e[2].dims)),w.push(...Wt(_)),{name:"MatMulNaive",shaderCache:{hint:`${t.activation};${p};${c};${h};${r}`,inputDependencies:m?["rank","rank","rank"]:["rank","rank"]},getRunData:()=>({outputs:[{dims:s?s(n):n,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(f/64)},programUniforms:w}),getShaderSource:i=>{const s=en("batch_dims",e[0].dataType,g.length),u=Xt("a",e[0].dataType,a.length,c),d=Xt("b",e[1].dataType,o.length,p),l=Yt("output",e[0].dataType,_.length,p),f=Lt(l.type.tensor),w=Pr(t,l.type.value,f),y=[u,d];let $="";if(m){const t=r?p:1;y.push(Xt("bias",e[2].dataType,e[2].dims.length,t)),$=r?`value += bias[col / ${t}];`:`value += ${l.type.value}(bias[row + i]);`}const b=[{name:"output_size",type:"u32"},{name:"M",type:"u32"},{name:"N",type:"u32"},{name:"K",type:"u32"}];return Nr(t,b),`\n  ${i.registerUniforms(b).registerInternalVariables(s).declareVariables(...y,l)}\n  ${i.mainStart()}\n    ${i.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n    let col = (global_idx % (uniforms.N / ${p})) * ${p};\n    var index1 = global_idx / (uniforms.N / ${p});\n    let stride1 = uniforms.M / ${h};\n    let row = (index1 % stride1) * ${h};\n    let batch = index1 / stride1;\n\n    ${2===n.length?"":`let batch_indices = ${s.offsetToIndices("batch")};`}\n\n    var a_indices: ${u.type.indices};\n    ${jr("a_indices",u,u.rank-2,s.rank,"batch_indices")}\n    ${u.indicesSet("a_indices",u.rank-2,0)}\n    ${u.indicesSet("a_indices",u.rank-1,0)}\n    let a_offset = ${u.indicesToOffset("a_indices")};\n\n    var b_indices: ${d.type.indices};\n    ${jr("b_indices",d,d.rank-2,s.rank,"batch_indices")}\n    ${d.indicesSet("b_indices",d.rank-2,0)}\n    ${d.indicesSet("b_indices",d.rank-1,0)}\n    let b_offset = ${d.indicesToOffset("b_indices")};\n    var values: array<${l.type.value}, ${h}>;\n    for (var k: u32 = 0u; k < uniforms.K; k = k + ${c}) {\n      ${(()=>{let e=`var a_data: ${u.type.value};`;for(let t=0;t<c;t++)e+=`\n              let b_data${t} = b[(b_offset + (k + ${t}) * uniforms.N + col) / ${p}];`;for(let t=0;t<h;t++){e+=`a_data = a[(a_offset + (row + ${t}) * uniforms.K + k) / ${c}];`;for(let n=0;n<c;n++)e+=`\n            values[${t}] = fma(${d.type.value}(a_data${1===c?"":`[${n}]`}), b_data${n}, values[${t}]);\n`}return e})()}\n    }\n    for (var i = 0u; i < ${h}u; i++) {\n      var value = values[i];\n      ${$}\n      ${w}\n      let cur_indices = ${l.type.indices}(batch, row + i, col);\n      let offset = ${l.indicesToOffset("cur_indices")};\n      ${l.setByOffset(`offset / ${p}`,"value")};\n    }\n  }\n  `}}}}}),Cd=P({"web/lib/wasm/jsep/webgpu/ops/3rd-party/matmul_packed_webgpu.ts"(){rd(),od(),fd(),Id(),Ed(),Td(),Fr=(e,t)=>e?`\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          kStart + inputRow,\n          globalRowStart / innerElementSize + inputCol${t?", batchIndices":""});\n        `:`\n        mm_Asub[inputRow][inputCol] = mm_readA(batch,\n          globalRow + innerRow,\n          kStart / innerElementSize + inputCol${t?", batchIndices":""});\n        `,Kr=(e,t)=>e?`\n        let ACached0 = mm_Asub[k * innerElementSize][localRow];\n        let ACached1 = mm_Asub[k * innerElementSize + 1][localRow];\n        let ACached2 = mm_Asub[k * innerElementSize + 2][localRow];\n        ${3===t?"":"let ACached3 = mm_Asub[k * innerElementSize + 3][localRow];"}\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          acc[i] = BCached0 * ACached0[i] + acc[i];\n          acc[i] = BCached1 * ACached1[i] + acc[i];\n          acc[i] = BCached2 * ACached2[i] + acc[i];\n          ${3===t?"":"acc[i] = BCached3 * ACached3[i] + acc[i];"}\n        }`:`\n        for (var i = 0; i < rowPerThread; i = i + 1) {\n          let ACached = mm_Asub[tileRow + i][k];\n          acc[i] = BCached0 * ACached.x + acc[i];\n          acc[i] = BCached1 * ACached.y + acc[i];\n          acc[i] = BCached2 * ACached.z + acc[i];\n          ${3===t?"":"acc[i] = BCached3 * ACached.w + acc[i];"}\n        }`,Zr=(e,t,n="f32",i,r=!1,s=32,a=!1,o=32)=>{const u=t[1]*e[1],d=t[0]*e[0],l=r?u:s,p=r?s:u,c=l/t[0],h=s/t[1];if((!r||4!==c||4!==e[1])&&(r||3!==c&&4!==c)||l%t[0]!==0||s%t[1]!==0||4!==e[0])throw new Error(`If transposeA ${r} is true, innerElementSize ${c} and workPerThread[1] ${e[1]} must be 4.\n      Otherwise, innerElementSize ${c} must be 3 or 4.\n  tileAWidth ${l} must be divisible by workgroupSize[0]${t[0]}. tileInner ${s} must be divisible by workgroupSize[1] ${t[1]}. colPerThread ${e[0]} must be 4.`);return`\nvar<workgroup> mm_Asub: array<array<vec${c}<${n}>, ${l/c}>, ${p}>;\nvar<workgroup> mm_Bsub: array<array<vec4<${n}>, ${d/e[0]}>, ${s}>;\n\nconst rowPerThread = ${e[1]};\nconst colPerThread = ${e[0]};\nconst innerElementSize = ${c};\nconst tileInner = ${s};\n\n@compute @workgroup_size(${t[0]}, ${t[1]}, ${t[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n  let localRow = i32(localId.y);\n  let tileRow = localRow * rowPerThread;\n  let tileCol = i32(localId.x);\n\n  let globalRow =i32(globalId.y) * rowPerThread;\n  let globalCol = i32(globalId.x);\n  let batch = ${a?"0":"i32(globalId.z)"};\n  ${i?`let batchIndices = ${i.offsetToIndices("u32(batch)")};`:""}\n  let globalRowStart = i32(workgroupId.y) * ${u};\n\n  let num_tiles = ${a?`${Math.ceil(o/s)}`:"(uniforms.dim_inner - 1) / tileInner + 1"};\n  var kStart = ${a?`i32(globalId.z) * ${o}`:"0"};\n\n  var acc: array<vec4<${n}>, rowPerThread>;\n\n  // Loop over shared dimension.\n  let tileRowB = localRow * ${h};\n  for (var t = 0; t < num_tiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let inputRow = tileRow + innerRow;\n          let inputCol = tileCol;\n          ${Fr(r,i)}\n      }\n\n      // Load one tile of B into local memory.\n      for (var innerRow = 0; innerRow < ${h}; innerRow = innerRow + 1) {\n          let inputRow = tileRowB + innerRow;\n          let inputCol = tileCol;\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch, kStart + inputRow, globalCol${i?", batchIndices":""});\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      for (var k = 0; k < tileInner / innerElementSize; k = k + 1) {\n          let BCached0 = mm_Bsub[k * innerElementSize][tileCol];\n          let BCached1 = mm_Bsub[k * innerElementSize + 1][tileCol];\n          let BCached2 = mm_Bsub[k * innerElementSize + 2][tileCol];\n          ${3===c?"":"let BCached3 = mm_Bsub[k * innerElementSize + 3][tileCol];"}\n\n          ${Kr(r,c)}\n      }\n\n      workgroupBarrier();\n  }\n\n  for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      mm_write(batch, globalRow + innerRow, globalCol, acc[innerRow]);\n  }\n}`},Qr=(e,t)=>e?`\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              kStart + inputRow,\n              globalRowStart + inputCol${t?", batchIndices":""});\n            `:`\n            mm_Asub[inputRow][inputCol] = mm_readA(batch,\n              globalRowStart + inputRow,\n              kStart + inputCol${t?", batchIndices":""});\n            `,Xr=e=>e?"let ACached = mm_Asub[k][tileRow + innerRow];":"let ACached = mm_Asub[tileRow + innerRow][k];",Yr=(e,t,n="f32",i,r=!1,s=32,a=!1,o=32,u=!1)=>{const d=e[1]*t[1],l=e[0]*t[0],p=r?d:s,c=r?s:d;if(c%t[1]!==0||p%t[0]!==0||s%t[1]!==0)throw new Error(`tileAHight ${c} must be divisible by workgroupSize[1]${t[1]}, tileAWidth ${p} must be divisible by workgroupSize[0]${t[0]}, tileInner ${s} must be divisible by workgroupSize[1]${t[1]}`);const h=c/t[1],f=p/t[0],m=s/t[1],g=u?`\n    let localRow = i32(localId.y);\n    let localCol = i32(localId.x);\n    let globalRowStart = i32(workgroupId.y) * ${d};\n    let globalColStart = i32(workgroupId.x) * ${l};\n\n    // Loop over shared dimension.\n    for (var t = 0; t < num_tiles; t = t + 1) {\n      // Load one tile of A into local memory.\n      for (var inputRow = localRow; inputRow < ${c}; inputRow = inputRow + ${t[1]}) {\n        for (var inputCol = localCol; inputCol < ${p}; inputCol = inputCol + ${t[0]}) {\n          ${Qr(r,i)}\n        }\n      }\n      // Load one tile of B into local memory.\n      for (var inputRow = localRow; inputRow < ${s}; inputRow = inputRow + ${t[1]}) {\n            for (var inputCol = localCol; inputCol < ${l}; inputCol = inputCol + ${t[0]}) {\n          mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n            kStart + inputRow,\n            globalColStart + inputCol${i?", batchIndices":""});\n        }\n      }\n      kStart = kStart + tileInner;\n      workgroupBarrier();\n\n      // Compute acc values for a single thread.\n      var BCached : array<${n}, colPerThread>;\n      for (var k = 0; k < tileInner; k = k + 1) {\n        for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n          BCached[inner] = mm_Bsub[k][localCol + inner * ${t[0]}];\n        }\n        for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n          let ACached = ${r?`mm_Asub[k][localRow + innerRow * ${t[1]}];`:`mm_Asub[localRow + innerRow * ${t[1]}][k];`}\n          for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n            acc[innerRow][innerCol] = acc[innerRow][innerCol] +\n                ACached * BCached[innerCol];\n          }\n        }\n      }\n      workgroupBarrier();\n    }\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      let gRow = globalRowStart + localRow + innerRow * ${t[1]};\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        let gCol = globalColStart + localCol + innerCol * ${t[0]};\n        mm_write(batch, gRow, gCol, acc[innerRow][innerCol]);\n      }\n    }\n    `:`\nlet tileRow = i32(localId.y) * rowPerThread;\nlet tileCol = i32(localId.x) * colPerThread;\n\nlet globalRow = i32(globalId.y) * rowPerThread;\nlet globalCol = i32(globalId.x) * colPerThread;\nlet globalRowStart = i32(workgroupId.y) * ${d};\n\nlet tileRowA = i32(localId.y) * ${h};\nlet tileColA = i32(localId.x) * ${f};\nlet tileRowB = i32(localId.y) * ${m};\n// Loop over shared dimension.\nfor (var t = 0; t < num_tiles; t = t + 1) {\n  // Load one tile of A into local memory.\n  for (var innerRow = 0; innerRow < ${h}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < ${f}; innerCol = innerCol + 1) {\n      let inputRow = tileRowA + innerRow;\n      let inputCol = tileColA + innerCol;\n      ${Qr(r,i)}\n    }\n  }\n\n  // Load one tile of B into local memory.\n  for (var innerRow = 0; innerRow < ${m}; innerRow = innerRow + 1) {\n    for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n      let inputRow = tileRowB + innerRow;\n      let inputCol = tileCol + innerCol;\n      mm_Bsub[inputRow][inputCol] = mm_readB(batch,\n        kStart + inputRow,\n        globalCol + innerCol${i?", batchIndices":""});\n    }\n  }\n  kStart = kStart + tileInner;\n  workgroupBarrier();\n\n  // Compute acc values for a single thread.\n  var BCached : array<${n}, colPerThread>;\n  for (var k = 0; k < tileInner; k = k + 1) {\n    for (var inner = 0; inner < colPerThread; inner = inner + 1) {\n      BCached[inner] = mm_Bsub[k][tileCol + inner];\n    }\n\n    for (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n      ${Xr(r)}\n      for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n        acc[innerRow][innerCol] = acc[innerRow][innerCol] + ACached * BCached[innerCol];\n      }\n    }\n  }\n\n  workgroupBarrier();\n}\n\nfor (var innerRow = 0; innerRow < rowPerThread; innerRow = innerRow + 1) {\n  for (var innerCol = 0; innerCol < colPerThread; innerCol = innerCol + 1) {\n    mm_write(batch, globalRow + innerRow, globalCol + innerCol,\n        acc[innerRow][innerCol]);\n  }\n}\n`;return`\n  var<workgroup> mm_Asub : array<array<${n}, ${p}>, ${c}>;\n  var<workgroup> mm_Bsub : array<array<${n}, ${l}>, ${s}>;\n  const rowPerThread = ${e[1]};\n  const colPerThread = ${e[0]};\n  const tileInner = ${s};\n\n@compute @workgroup_size(${t[0]}, ${t[1]}, ${t[2]})\nfn main(@builtin(local_invocation_id) localId : vec3<u32>,\n        @builtin(global_invocation_id) globalId : vec3<u32>,\n        @builtin(workgroup_id) workgroupId : vec3<u32>) {\n    let batch = ${a?"0":"i32(globalId.z)"};\n    ${i?`let batchIndices = ${i.offsetToIndices("u32(batch)")};`:""}\n    let num_tiles = ${a?`${Math.ceil(o/s)}`:"(uniforms.dim_inner - 1) / tileInner + 1"};\n    var kStart = ${a?`i32(globalId.z) * ${o}`:"0"};\n\n    var acc : array<array<${n}, colPerThread>, rowPerThread>;\n    ${g}\n  }\n`},Jr=(e,t,n,i,r=!1)=>{const[s,a,o,u]=i,d=Lt(i[0].type.tensor);return`\n    fn mm_readA(batch: i32, row: i32, colIn: i32, batchIndices: ${s.type.indices}) -> ${Lr(e,d)} {\n      var value = ${Lr(e,d)}(0.0);\n      let col = colIn * ${e};\n      if(row < uniforms.dim_a_outer && col < uniforms.dim_inner)\n      {\n        var aIndices: ${a.type.indices};\n        ${jr("aIndices",a,a.rank-2,s.rank,"batchIndices")}\n        ${a.indicesSet("aIndices",a.rank-2,"u32(row)")}\n        ${a.indicesSet("aIndices",a.rank-1,"u32(colIn)")}\n        value = ${a.getByIndices("aIndices")};\n      }\n      return value;\n    }\n\n    fn mm_readB(batch: i32, row: i32, colIn: i32, batchIndices: ${s.type.indices}) -> ${Lr(e,d)} {\n      var value = ${Lr(e,d)}(0.0);\n      let col = colIn * ${e};\n      if(row < uniforms.dim_inner && col < uniforms.dim_b_outer)\n      {\n        var bIndices: ${o.type.indices};\n        ${jr("bIndices",o,o.rank-2,s.rank,"batchIndices")}\n        ${o.indicesSet("bIndices",o.rank-2,"u32(row)")}\n        ${o.indicesSet("bIndices",o.rank-1,"u32(colIn)")}\n        value = ${o.getByIndices("bIndices")};\n      }\n      return value;\n    }\n\n    fn mm_write(batch: i32, row: i32, colIn: i32, valueIn: ${Lr(e,d)}) {\n      let col = colIn * ${e};\n      if (row < uniforms.dim_a_outer && col < uniforms.dim_b_outer) {\n        var value = valueIn;\n        let coords = vec3<i32>(batch, row, colIn);\n        ${t?`value = value + ${r?"bias[colIn]":`${Lr(e,d)}(bias[row])`};`:""}\n        ${n}\n        ${u.setByIndices("vec3<u32>(coords)","value")}\n      }\n    }\n    `},es=(e,t,n,i,r=!1,s)=>{const a=e[0].dims,o=e[1].dims,u=a.slice(0,-2),d=o.slice(0,-2),l=i?i.slice(0,-2):n.slice(0,-2),p=dt.size(l),c=a[a.length-2],h=a[a.length-1],f=o[o.length-1],m=h%4==0&&f%4==0,g=c<=8?[4,1,1]:[4,4,1],_=[8,8,1],w=[Math.ceil(f/_[0]/g[0]),Math.ceil(c/_[1]/g[1]),Math.ceil(p/_[2]/g[2])],y=m?4:1,$=[...u,c,h/y],b=$.length,v=[...d,h,f/y],x=v.length,k=[p,c,f/y],S=[{type:6,data:c},{type:6,data:f},{type:6,data:h}];qr(t,S),S.push(...Wt(l,$,v));const I=["rank","rank"],T=e.length>2;return T&&(S.push(...Wt(e[2].dims)),I.push("rank")),S.push(...Wt(k)),{name:"MatMul",shaderCache:{hint:`${g};${t.activation};${m};${r}`,inputDependencies:I},getRunData:()=>({outputs:[{dims:s?s(n):n,dataType:e[0].dataType}],dispatchGroup:{x:w[0],y:w[1],z:w[2]},programUniforms:S}),getShaderSource:n=>{const i=l.length,s=en("batchDims",e[0].dataType,i,1),a=Lt(e[0].dataType),o=Xt("a",e[0].dataType,b,y),u=Xt("b",e[1].dataType,x,y),d=Yt("result",e[0].dataType,k.length,y),p=[o,u];if(T){const t=r?y:1;p.push(Xt("bias",e[2].dataType,e[2].dims.length,t))}const c=[{name:"dim_a_outer",type:"i32"},{name:"dim_b_outer",type:"i32"},{name:"dim_inner",type:"i32"}];Nr(t,c);const h=Lt(d.type.tensor),f=Pr(t,d.type.value,h),w=Jr(y,T,f,[s,o,u,d],r);return`\n  ${n.registerUniforms(c).registerInternalVariables(s).declareVariables(...p,d)}\n  ${w}\n  ${m?Zr(g,_,a,s):Yr(g,_,a,s)}\n                   `}}}}}),Od=P({"web/lib/wasm/jsep/webgpu/ops/3rd-party/conv2d_mm_webgpu.ts"(){rd(),ad(),fd(),Id(),Td(),zd(),Cd(),ts=(e,t,n,i,r=!1,s,a=4,o=4,u=4,d="f32")=>{const l=e=>{switch(e){case 1:return"return w[row * i32(uniforms.w_shape[3]) + colIn];";case 4:return"return w[row * i32(uniforms.w_shape[3]) / 4 + colIn];";default:throw new Error(`innerElementSize ${e} is not supported.`)}},p=e?"\n    let coord = vec4<i32>(batch, xRow, xCol, xCh);\n    ":"\n    let coord = vec4<i32>(batch, xCh, xRow, xCol);\n    ",c=e?"\n    let coords = vec4<i32>(\n      batch,\n      row / outWidth,\n      row % outWidth,\n      col);\n    ":"\n    let coords = vec4<i32>(\n      batch,\n      row,\n      col / outWidth,\n      col % outWidth);\n    ",h=e?"i32(uniforms.x_shape[1])":"i32(uniforms.x_shape[2])",f=e?"i32(uniforms.x_shape[2])":"i32(uniforms.x_shape[3])",m=e?"row":"col",g=e?"col":"row",_=`\n    let inChannels = i32(uniforms.w_shape[2]);\n    let outWidth = ${e?"i32(uniforms.result_shape[2])":"i32(uniforms.result_shape[3])"};\n    let outRow = ${m} / outWidth;\n    let outCol = ${m} % outWidth;\n\n    let WRow = ${g} / (i32(uniforms.w_shape[1]) * inChannels);\n    let WCol = ${g} / inChannels % i32(uniforms.w_shape[1]);\n    let xRow = outRow * uniforms.stride[0] + uniforms.dilation[0] * WRow - uniforms.pad[0];\n    let xCol = outCol * uniforms.stride[1] + uniforms.dilation[1] * WCol - uniforms.pad[1];\n    let xCh = ${g} % inChannels;\n    var resData = ${Lr(a,d)}(0.0);\n    // The bounds checking is always needed since we use it to pad zero for\n    // the 'same' padding type.\n    if (xRow >= 0 && xRow < ${h} && xCol >= 0 && xCol < ${f}) {\n      ${p}\n      let xIndex = getIndexFromCoords4D(coord, vec4<i32>(uniforms.x_shape));\n      ${(e=>{switch(e){case 1:return"resData = x[xIndex];";case 3:return`resData = vec3<${d}>(x[xIndex], x[xIndex + 1], x[xIndex + 2]);`;case 4:return"resData = x[xIndex / 4];";default:throw new Error(`innerElementSize ${e} is not supported.`)}})(a)}\n    }\n    return resData;`,w=e?t&&i?`\n    let col = colIn * ${a};\n    ${_}`:`\n    let col = colIn * ${a};\n    if (row < uniforms.dim_a_outer && col < uniforms.dim_inner) {\n      ${_}\n    }\n    return ${Lr(a,d)}(0.0);`:i&&n?`\n    let col = colIn * ${a};\n    ${_}`:`\n    let col = colIn * ${a};\n    if (row < uniforms.dim_inner && col < uniforms.dim_b_outer) {\n      ${_}\n    }\n    return ${Lr(a,d)}(0.0);`,y=e?i&&n?l(o):`\n    let col = colIn * ${o};\n    if (row < uniforms.dim_inner && col < uniforms.dim_b_outer) {\n      ${l(o)}\n    }\n    return ${Lr(o,d)}(0.0);`:`\n    let col = colIn * ${o};\n    if (row < uniforms.dim_inner && col < uniforms.dim_a_outer) {\n      ${l(o)}\n    }\n    return ${Lr(o,d)}(0.0);`,$=Lr(u,d),b=Lr(e?a:o,d),v=Lr(e?o:a,d),x=Pr(s,$,d);return`\n    fn mm_readA(batch: i32, row : i32, colIn : i32) -> ${b} {\n      ${e?w:y}\n    }\n\n    fn mm_readB(batch: i32, row : i32, colIn : i32) -> ${v} {\n      ${e?y:w}\n    }\n\n    fn mm_write(batch: i32, row : i32, colIn : i32, valueIn : ${$}) {\n      let col = colIn * ${u};\n      if (row < uniforms.dim_a_outer && col < uniforms.dim_b_outer)\n      {\n      var value = valueIn;\n      let outWidth = ${e?"i32(uniforms.result_shape[2])":"i32(uniforms.result_shape[3])"};\n      ${c}\n      ${Gr(r)}\n      ${x}\n      setOutputAtCoords(coords[0], coords[1], coords[2], coords[3], value);\n      }\n    }`},ns=(e,t,n,i,r,s,a,o,u)=>{const d="NHWC"===t.format,l=d?e[0].dims[3]:e[0].dims[1],p=n[0],c=d?n[2]:n[3],h=d?n[1]:n[2],f=d?n[3]:n[1],m=d&&(l%4==0||l%3==0)&&f%4==0,g=d?f:c*h,_=d?c*h:f,w=[8,8,1],y=i<=8?[4,1,1]:[4,4,1],$=[Math.ceil(g/w[0]/y[0]),Math.ceil(_/w[1]/y[1]),Math.ceil(p/w[2]/y[2])];at("verbose",()=>`[conv2d_mm_webgpu] dispatch = ${$}`);const b=m?d&&l%4!=0?3:4:1,v=w[1]*y[1],x=w[0]*y[0],k=Math.max(w[0]*b,w[1]),S=i%v===0,I=r%x===0,T=s%k===0,z=m?[b,4,4]:[1,1,1],E=[{type:6,data:i},{type:6,data:r},{type:6,data:s},{type:6,data:[t.pads[0],t.pads[1]]},{type:6,data:t.strides},{type:6,data:t.dilations}];qr(t,E),E.push(...Wt(e[0].dims,e[1].dims));const C=["rank","rank"];return a&&(E.push(...Wt(e[2].dims)),C.push("rank")),E.push(...Wt(n)),{name:"Conv2DMatMul",shaderCache:{hint:`${t.cacheKey};${b};${m};${S};${I};${T};${v};${x};${k}`,inputDependencies:C},getRunData:()=>({outputs:[{dims:u?u(n):n,dataType:e[0].dataType}],dispatchGroup:{x:$[0],y:$[1],z:$[2]},programUniforms:E}),getShaderSource:i=>{const r=[{name:"dim_a_outer",type:"i32"},{name:"dim_b_outer",type:"i32"},{name:"dim_inner",type:"i32"},{name:"pad",type:"i32",length:2},{name:"stride",type:"i32",length:2},{name:"dilation",type:"i32",length:2}];Nr(t,r);const s=m?4:1,u=Lt(e[0].dataType);let l=`\n      fn setOutputAtIndex(flatIndex : i32, value : ${m?`vec4<${u}>`:u}) {\n        result[flatIndex] = ${m?`vec4<${u}>`:u}(value);\n      }\n      fn setOutputAtCoords(d0 : i32, d1 : i32, d2 : i32, d3 : i32, value : ${m?`vec4<${u}>`:u}) {\n        let flatIndex = getOutputIndexFromCoords(vec4<i32>(d0, d1, d2, d3));\n        setOutputAtIndex(flatIndex ${m?"/ 4":""}, value);\n      }`;const p=[Xt("x",e[0].dataType,e[0].dims.length,3===b?1:b),Xt("w",e[1].dataType,e[1].dims.length,s)],c=Yt("result",e[0].dataType,n.length,s);if(a){const t=Xt("bias",e[2].dataType,e[2].dims.length,s);p.push(t),l+=`\n        fn getBiasByOutputCoords(coords : vec4<i32>) -> ${m?`vec4<${u}>`:u} {\n          return bias[coords.${d?"w":"y"}${m?"/ 4":""}];\n        }`}return`\n        ${Wr("uniforms.result_strides")}\n        //struct Uniforms { xShape : vec4<i32>, wShape : vec4<i32>, outShape : vec4<i32>,\n        //  outShapeStrides: vec3<i32>, filterDims : vec2<i32>, pad : vec2<i32>, stride : vec2<i32>,\n        //  dilation : vec2<i32>, dimAOuter : i32, dimBOuter : i32, dimInner : i32 };\n        ${i.registerUniforms(r).declareVariables(...p,c)}\n        ${l}\n        ${ts(d,S,I,T,a,t,z[0],z[1],z[2],u)}\n        ${m?Zr(y,w,u,void 0,!d,k):Yr(y,w,u,void 0,!d,k,!1,void 0,o)}`}}}}}),Ad=P({"web/lib/wasm/jsep/webgpu/ops/3rd-party/conv3d_naive_webgpu.ts"(){rd(),ad(),od(),fd(),Id(),Td(),is=e=>{let t=1;for(let n=0;n<e.length;n++)t*=e[n];return t},rs=e=>"number"==typeof e?[e,e,e]:e,ss=(e,t)=>t<=1?e:e+(e-1)*(t-1),as=(e,t,n,i=1)=>{const r=ss(t,i);return Math.floor((e[0]*(n-1)-n+r)/2)},os=(e,t,n,i,r)=>{null==r&&(r=as(e,t[0],i[0]));const s=[0,0,0,n];for(let n=0;n<3;n++)e[n]+2*r>=t[n]&&(s[n]=Math.trunc((e[n]-t[n]+2*r)/i[n]+1));return s},us=(e,t,n,i,r,s,a,o,u,d)=>{let l,p,c,h;if("VALID"===e&&(e=0),"number"==typeof e){l={top:e,bottom:e,left:e,right:e,front:e,back:e};const f=os([t,n,i,1],[o,u,d],1,[r,s,a],e);p=f[0],c=f[1],h=f[2]}else if(Array.isArray(e)){if(!e.every((e,t,n)=>e===n[0]))throw Error(`Unsupported padding parameter: ${e}`);l={top:e[0],bottom:e[1],left:e[2],right:e[3],front:e[4],back:e[5]};const f=os([t,n,i,1],[o,u,d],1,[r,s,a],e[0]);p=f[0],c=f[1],h=f[2]}else{if("SAME_UPPER"!==e)throw Error(`Unknown padding parameter: ${e}`);{p=Math.ceil(t/r),c=Math.ceil(n/s),h=Math.ceil(i/a);const e=(p-1)*r+o-t,f=(c-1)*s+u-n,m=(h-1)*a+d-i,g=Math.floor(e/2),_=e-g,w=Math.floor(f/2),y=f-w,$=Math.floor(m/2);l={top:w,bottom:y,left:$,right:m-$,front:g,back:_}}}return{padInfo:l,outDepth:p,outHeight:c,outWidth:h}},ds=(e,t,n,i,r,s=!1,a="channelsLast")=>{let o,u,d,l,p;if("channelsLast"===a)[o,u,d,l,p]=e;else{if("channelsFirst"!==a)throw new Error(`Unknown dataFormat ${a}`);[o,p,u,d,l]=e}const[c,,h,f,m]=t,[g,_,w]=rs(n),[y,$,b]=rs(i),v=ss(h,y),x=ss(f,$),k=ss(m,b),{padInfo:S,outDepth:I,outHeight:T,outWidth:z}=us(r,u,d,l,g,_,w,v,x,k),E=s?c*p:c;let C=[0,0,0,0,0];return"channelsFirst"===a?C=[o,E,I,T,z]:"channelsLast"===a&&(C=[o,I,T,z,E]),{batchSize:o,dataFormat:a,inDepth:u,inHeight:d,inWidth:l,inChannels:p,outDepth:I,outHeight:T,outWidth:z,outChannels:E,padInfo:S,strideDepth:g,strideHeight:_,strideWidth:w,filterDepth:h,filterHeight:f,filterWidth:m,effectiveFilterDepth:v,effectiveFilterHeight:x,effectiveFilterWidth:k,dilationDepth:y,dilationHeight:$,dilationWidth:b,inShape:e,outShape:C,filterShape:t}},ls=(e,t,n,i,r,s)=>{const a="channelsLast"===s,o=(a?e[0].dims[3]:e[0].dims[1],{x:n.map((e,t)=>t)}),u=[Math.ceil(is(o.x.map(e=>n[e]))/64),1,1];at("verbose",()=>`[conv3d_naive_webgpu] dispatch = ${u}`);const d=[{type:12,data:dt.size(n)},{type:12,data:i},{type:12,data:r},{type:12,data:t.strides},{type:12,data:t.dilations}];qr(t,d),d.push(...Wt(e[0].dims,e[1].dims));const l=["rank","rank"],p=3===e.length;return p&&(d.push(...Wt(e[2].dims)),l.push("rank")),d.push(...Wt(n)),{name:"Conv3DNaive",shaderCache:{hint:`${t.cacheKey};${a};1;${p}`,inputDependencies:l},getRunData:()=>({outputs:[{dims:n,dataType:e[0].dataType}],dispatchGroup:{x:u[0],y:u[1],z:u[2]},programUniforms:d}),getShaderSource:s=>{const o=[{name:"output_size",type:"u32"},{name:"filter_dims",type:"u32",length:i.length},{name:"pads",type:"u32",length:r.length},{name:"strides",type:"u32",length:t.strides.length},{name:"dilations",type:"u32",length:t.dilations.length}];Nr(t,o);const u=Lt(e[0].dataType),d=Xt("x",e[0].dataType,e[0].dims.length,1),l=Xt("W",e[1].dataType,e[1].dims.length,1),c=[d,l],h=Yt("result",e[0].dataType,n.length,1);let f="";if(p){const t=Xt("bias",e[2].dataType,e[2].dims.length,1);c.push(t),f+=`\n        fn getBiasByOutputCoords(coords : array<u32, 5>) -> ${u} {\n          return bias[${Zt("coords",a?4:1,5)}];\n        }`}const m=Lr(1,u),g=Pr(t,m,u);return`\n            ${f}\n            fn getX(d0 : u32, d1 : u32, d2 : u32, d3 : u32, d4 : u32) -> f32 {\n              let aIndices = array<u32, 5>(d0, d1, d2, d3, d4);\n              return ${d.getByIndices("aIndices")};\n            }\n            fn getW(d0 : u32, d1 : u32, d2 : u32, d3 : u32, d4 : u32) -> f32 {\n              let aIndices = array<u32, 5>(d0, d1, d2, d3, d4);\n              return ${l.getByIndices("aIndices")};\n            }\n          ${s.registerUniforms(o).declareVariables(...c,h)}\n          ${s.mainStart()}\n          ${s.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n              let coords = ${h.offsetToIndices("global_idx")};\n              let batch = ${Zt("coords",0,d.rank)};\n              let d2 = ${Zt("coords",a?d.rank-1:1,d.rank)};\n              let xFRCCorner = vec3<u32>(${Zt("coords",a?1:2,d.rank)},\n              ${Zt("coords",a?2:3,d.rank)},\n              ${Zt("coords",a?3:4,d.rank)}) * uniforms.strides - uniforms.pads;\n              let xFCorner = xFRCCorner.x;\n              let xRCorner = xFRCCorner.y;\n              let xCCorner = xFRCCorner.z;\n              let xShapeY = ${Zt("uniforms.x_shape",a?1:2,d.rank)};\n              let xShapeZ = ${Zt("uniforms.x_shape",a?2:3,d.rank)};\n              let xShapeW = ${Zt("uniforms.x_shape",a?3:4,d.rank)};\n              let xShapeU = ${Zt("uniforms.x_shape",a?4:1,d.rank)};\n              let inputDepthNearestVec4 = (xShapeU / 4) * 4;\n              let inputDepthVec4Remainder = xShapeU % 4;\n\n              var value = 0.0;\n              for (var wF = 0u; wF < uniforms.filter_dims[0]; wF++) {\n                let xF = xFCorner + wF * uniforms.dilations[0];\n                if (xF < 0 || xF >= xShapeY) {\n                  continue;\n                }\n\n                for (var wR = 0u; wR < uniforms.filter_dims[1]; wR++) {\n                  let xR = xRCorner + wR * uniforms.dilations[1];\n                  if (xR < 0 || xR >= xShapeZ) {\n                    continue;\n                  }\n\n                  for (var wC = 0u; wC < uniforms.filter_dims[2]; wC++) {\n                    let xC = xCCorner + wC * uniforms.dilations[2];\n                    if (xC < 0 || xC >= xShapeW) {\n                      continue;\n                    }\n\n                    for (var d1 = 0u; d1 < inputDepthNearestVec4; d1 += 4) {\n                      ${a?"let xValues = vec4<f32>(\n                               getX(batch, xF, xR, xC, d1),\n                               getX(batch, xF, xR, xC, d1 + 1),\n                               getX(batch, xF, xR, xC, d1 + 2),\n                               getX(batch, xF, xR, xC, d1 + 3));\n                            ":"let xValues = vec4<f32>(\n                               getX(batch, d1, xF, xR, xC),\n                               getX(batch, d1 + 1, xF, xR, xC),\n                               getX(batch, d1 + 2, xF, xR, xC),\n                               getX(batch, d1 + 3, xF, xR, xC));\n                            "}\n                            let wValues = vec4<f32>(\n                              getW(d2, d1, wF, wR, wC),\n                              getW(d2, d1 + 1, wF, wR, wC),\n                              getW(d2, d1 + 2, wF, wR, wC),\n                              getW(d2, d1 + 3, wF, wR, wC));\n                      value += dot(xValues, wValues);\n                    }\n                    if (inputDepthVec4Remainder == 1) {\n                        ${a?"value += getX(batch, xF, xR, xC, inputDepthNearestVec4)\n                          * getW(d2, inputDepthNearestVec4, wF, wR, wC);":"value += getX(batch, inputDepthNearestVec4, xF, xR, xC)\n                          * getW(d2, inputDepthNearestVec4, wF, wR, wC);"}\n                    } else if (inputDepthVec4Remainder == 2) {\n                      ${a?"let xValues = vec2<f32>(\n                        getX(batch, xF, xR, xC, inputDepthNearestVec4),\n                        getX(batch, xF, xR, xC, inputDepthNearestVec4 + 1));\n                      ":"let xValues = vec2<f32>(\n                        getX(batch, inputDepthNearestVec4, xF, xR, xC),\n                        getX(batch, inputDepthNearestVec4 + 1, xF, xR, xC));\n                    "}\n                    let wValues = vec2<f32>(\n                      getW(d2, inputDepthNearestVec4, wF, wR, wC),\n                      getW(d2, inputDepthNearestVec4 + 1, wF, wR, wC));\n                      value += dot(xValues, wValues);\n                    } else if (inputDepthVec4Remainder == 3) {\n                      ${a?"let xValues = vec3<f32>(\n                        getX(batch, xF, xR, xC, inputDepthNearestVec4),\n                        getX(batch, xF, xR, xC, inputDepthNearestVec4 + 1),\n                        getX(batch, xF, xR, xC, inputDepthNearestVec4 + 2));\n                      ":"let xValues = vec3<f32>(\n                        getX(batch, inputDepthNearestVec4, xF, xR, xC),\n                        getX(batch, inputDepthNearestVec4 + 1, xF, xR, xC),\n                        getX(batch, inputDepthNearestVec4 + 2, xF, xR, xC));\n                    "}\n                    let wValues = vec3<f32>(\n                      getW(d2, inputDepthNearestVec4, wF, wR, wC),\n                      getW(d2, inputDepthNearestVec4 + 1, wF, wR, wC),\n                      getW(d2, inputDepthNearestVec4 + 2, wF, wR, wC));\n                      value += dot(xValues, wValues);\n                    }\n                  }\n                }\n              }\n              ${p?"value = value + getBiasByOutputCoords(coords)":""};\n              ${g}\n              result[global_idx] = f32(value);\n          }`}}}}}),Bd=P({"web/lib/wasm/jsep/webgpu/ops/conv-grouped.ts"(){rd(),od(),fd(),Id(),ps=(e,t,n,i)=>{const r=e.length>2,s=r?"value += b[output_channel];":"",a=e[0].dims,o=e[1].dims,u="NHWC"===t.format,d=u?n[3]:n[1],l=d/t.group,p=u&&l>=4?jt(d):1,c=dt.size(n)/p,h=[{type:12,data:c},{type:12,data:t.dilations},{type:12,data:[t.strides[0],t.strides[1]]},{type:12,data:[t.pads[0],t.pads[1]]},{type:12,data:l}];qr(t,h),h.push(...Wt(a,[o[0],o[1],o[2],o[3]/p]));const f=r?["rank","rank","rank"]:["rank","rank"];return h.push(...Wt([n[0],n[1],n[2],n[3]/p])),{name:"GroupedConv",shaderCache:{hint:`${t.cacheKey}_${p}`,inputDependencies:f},getRunData:()=>({outputs:[{dims:i?i(n):n,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(c/64)},programUniforms:h}),getShaderSource:i=>{const d=Yt("output",e[0].dataType,n.length,p),l=Lt(d.type.tensor),c=Pr(t,d.type.value,l),h=Xt("x",e[0].dataType,a.length),f=Xt("w",e[1].dataType,o.length,p),m=[h,f];r&&m.push(Xt("b",e[2].dataType,e[2].dims,p));const g=[{name:"output_size",type:"u32"},{name:"dilations",type:"u32",length:t.dilations.length},{name:"strides",type:"u32",length:2},{name:"pads",type:"u32",length:2},{name:"output_channels_per_group",type:"u32"}];Nr(t,g);const _=u?`\n      for (var wHeight: u32 = 0u; wHeight < uniforms.w_shape[0]; wHeight++) {\n        let xHeight = xRCCorner.x + wHeight * uniforms.dilations[0];\n\n        if (xHeight < 0u || xHeight >= uniforms.x_shape[1]) {\n          continue;\n        }\n\n        for (var wWidth: u32 = 0u; wWidth < uniforms.w_shape[1]; wWidth++) {\n          let xWidth = xRCCorner.y + wWidth * uniforms.dilations[1];\n          if (xWidth < 0u || xWidth >= uniforms.x_shape[2]) {\n            continue;\n          }\n\n          for (var wInChannel: u32 = 0u; wInChannel < uniforms.w_shape[2]; wInChannel++) {\n            let input_channel = in_channel_offset + wInChannel;\n            let xVal = ${h.get("batch","xHeight","xWidth","input_channel")};\n            let wVal = ${f.get("wHeight","wWidth","wInChannel","output_channel")};\n            value += xVal * wVal;\n          }\n        }\n      }\n      `:`\n      for (var wInChannel: u32 = 0u; wInChannel < uniforms.w_shape[1]; wInChannel++) {\n        let input_channel = in_channel_offset + wInChannel;\n        for (var wHeight: u32 = 0u; wHeight < uniforms.w_shape[2]; wHeight++) {\n          let xHeight = xRCCorner.x + wHeight * uniforms.dilations[0];\n\n          if (xHeight < 0u || xHeight >= uniforms.x_shape[2]) {\n            continue;\n          }\n\n          for (var wWidth: u32 = 0u; wWidth < uniforms.w_shape[3]; wWidth++) {\n            let xWidth = xRCCorner.y + wWidth * uniforms.dilations[1];\n            if (xWidth < 0u || xWidth >= uniforms.x_shape[3]) {\n              continue;\n            }\n\n            let xVal = ${h.get("batch","input_channel","xHeight","xWidth")};\n            let wVal = ${f.get("output_channel","wInChannel","wHeight","wWidth")};\n            value += xVal * wVal;\n          }\n        }\n      }\n      `;return`\n  ${i.registerUniforms(g).declareVariables(...m,d)}\n\n  ${i.mainStart()}\n    ${i.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n\n    let outputIndices = ${d.offsetToIndices("global_idx")};\n    let batch: u32 = outputIndices[0];\n    let output_channel: u32 = outputIndices[${u?3:1}];\n    let xRCCorner: vec2<u32> = vec2<u32>(outputIndices[${u?1:2}], outputIndices[${u?2:3}]) * uniforms.strides - uniforms.pads;\n    let group_id: u32 = output_channel * ${p} / uniforms.output_channels_per_group;\n    var in_channel_offset = group_id * uniforms.w_shape[${u?2:1}];\n\n    var value: ${d.type.value} = ${d.type.value}(0);\n    ${_}\n    ${s}\n    ${c}\n    ${d.setByOffset("global_idx","value")}\n  }`}}},cs=(e,t,n,i)=>{const r=e.length>2,s=jt(n[3]),a=jt(n[2]),o=dt.size(n)/s/a,u=[e[0].dims[0],e[0].dims[1],e[0].dims[2],e[0].dims[3]/s],d=[e[1].dims[0],e[1].dims[1],e[1].dims[2],e[1].dims[3]/s],l=[n[0],n[1],n[2],n[3]/s],p=[{type:12,data:o},{type:6,data:[t.strides[0],t.strides[1]]},{type:6,data:[t.pads[0],t.pads[1]]}];qr(t,p),p.push(...Wt(u,d,l));const c=(a-1)*t.strides[1]+d[1];return{name:"GroupedConv-Vectorize",shaderCache:{hint:`${t.cacheKey};${s};${a};${c};${d[0]};${d[1]}`,inputDependencies:r?["rank","rank","type"]:["rank","rank"]},getRunData:()=>({outputs:[{dims:i?i(n):n,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(o/64)},programUniforms:p}),getShaderSource:n=>{const i=Yt("output",e[0].dataType,l.length,s),o=Lt(i.type.tensor),p=Pr(t,i.type.value,o),h=Xt("x",e[0].dataType,u.length,s),f=Xt("w",e[1].dataType,d.length,s),m=[h,f];r&&m.push(Xt("b",e[2].dataType,e[2].dims,s));const g=r?"value += b[output_channel];":"",_=[{name:"output_size",type:"u32"},{name:"strides",type:"i32",length:2},{name:"pads",type:"i32",length:2}];return Nr(t,_),`\n  ${n.registerUniforms(_).declareVariables(...m,i)}\n  ${n.mainStart()}\n    ${n.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n    let width0 = uniforms.output_shape[3];\n    let output_channel = global_idx % width0;\n    var index1 = global_idx / width0;\n    let width1 = uniforms.output_shape[2] / ${a}u;\n    let col = (index1 % width1) * ${a}u;\n    index1 = index1 / width1;\n    let row = index1 % uniforms.output_shape[1];\n    let batch = index1 / uniforms.output_shape[1];\n\n    let x_corner = vec2<i32>(i32(row), i32(col)) * uniforms.strides - uniforms.pads;\n\n    var x_vals: array<${h.type.value}, ${c}>;\n    var values: array<${i.type.value}, ${a}>;\n    let input_channel = output_channel;\n    // Use constant instead of uniform can give better performance for w's height/width.\n    for (var w_height: u32 = 0u; w_height < ${d[0]}; w_height++) {\n      let x_height = x_corner.x + i32(w_height);\n      if (x_height >= 0 && u32(x_height) < uniforms.x_shape[1]) {\n        for (var i = 0; i < ${c}; i++) {\n          let x_width = x_corner.y + i;\n          if (x_width >= 0 && u32(x_width) < uniforms.x_shape[2]) {\n            x_vals[i] = ${h.get("batch","u32(x_height)","u32(x_width)","input_channel")};\n          } else {\n            x_vals[i] = ${h.type.value}(0);\n          }\n        }\n        for (var w_width: u32 = 0u; w_width < ${d[1]}; w_width++) {\n          let w_val = ${f.get("w_height","w_width","0","output_channel")};\n          for (var i = 0u; i < ${a}u; i++) {\n            values[i] = fma(x_vals[i * u32(uniforms.strides[1]) + w_width], w_val, values[i]);\n          }\n        }\n      }\n    }\n\n    for (var i = 0u; i < ${a}u; i++) {\n      var value = values[i];\n      ${g}\n      ${p}\n      ${i.set("batch","row","col + i","output_channel","value")};\n    }\n  }`}}}}}),Rd=P({"web/lib/wasm/jsep/webgpu/ops/conv.ts"(){od(),Od(),Ad(),Cd(),Bd(),Id(),Ed(),md(),hs=(e,t,n,i,r,s)=>{const a=e[0],o=e.slice(s?1:2,s?3:4),u=o.length,d=t[0],l=t.slice(2).map((e,t)=>e+(e-1)*(n[t]-1)),p=o.map((e,t)=>e+i[t]+i[t+u]).map((e,t)=>Math.floor((e-l[t]+r[t])/r[t]));return p.splice(0,0,a),p.splice(s?3:1,0,d),p},fs=[2,3,1,0],ms=(e,t)=>{if(!e||2!==e.length&&3!==e.length)throw new Error("Conv requires 2 or 3 inputs");if(e[0].dims.length>5)throw new Error("greater than 5D is not supported");if(e[0].dims.length!==e[1].dims.length)throw new Error("filter does not have same dimension as input");if(e[0].dims["NHWC"===t.format?e[0].dims.length-1:1]!==e[1].dims[1]*t.group)throw new Error("FILTER_IN_CHANNEL should be equal to DATA_CHANNEL");if(3===e.length&&(1!==e[2].dims.length||e[1].dims[0]!==e[2].dims[0]))throw new Error("invalid bias");const n=e[0].dims.length-2;if(t.dilations.length!==n)throw new Error(`dilations should be ${n}D`);if(t.strides.length!==n)throw new Error(`strides should be ${n}D`);if(t.pads.length!==2*n)throw new Error(`pads should be ${2*n}D`);if(0!==t.kernelShape.length&&t.kernelShape.length!==e[1].dims.length-2)throw new Error("invalid kernel shape")},gs=(e,t)=>{const n=e.kernelShape.slice();n.length<t[1].dims.length-2&&n.push(...Array(t[1].dims.length-2-n.length).fill(0));for(let e=2;e<t[1].dims.length;++e)0===n[e-2]&&(n[e-2]=t[1].dims[e]);const i=e.pads.slice();lt.adjustPadsBasedOnAutoPad(t[0].dims,e.strides,e.dilations,n,i,"NHWC"===e.format,e.autoPad);const r=Object.assign({},e);return Object.assign(r,{kernelShape:n,pads:i}),r},_s=e=>{const t=Vr(e),n=e.format;return{autoPad:["NOTSET","VALID","SAME_UPPER","SAME_LOWER"][e.auto_pad],format:n,dilations:e.dilations,group:e.group,kernelShape:e.kernel_shape,pads:e.pads,strides:e.strides,wIsConst:e.w_is_const(),...t,cacheKey:`${e.format};${t.activation};`}},ws=(e,t,n,i)=>{const r="NHWC"===n.format,s=hs(t[0].dims,t[1].dims,n.dilations,n.pads,n.strides,r);if(1!==n.group){const a=[t[0]];if(r){const i=e.kernelCustomData.wT??e.compute(ln(t[1],fs),{inputs:[1],outputs:[n.wIsConst?-2:-1]})[0];n.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=i),a.push(i)}else a.push(t[1]);return 3===t.length&&a.push(t[2]),void(!e.adapterInfo.isArchitecture("ampere")&&r&&t[1].dims[0]===n.group&&1===t[1].dims[1]&&1===n.dilations[0]&&1===n.dilations[1]?e.compute(cs(a,n,s,i),{inputs:a}):e.compute(ps(a,n,s,i),{inputs:a}))}const a=3===t.length,o=t[0].dims[r?1:2],u=t[0].dims[r?2:3],d=t[0].dims[r?3:1],l=t[1].dims[2],p=t[1].dims[3],c=s[r?1:2],h=s[r?2:3],f=s[r?3:1],m=r&&l===o&&p===u&&0===n.pads[0]&&0===n.pads[1];if(m||1===l&&1===p&&1===n.dilations[0]&&1===n.dilations[1]&&1===n.strides[0]&&1===n.strides[1]&&0===n.pads[0]&&0===n.pads[1]){const l=s[0];let p,g,_;const w=[];if(r){const i=e.kernelCustomData.wT??e.compute(ln(t[1],fs),{inputs:[1],outputs:[n.wIsConst?-2:-1]})[0];if(n.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=i),m){const e=o*u*d;p=t[0].reshape([1,l,e]),g=i.reshape([1,e,f]),_=[1,l,f]}else p=t[0].reshape([l,o*u,d]),g=i.reshape([1,d,f]),_=[l,c*h,f];w.push(p),w.push(g)}else p=t[0].reshape([l,d,o*u]),g=t[1].reshape([1,f,d]),_=[l,f,c*h],w.push(g),w.push(p);a&&w.push(t[2]);const y=_[2],$=w[0].dims[w[0].dims.length-1];return void(y<8&&$<8?e.compute(Hr(w,n,s,_,r,i),{inputs:w}):e.compute(es(w,n,s,_,r,i),{inputs:w}))}const g=e.kernelCustomData.wT??e.compute(ln(t[1],fs),{inputs:[1],outputs:[n.wIsConst?-2:-1]})[0];n.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=g);const _=[t[0],g];a&&_.push(t[2]);const w=r?c*h:f,y=r?f:c*h,$=l*p*d;e.compute(ns(_,n,s,w,y,$,a,!0,i),{inputs:_})},ys=(e,t)=>{const n="NHWC"===t.format,i=[e.inputs[0].reshape(n?[e.inputs[0].dims[0],1,e.inputs[0].dims[1],e.inputs[0].dims[2]]:[e.inputs[0].dims[0],e.inputs[0].dims[1],1,e.inputs[0].dims[2]]),e.inputs[1].reshape([e.inputs[1].dims[0],e.inputs[1].dims[1],1,e.inputs[1].dims[2]])];3===e.inputs.length&&i.push(e.inputs[2]);const r=[0,t.pads[0],0,t.pads[1]],s=[1].concat(t.strides),a=[1].concat(t.dilations),o=[1].concat(t.kernelShape),u=gs({...t,pads:r,strides:s,dilations:a,kernelShape:o},i);ws(e,i,u,e=>n?[e[0],e[2],e[3]]:[e[0],e[1],e[3]])},$s=(e,t,n)=>{const i="NHWC"===n.format?"channelsLast":"channelsFirst",r=gs(n,t),s="NOTSET"===n.autoPad?n.pads:n.autoPad,a=ds(t[0].dims,t[1].dims,n.strides,n.dilations,s,!1,i);e.compute(ls(t,r,a.outShape,[a.filterDepth,a.filterHeight,a.filterWidth],[a.padInfo.front,a.padInfo.top,a.padInfo.left],i))},bs=(e,t)=>{if(ms(e.inputs,t),3===e.inputs[0].dims.length)ys(e,t);else if(5===e.inputs[0].dims.length)$s(e,e.inputs,t);else{const n=gs(t,e.inputs);ws(e,e.inputs,n)}}}}),Dd=P({"web/lib/wasm/jsep/webgpu/ops/3rd-party/conv_backprop_webgpu.ts"(){rd(),ad(),od(),fd(),vs=(e,t,n)=>{const i=e.length>2,r=t.outputShape,s="NHWC"===t.format,a=t.group,o=e[1].dims,u=o[2]/a,d=o[3],l=s?jt(u):1,p=s&&1===d&&u>=4,c=p?4*Math.floor(u/4):Math.floor(u/l)*l,h=u-c,f=s?jt(d):1,m=s?1===d?l:f:1,g=dt.size(r)/f,_=[Math.ceil(g/64),1,1];at("verbose",()=>`[conv2d_backprop_webgpu] dispatch = ${_}`);const w=["rank","rank"],y=[t.strides[0],t.strides[1]],$=[t.kernelShape[s?1:2],t.kernelShape[s?2:3]],b=[t.dilations[0],t.dilations[1]],v=[$[0]+(t.dilations[0]<=1?0:(t.kernelShape[s?1:2]-1)*(t.dilations[0]-1)),$[1]+(t.dilations[1]<=1?0:(t.kernelShape[s?2:3]-1)*(t.dilations[1]-1))],x=[v[0]-1-Math.floor((t.pads[0]+t.pads[2])/2),v[1]-1-Math.floor((t.pads[1]+t.pads[3])/2)],k=[{type:12,data:g},{type:12,data:y},{type:12,data:$},{type:12,data:b},{type:12,data:v},{type:6,data:x},{type:12,data:c},{type:12,data:u},{type:12,data:d},...Wt(e[0].dims,e[1].dims)];return i&&(k.push(...Wt(e[2].dims)),w.push("rank")),k.push(...Wt(r)),{name:"ConvTranspose2D",shaderCache:{hint:`${t.cacheKey};${l}${m}${f}${p}${h}`,inputDependencies:w},getRunData:()=>({dispatchGroup:{x:_[0],y:_[1],z:_[2]},outputs:[{dims:n?n(r):r,dataType:e[0].dataType}],programUniforms:k}),getShaderSource:t=>{const n=[{name:"output_size",type:"u32"},{name:"strides",type:"u32",length:y.length},{name:"filter_dims",type:"u32",length:$.length},{name:"dilations",type:"u32",length:$.length},{name:"effective_filter_dims",type:"u32",length:v.length},{name:"pads",type:"i32",length:x.length},{name:"input_channels_per_group_int",type:"u32"},{name:"input_channels_per_group",type:"u32"},{name:"output_channels_per_group",type:"u32"}],a=Lt(e[0].dataType),o=s?1:2,u=s?2:3,d=s?3:1,c=Xt("W",e[1].dataType,e[1].dims.length,m),g=Xt("Dy",e[0].dataType,e[0].dims.length,l),_=[g,c];i&&_.push(Xt("bias",e[2].dataType,[r[d]].length,f));const w=Yt("result",e[0].dataType,r.length,f),b=`\n            let outputIndices = ${w.offsetToIndices(`global_idx * ${f}`)};\n            let batch = ${w.indicesGet("outputIndices",0)};\n            let d1 = ${w.indicesGet("outputIndices",d)};\n            let r = ${w.indicesGet("outputIndices",o)};\n            let c = ${w.indicesGet("outputIndices",u)};\n            let dyCorner = vec2<i32>(i32(r), i32(c)) - uniforms.pads;\n            let dyRCorner = dyCorner.x;\n            let dyCCorner = dyCorner.y;\n            let groupId = d1 / uniforms.output_channels_per_group;\n            let wOutChannel = d1 - groupId * uniforms.output_channels_per_group;\n            // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n            // ? = to be determined. : = across all values in that axis.\n            var dotProd = ${w.type.value}(0.0);\n            var wR: u32 = 0;\n            if (uniforms.dilations.x == 1) {\n              // Minimum wR >= 0 that satisfies (dyRCorner + wR) % (uniforms.strides.x) == 0\n              wR = u32(((dyRCorner + i32(uniforms.strides.x) - 1) / i32(uniforms.strides.x)) * i32(uniforms.strides.x) - dyRCorner);\n            }\n            for (; wR < uniforms.effective_filter_dims.x; wR = wR + 1) {\n              if (wR % uniforms.dilations.x != 0) {\n                continue;\n              }\n              let dyR = (${a}(dyRCorner) + ${a}(wR)) / ${a}(uniforms.strides[0]);\n              let wRPerm = uniforms.filter_dims.x - 1 - wR / uniforms.dilations.x;\n              if (dyR < 0.0 || dyR >= ${a}(uniforms.Dy_shape[${o}]) || fract(dyR) > 0.0 ||\n                  wRPerm < 0) {\n                continue;\n              }\n              let idyR: u32 = u32(dyR);\n              var wC: u32 = 0;\n              if (uniforms.dilations.y == 1) {\n                // Minimum wC >= 0 that satisfies (dyCCorner + wC) % (uniforms.strides.y) == 0\n                wC = u32(((dyCCorner + i32(uniforms.strides.y) - 1) / i32(uniforms.strides.y)) * i32(uniforms.strides.y) - dyCCorner);\n              }\n              for (; wC < uniforms.effective_filter_dims.y; wC = wC + 1) {\n                if (wC % uniforms.dilations.y != 0) {\n                  continue;\n                }\n                let dyC = (${a}(dyCCorner) + ${a}(wC)) / ${a}(uniforms.strides.y);\n                let wCPerm = uniforms.filter_dims.y - 1 - wC / uniforms.dilations.y;\n                if (dyC < 0.0 || dyC >= ${a}(uniforms.Dy_shape[${u}]) ||\n                    fract(dyC) > 0.0 || wCPerm < 0) {\n                  continue;\n                }\n                let idyC: u32 = u32(dyC);\n                var inputChannel = groupId * uniforms.input_channels_per_group;\n                ${p?`\n                var x_offset = ${g.indicesToOffset(`${g.type.indices}(batch, idyR, idyC, inputChannel)`)} / ${l};\n                var w_offset = ${c.indicesToOffset(`${c.type.indices}(wRPerm, wCPerm, inputChannel, wOutChannel)`)} / ${m};\n                  `:""}\n                for (var d2: u32 = 0; d2 < uniforms.input_channels_per_group_int; d2 = d2 + ${p?4:l}) {\n                  ${(()=>{let e="";if(p)4===l?e+=`\n        let xValue = ${g.getByOffset("x_offset")};\n        let wValue = ${c.getByOffset("w_offset")};\n        dotProd = dotProd + dot(xValue, wValue);\n        x_offset += 1u;\n        w_offset += 1u;`:2===l?e+=`\n          dotProd = dotProd + dot(vec4<${a}>(${g.getByOffset("x_offset")}, ${g.getByOffset("x_offset + 1u")}), vec4<${a}>(${c.getByOffset("w_offset")}, ${c.getByOffset("w_offset + 1u")}));\n          x_offset += 2u;\n          w_offset += 2u;`:1===l&&(e+=`\n          dotProd = dotProd + dot(vec4<${a}>(${g.getByOffset("x_offset")}, ${g.getByOffset("x_offset + 1u")}, ${g.getByOffset("x_offset + 2u")}, ${g.getByOffset("x_offset + 3u")}), vec4<${a}>(${c.getByOffset("w_offset")}, ${c.getByOffset("w_offset + 1u")}, ${c.getByOffset("w_offset + 2u")}, ${c.getByOffset("w_offset + 3u")}));\n          x_offset += 4u;\n          w_offset += 4u;`);else if(e+=`\n                  let xValue = ${s?g.getByOffset(`${g.indicesToOffset(`${g.type.indices}(batch, idyR, idyC, inputChannel)`)} / ${l}`):g.get("batch","inputChannel","idyR","idyC")};\n        `,1===l)e+=`\n          let w_offset = ${c.indicesToOffset(`${c.type.indices}(u32(wRPerm), u32(wCPerm), inputChannel, wOutChannel)`)};\n          let wValue = ${c.getByOffset(`w_offset / ${m}`)};\n          dotProd = dotProd + xValue * wValue;`;else for(let t=0;t<l;t++)e+=`\n            let wValue${t} = ${c.getByOffset(`${c.indicesToOffset(`${c.type.indices}(u32(wRPerm), u32(wCPerm), inputChannel + ${t}, wOutChannel)`)} / ${m}`)};\n            dotProd = dotProd + xValue[${t}] * wValue${t};`;return e})()}\n                  inputChannel = inputChannel + ${p?4:l};\n                }\n                ${(()=>{if(0===h)return"";if(!p)throw new Error(`packInputAs4 ${p} is not true.`);let e="";if(1===l){e+="dotProd = dotProd";for(let t=0;t<h;t++)e+=`\n            + ${g.getByOffset(`x_offset + ${t}`)} * ${c.getByOffset(`w_offset + ${t}`)}`;e+=";"}else if(2===l){if(2!==h)throw new Error(`Invalid inputChannelsRemainder ${h}.`);e+=`\n          let xValue = ${g.getByOffset("x_offset")};\n          let wValue = ${c.getByOffset("w_offset")};\n          dotProd = dotProd + dot(xValue, wValue);`}return e})()}\n                wC = wC + uniforms.strides.y - 1;\n              }\n              wR = wR + uniforms.strides[0] - 1;\n            }\n            let value = dotProd${i?` + bias[d1 / ${f}]`:""};\n            ${w.setByOffset("global_idx","value")};\n          `;return`\n    ${t.registerUniforms(n).declareVariables(..._,w)}\n      ${t.mainStart()}\n      ${t.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")};\n    ${b}}`}}}}}),Md=P({"web/lib/wasm/jsep/webgpu/ops/conv-transpose.ts"(){Dd(),Id(),md(),xs=(e,t,n,i,r,s)=>(e-1)*t+n+(i-1)*r+1-s,ks=(e,t,n,i,r)=>{const s=Math.floor(e/2);"SAME_UPPER"===t?(n[i]=s,n[r]=e-s):"SAME_LOWER"===t&&(n[i]=e-s,n[r]=s)},Ss=(e,t,n,i,r,s,a,o,u,d)=>{const l=e.length-2,p=0===d.length;u.length<l&&u.push(...Array(l-u.length).fill(0));const c=e[0],h=t[o?3:1]*r;for(let r=0,c=e.length-l-(o?1:0);r<l;++r,++c){const o=e[c],h=p?o*a[r]:d[r],f=xs(o,a[r],s[r],t[c],n[r],h);ks(f,i,s,r,r+l),p&&d.push(a[r]*(o-1)+u[r]+(t[c]-1)*n[r]+1-s[r]-s[r+l])}d.splice(0,0,c),d.splice(o?3:1,0,h)},Is=(e,t)=>{const n=e.kernelShape.slice();if(0===e.kernelShape.length||0===e.kernelShape.reduce((e,t)=>e*t,1)){n.length=0;for(let e=2;e<t[1].dims.length;++e)n.push(t[1].dims[e])}const i="NHWC"===e.format;n.splice(0,0,t[1].dims[0]),n.splice(i?3:1,0,t[1].dims[1]);const r=e.pads.slice(),s=e.outputShape.slice(),a=e.outputPadding.slice(),o=t[0].dims;let u=e.dilations.slice();if(0===u.reduce((e,t)=>e+t,0)){const e=t[0].dims.length-2;u=new Array(e).fill(1)}let d=e.strides.slice();if(0===d.reduce((e,t)=>e+t,0)){const e=t[0].dims.length-2;d=new Array(e).fill(1)}Ss(o,n,u,e.autoPad,e.group,r,d,i,a,s);const l=Object.assign({},e);return Object.assign(l,{kernelShape:n,pads:r,outputPadding:a,outputShape:s,dilations:u,strides:d}),l},Ts=e=>{const t=Vr(e),n=e.format,i=["NOTSET","VALID","SAME_UPPER","SAME_LOWER"][void 0===e.autoPad?0:e.autoPad],r=e.dilations,s=e.group,a=e.kernelShape,o=e.pads,u=e.strides,d=e.wIsConst();return{autoPad:i,format:n,dilations:r,group:s,kernelShape:a,outputPadding:e.outputPadding,outputShape:e.outputShape,pads:o,strides:u,wIsConst:d,...t,cacheKey:`${e.format};${t.activation};`}},zs=(e,t)=>{if(!e||2!==e.length&&3!==e.length)throw new Error("Conv requires 2 or 3 inputs");if(4!==e[0].dims.length&&3!==e[0].dims.length)throw new Error("currently only support 2-dimensional conv");if(e[0].dims.length!==e[1].dims.length)throw new Error("filter does not have same dimension as input");if(e[0].dims["NHWC"===t.format?e[0].dims.length-1:1]!==e[1].dims[0])throw new Error("FILTER_IN_CHANNEL should be equal to DATA_CHANNEL");const n=e[1].dims[1]*t.group;if(3===e.length&&(1!==e[2].dims.length||e[2].dims[0]!==n))throw new Error("invalid bias");const i=e[0].dims.length-2;if(t.dilations.reduce((e,t)=>e+t,0)>0&&t.dilations.length!==i)throw new Error(`dilations should be ${i}D`);if(t.strides.reduce((e,t)=>e+t,0)>0&&t.strides.length!==i)throw new Error(`strides should be ${i}D`);if(t.pads.reduce((e,t)=>e+t,0)>0&&t.pads.length!==2*i)throw new Error(`pads should be ${2*i}D`);if(t.outputPadding.length!==i&&0!==t.outputPadding.length)throw new Error(`output_padding should be ${i}D`);if(t.kernelShape.reduce((e,t)=>e+t,0)>0&&0!==t.kernelShape.length&&t.kernelShape.length!==e[1].dims.length-2)throw new Error("invalid kernel shape");if(0!==t.outputShape.length&&t.outputShape.length!==e[0].dims.length-2)throw new Error("invalid output shape")},Es=(e,t,n,i)=>{const r=e.kernelCustomData.wT??e.compute(ln(t[1],[2,3,0,1]),{inputs:[1],outputs:[n.wIsConst?-2:-1]})[0];n.wIsConst&&!e.kernelCustomData.wT&&(e.kernelCustomData.wT=r);const s=[t[0],r];3===t.length&&s.push(t[2]),e.compute(vs(s,n,i),{inputs:s})},Cs=(e,t)=>{const n="NHWC"===t.format,i=[e.inputs[0].reshape(n?[e.inputs[0].dims[0],1,e.inputs[0].dims[1],e.inputs[0].dims[2]]:[e.inputs[0].dims[0],e.inputs[0].dims[1],1,e.inputs[0].dims[2]]),e.inputs[1].reshape([e.inputs[1].dims[0],e.inputs[1].dims[1],1,e.inputs[1].dims[2]])];3===e.inputs.length&&i.push(e.inputs[2]);let r=t.kernelShape;0!==r.length&&0!==r[0]||(r=[e.inputs[1].dims[2]]);let s=t.dilations;0!==s.length&&0!==s[0]||(s=[1]);let a=t.strides;0!==a.length&&0!==a[0]||(a=[1]);let o=t.pads;0===o.length&&(o=[0,0]),o=[0,o[0],0,o[1]],a=[1].concat(a),s=[1].concat(s),r=[1].concat(r);let u=t.outputPadding;u=[0].concat(u);const d=Is({...t,pads:o,strides:a,dilations:s,kernelShape:r,outputPadding:u},i);Es(e,i,d,e=>n?[e[0],e[2],e[3]]:[e[0],e[1],e[3]])},Os=(e,t)=>{if(zs(e.inputs,t),3===e.inputs[0].dims.length)Cs(e,t);else{const n=Is(t,e.inputs);Es(e,e.inputs,n)}}}}),Ud=P({"web/lib/wasm/jsep/webgpu/ops/cumsum.ts"(){rd(),od(),hd(),fd(),As=(e,t,n,i)=>{const r=dt.size(t),s=t.length,a=Xt("input",e,s),o=Yt("output",e,s),u=6===n.dataType?n.getInt32Array()[0]:Number(n.getBigInt64Array()[0]),d=dt.normalizeAxis(u,s);return{name:"CumSum",shaderCache:{hint:i.cacheKey,inputDependencies:["rank"]},getRunData:()=>({outputs:[{dims:t,dataType:e}],dispatchGroup:{x:Math.ceil(r/64)},programUniforms:[{type:12,data:r},{type:12,data:d},...Wt(t,t)]}),getShaderSource:e=>{const t=` i32(${a.indicesGet("inputIndices","uniforms.axis")}) `,n=Zt("uniforms.input_shape","uniforms.axis",s),r=i.reverse?t+(i.exclusive?" + 1":""):"0",u=i.reverse?n:t+(i.exclusive?"":" + 1");return`\n                ${e.registerUniform("outputSize","u32").registerUniform("axis","u32").declareVariables(a,o)}\n                ${e.mainStart()}\n                  ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}\n                  var inputIndices = ${o.offsetToIndices("global_idx")};\n                  var sum = ${o.type.value}(0);\n                  let first : i32 = ${r};\n                  let last : i32 = ${u};\n                  for (var i : i32 = first; i < last; i++) {\n                    ${a.indicesSet("inputIndices","uniforms.axis","u32(i)")};\n                    sum = sum + ${a.getByIndices("inputIndices")};\n                  }\n                  ${o.setByOffset("global_idx","sum")};\n                }`}}},Bs=(e,t)=>{const n=e.inputs[0].dims,i=e.inputs[0].dataType,r=e.inputs[1];e.compute(As(i,n,r,t),{inputs:[0]})},Rs=e=>{const t=1===e.exclusive,n=1===e.reverse;return qt({exclusive:t,reverse:n})}}}),Pd=P({"web/lib/wasm/jsep/webgpu/ops/depth-to-space.ts"(){rd(),od(),hd(),fd(),Ds=e=>{if(!e||1!==e.length)throw new Error("DepthToSpace requires 1 input.");if(4!==e[0].dims.length)throw new Error("DepthToSpace requires 4D input.")},Ms=(e,t,n,i)=>{const r=[];r.push(`fn perm(i: ${i.type.indices}) -> ${n.type.indices} {\n    var a: ${n.type.indices};`);for(let i=0;i<t;++i)r.push(n.indicesSet("a",e[i],`i[${i}]`));return r.push("return a;}"),r.join("\n")},Us=(e,t)=>{let n,i,r,s,a,o;const u="NHWC"===t.format,d=t.blocksize,l="DCR"===t.mode;u?([n,i,r,s]=e.dims,a=l?[n,i,r,d,d,s/d**2]:[n,i,r,s/d**2,d,d],o=l?[0,1,3,2,4,5]:[0,1,4,2,5,3]):([n,i,r,s]=[e.dims[0],e.dims[2],e.dims[3],e.dims[1]],a=l?[n,d,d,s/d**2,i,r]:[n,s/d**2,d,d,i,r],o=l?[0,3,4,1,5,2]:[0,1,4,2,5,3]);const p=e.reshape(a),c=p.dims.length,h=e.dataType,f=Xt("a",h,c),m=Yt("output",h,c);return{name:"DepthToSpace",shaderCache:{hint:`${e.dims};${t.blocksize};${t.mode}`,inputDependencies:["rank"]},getRunData:e=>{const t=u?[n,i*d,r*d,s/d**2]:[n,s/d**2,i*d,r*d],a=dt.size(t),l=p.dims,c=dt.sortBasedOnPerm(l,o);return{outputs:[{dims:t,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(a/64)},programUniforms:[{type:12,data:a},...Wt(l,c)]}},getShaderSource:e=>`\n  ${e.registerUniform("output_size","u32").declareVariables(f,m)}\n\n  ${Ms(o,c,f,m)}\n\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n\n    let indices = ${m.offsetToIndices("global_idx")};\n    let aIndices = perm(indices);\n\n    ${m.setByOffset("global_idx",f.getByIndices("aIndices"))}\n  }`}},Ps=(e,t)=>{Ds(e.inputs),e.compute(Us(e.inputs[0],t))},qs=e=>qt({blocksize:e.blocksize,mode:e.mode,format:e.format})}}),qd=P({"web/lib/wasm/jsep/webgpu/ops/einsum.ts"(){rd(),od(),hd(),fd(),Ls="^"+(Vs="("+(Ns="[a-zA-Z]|\\.\\.\\.")+")+")+"$",Gs="^("+Vs+",)*"+Vs+"$",Ws=class{constructor(e=-1){this.symbolToIndices=new Map,this.inputIndex=e}addSymbol(e,t){let n=this.symbolToIndices.get(e);void 0===n?n=[t]:n.push(t),this.symbolToIndices.set(e,n)}},js=class{constructor(e,t){this.equation=t,this.hasEllipsis=!1,this.symbolToInfo=new Map,this.lhs=new Array,this.outputDims=[];let[n,i]=t.includes("->")?t.split("->",2):[t,""];if(!n.match(RegExp(Gs)))throw new Error("Invalid LHS term");if(n.split(",").forEach((t,n)=>{const i=e[n].dims.slice();if(!t.match(RegExp(Ls)))throw new Error("Invalid LHS term");const r=this.processTerm(t,!0,i,n);this.lhs.push(r)}),""===i)i+=[...this.symbolToInfo.entries()].filter(([e,t])=>1===t.count||"..."===e).map(([e])=>e).join("");else if(!i.match(RegExp(Vs)))throw new Error("Invalid RHS");const r=i.match(RegExp(Ns,"g"));r?.forEach(e=>{if("..."===e)this.outputDims=this.outputDims.concat(this.ellipsisDims);else{const t=this.symbolToInfo.get(e);if(void 0===t)throw new Error("Invalid RHS symbol");this.outputDims.push(t.dimValue)}}),this.rhs=this.processTerm(i,!1,this.outputDims)}addSymbol(e,t,n){let i=this.symbolToInfo.get(e);if(void 0!==i){if(i.dimValue!==t&&1!==i.count)throw new Error("Dimension mismatch");i.count++,i.inputIndices.push(n)}else i={count:1,dimValue:t,inputIndices:[n]};this.symbolToInfo.set(e,i)}processTerm(e,t,n,i=-1){const r=n.length;let s=!1,a=[],o=0;if(!e.match(RegExp(Ls))&&!t&&""!==e)throw new Error("Invalid LHS term");const u=e.match(RegExp(Ns,"g")),d=new Ws(i);return u?.forEach((e,l)=>{if("..."===e){if(s)throw new Error("Only one ellipsis is allowed per input term");s=!0;const e=r-u.length+1;if(e<0)throw new Error("Ellipsis out of bounds");if(a=n.slice(o,o+e),this.hasEllipsis){if(this.ellipsisDims.length!==a.length||this.ellipsisDims.toString()!==a.toString())throw new Error("Ellipsis dimensions mismatch")}else{if(!t)throw new Error("Ellipsis must be specified in the LHS");this.hasEllipsis=!0,this.ellipsisDims=a}for(let e=0;e<a.length;e++){const t=String.fromCharCode("0".charCodeAt(0)+e);d.addSymbol(t,l+e),this.addSymbol(t,n[o++],i)}}else d.addSymbol(e,l+(this.hasEllipsis?this.ellipsisDims.length-1:0)),this.addSymbol(e,n[o++],i)}),d}},Hs=e=>e+"_max",Fs=(e,t,n,i)=>{const r=e.map(e=>e.length).map((e,n)=>Xt(`input${n}`,t,e)),s=dt.size(i),a=Yt("output",t,i.length),o=[...n.symbolToInfo.keys()].filter(e=>!n.rhs.symbolToIndices.has(e));return{name:"Einsum",shaderCache:{hint:n.equation,inputDependencies:e.map(()=>"rank")},getRunData:()=>{const r=o.filter(e=>n.symbolToInfo.has(e)).map(e=>({type:12,data:n.symbolToInfo.get(e)?.dimValue||0}));r.push({type:12,data:s});const a=e.map((e,t)=>[...Wt(e)]).reduce((e,t)=>e.concat(t),r);return a.push(...Wt(i)),{outputs:[{dims:i,dataType:t}],dispatchGroup:{x:Math.ceil(s/64)},programUniforms:a}},getShaderSource:e=>{const t=[],i=[],s=[],u=[],d=[],l=n.symbolToInfo.size===n.rhs.symbolToIndices.size;n.symbolToInfo.forEach((e,o)=>{if(n.rhs.symbolToIndices.has(o)){const i=n.rhs.symbolToIndices.get(o)?.[0];void 0!==i&&n.lhs.forEach((n,s)=>{if(e.inputIndices.includes(s)){const e=n.symbolToIndices.get(o);if(void 0===e)throw new Error("Invalid symbol error");e.forEach(e=>{t.push(`${r[s].indicesSet(`input${s}Indices`,e,a.indicesGet("outputIndices",i))}`)})}})}else n.lhs.forEach((t,n)=>{if(e.inputIndices.includes(n)){const e=t.symbolToIndices.get(o);if(void 0===e)throw new Error("Invalid symbol error");e.forEach(e=>{i.push(`${r[n].indicesSet(`input${n}Indices`,e,`${o}`)}`)}),d.push(`prod *= ${r[n].getByIndices(`input${n}Indices`)};`)}}),s.push(`for(var ${o}: u32 = 0; ${o} < uniforms.${Hs(o)}; ${o}++) {`),u.push("}")});const p=l?[...t,`let sum = ${r.map((e,t)=>e.getByIndices(`input${t}Indices`)).join(" * ")};`]:[...t,"var sum = 0.0;",...s,...i,"var prod = 1.0;",...d,"sum += prod;",...u];return`\n            ${e.registerUniforms(o.map(e=>({name:`${Hs(e)}`,type:"u32"}))).registerUniform("outputSize","u32").declareVariables(...r,a)}\n\n            ${e.mainStart()}\n            ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}\n            var outputIndices = ${a.offsetToIndices("global_idx")};\n            ${r.map((e,t)=>`var input${t}Indices: ${r[t].type.indices};`).join("\n")}\n            ${p.join("\n")};\n            ${a.setByOffset("global_idx","sum")};\n          }`}}},Ks=(e,t)=>{const n=new js(e.inputs,t.equation),i=n.outputDims,r=e.inputs.map((e,t)=>e.dims);e.compute(Fs(r,e.inputs[0].dataType,n,i))},Zs=e=>{const t=e.equation.replace(/\s+/g,"");return qt({equation:t})}}}),Nd=P({"web/lib/wasm/jsep/webgpu/ops/expand.ts"(){rd(),od(),fd(),Qs=e=>{if(!e||2!==e.length)throw new Error("Expand requires 2 input.");const t=e[0].dims,n=Array.from(e[1].getBigInt64Array(),Number);let i=n.length<t.length?0:n.length-t.length,r=t.length<n.length?0:t.length-n.length;for(;i<n.length&&r<t.length;++i,++r)if(n[i]!==t[r]&&1!==n[i]&&1!==t[r])throw new Error("Expand requires shape to be broadcastable to input")},Xs=(e,t)=>{const n=e.length-t.length,i=[];for(let t=0;t<n;++t)i.push(e[t]);for(let r=0;r<t.length;++r)i.push(1===t[r]?e[r+n]:t[r]);return i},Ys=(e,t)=>e.length>t.length?Xs(e,t):Xs(t,e),Js=e=>{const t=e[0].dims,n=Array.from(e[1].getBigInt64Array(),Number),i=Ys(t,n),r=e[0].dataType,s=9===r||1===dt.size(t),a=9===r||t.length>0&&t[t.length-1]%4==0?4:1,o=s||i.length>0&&i[i.length-1]%4==0?4:1,u=Math.ceil(dt.size(i)/o),d=[{type:12,data:u},...Wt(t,i)];return{name:"Expand",shaderCache:{hint:`${i.length};${a}${o}`,inputDependencies:["rank"]},getShaderSource:e=>{const n=Xt("input",r,t.length,a),s=Yt("output",r,i.length,o);let u;if(9===r){const e=(e,t,i="")=>`\n          let outputIndices${t} = ${s.offsetToIndices(`outputOffset + ${t}u`)};\n          let offset${t} = ${n.broadcastedIndicesToOffset(`outputIndices${t}`,s)};\n          let index${t} = offset${t} / 4u;\n          let component${t} = offset${t} % 4u;\n          ${e}[${t}] = ${i}(${n.getByOffset(`index${t}`)}[component${t}]);\n        `;u=`\n        let outputOffset = global_idx * ${o};\n        var data = vec4<u32>(0);\n        ${e("data",0,"u32")}\n        ${e("data",1,"u32")}\n        ${e("data",2,"u32")}\n        ${e("data",3,"u32")}\n        ${s.setByOffset("global_idx","data")}\n      }`}else u=`\n        let outputIndices = ${s.offsetToIndices(`global_idx * ${o}`)};\n        let inputOffset = ${n.broadcastedIndicesToOffset("outputIndices",s)};\n        let data = ${s.type.value}(${n.getByOffset(`inputOffset / ${a}`)});\n        ${s.setByOffset("global_idx","data")}\n      }`;return`\n    ${e.registerUniform("vec_size","u32").declareVariables(n,s)}\n    ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.vec_size")}\n    ${u}`},getRunData:()=>({outputs:[{dims:i,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(u/64)},programUniforms:d})}},ea=e=>{Qs(e.inputs),e.compute(Js(e.inputs),{inputs:[0]})}}}),Vd=P({"web/lib/wasm/jsep/webgpu/ops/fast-gelu.ts"(){rd(),od(),fd(),vd(),ta=e=>{const t=e[0].dataType,n=dt.size(e[0].dims),i=dt.size(e[1].dims),r=i%4==0;return{name:"FastGeluWithBias",shaderCache:{hint:`${r}`,inputDependencies:["type","type"]},getShaderSource:e=>{const n=Xt("x",t,[1],4),i=Xt("bias",t,[1],4),s=Yt("y",t,[1],4),a=e=>`\n      let bias${e}_offset: u32 = (global_idx * 4 + ${e}) % uniforms.bias_size;\n      let bias${e} = ${i.getByOffset(`bias${e}_offset / 4`)}[bias${e}_offset % 4];`,o=r?`\n      let bias = ${i.getByOffset("global_idx % (uniforms.bias_size / 4)")};`:`${a(0)}${a(1)}${a(2)}${a(3)}\n      let bias = ${n.type.value}(bias0, bias1, bias2, bias3);`;return`${e.registerUniforms([{name:"output_vec_size",type:"u32"},{name:"bias_size",type:"u32"}]).declareVariables(n,i,s)}\n\n    ${ur(Gt(t))}\n\n    ${e.mainStart(Nt)}\n      ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_vec_size")}\n\n      let x = ${n.getByOffset("global_idx")};\n      ${o}\n      let x_in = x + bias;\n      ${s.setByOffset("global_idx",dr("x_in"))}\n    }`},getRunData:e=>({outputs:[{dims:e[0].dims,dataType:e[0].dataType}],programUniforms:[{type:12,data:Math.ceil(n/4)},{type:12,data:i}],dispatchGroup:{x:Math.ceil(n/Nt/4)}})}},na=e=>{e.inputs.length<2||0===dt.size(e.inputs[1].dims)?lr(e):e.compute(ta(e.inputs))}}}),Ld=P({"web/lib/wasm/jsep/webgpu/ops/gather.ts"(){rd(),od(),hd(),fd(),ia=e=>{if(!e||2!==e.length)throw new Error("Gather requires 2 inputs.")},ra=(e,t)=>{const n=e[0].dims,i=e[1].dims,r=n.length,s=dt.normalizeAxis(t.axis,r),a=n.slice(0);a.splice(s,1,...i);const o=n[s],u=9===e[0].dataType?4:1,d=Math.ceil(dt.size(a)/u),l=[{type:12,data:d},{type:6,data:o},{type:12,data:s},...Wt(e[0].dims,e[1].dims,a)];return{name:"Gather",shaderCache:{hint:t.cacheKey,inputDependencies:["rank","rank"]},getRunData:()=>({outputs:[{dims:a,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(d/64)},programUniforms:l}),getShaderSource:t=>{const n=Xt("data",e[0].dataType,e[0].dims.length,u),o=Xt("inputIndices",e[1].dataType,e[1].dims.length),d=Yt("output",e[0].dataType,a.length,u),l=e=>{const t=i.length;let u=`var indicesIndices${e}  = ${o.type.indices}(0);`;for(let n=0;n<t;n++)u+=`${t>1?`indicesIndices${e}[${n}]`:`indicesIndices${e}`} = ${a.length>1?`outputIndices${e}[uniforms.axis + ${n}]`:`outputIndices${e}`};`;u+=`\n          var idx${e} = ${o.getByIndices(`indicesIndices${e}`)};\n          if (idx${e} < 0) {\n            idx${e} = idx${e} + uniforms.axisDimLimit;\n          }\n          var dataIndices${e} : ${n.type.indices};\n        `;for(let n=0,i=0;n<r;n++)n===s?(u+=`${r>1?`dataIndices${e}[${n}]`:`dataIndices${e}`} = u32(idx${e});`,i+=t):(u+=`${r>1?`dataIndices${e}[${n}]`:`dataIndices${e}`} = ${a.length>1?`outputIndices${e}[${i}]`:`outputIndices${e}`};`,i++);return u};let p;if(9===e[0].dataType){const e=(e,t,i="")=>`\n          let outputIndices${t} = ${d.offsetToIndices(`outputOffset + ${t}u`)};\n          ${l(t)};\n          let offset${t} = ${n.indicesToOffset(`dataIndices${t}`)};\n          let index${t} = offset${t} / 4u;\n          let component${t} = offset${t} % 4u;\n          ${e}[${t}] = ${i}(${n.getByOffset(`index${t}`)}[component${t}]);\n        `;p=`\n        let outputOffset = global_idx * ${u};\n        var value = vec4<u32>(0);\n        ${e("value",0,"u32")}\n        ${e("value",1,"u32")}\n        ${e("value",2,"u32")}\n        ${e("value",3,"u32")}\n        ${d.setByOffset("global_idx","value")}\n      `}else p=`\n      let outputIndices = ${d.offsetToIndices("global_idx")};\n      ${l("")};\n      let value = ${n.getByIndices("dataIndices")};\n      ${d.setByOffset("global_idx","value")};\n      `;return`\n      ${t.registerUniform("outputSize","u32").registerUniform("axisDimLimit","i32").registerUniform("axis","u32").declareVariables(n,o,d)}\n      ${t.mainStart()}\n        ${t.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}\n        ${p}\n      }`}}},sa=e=>qt({axis:e.axis}),aa=(e,t)=>{const n=e.inputs;ia(n),e.compute(ra(e.inputs,t))}}}),Gd=P({"web/lib/wasm/jsep/webgpu/ops/gather-nd.ts"(){rd(),od(),fd(),oa=(e,t,n,i,r,s,a,o,u)=>{const d=[{type:12,data:s},{type:12,data:i},{type:12,data:r},{type:12,data:n},{type:12,data:a},{type:12,data:o},{type:12,data:u}],l=[s];return d.push(...Wt(t.dims,l)),e.compute({name:"computeSliceOffsets",shaderCache:{hint:`${r.length}_${n.length}`,inputDependencies:["rank"]},getRunData:()=>({outputs:[{dims:l,dataType:e.inputs[1].dataType}],dispatchGroup:{x:Math.ceil(s/64)},programUniforms:d}),getShaderSource:e=>{const i=[Xt("indices_data",t.dataType,t.dims.length),Yt("input_slice_offsets_data",12,1,1)],s=[{name:"output_size",type:"u32"},{name:"batch_dims",type:"u32"},{name:"input_dims",type:"u32",length:r.length},{name:"sizes_from_slice_dims_data",type:"u32",length:n.length},{name:"num_slices_per_batch",type:"u32"},{name:"input_batch_stride",type:"u32"},{name:"num_slice_dims",type:"u32"}];return`\n  ${e.registerUniforms(s).declareVariables(...i)}\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n    let batch_idx = global_idx / uniforms.num_slices_per_batch;\n    let base_offset = batch_idx * uniforms.input_batch_stride;\n\n    let slice_indices_base_offset = global_idx * uniforms.num_slice_dims;\n    var relative_slice_offset = 0;\n    for (var dim_idx = 0u; dim_idx < uniforms.num_slice_dims; dim_idx ++) {\n      var index = i32(indices_data[dim_idx + slice_indices_base_offset].x);\n      let input_dim_idx = uniforms.batch_dims + dim_idx;\n      if (index < 0) {\n        ${1===r.length?"index += i32(uniforms.input_dims);":"index += i32(uniforms.input_dims[input_dim_idx]);"}\n      }\n      ${1===n.length?"relative_slice_offset += index * i32(uniforms.sizes_from_slice_dims_data);":"relative_slice_offset += index * i32(uniforms.sizes_from_slice_dims_data[dim_idx]);"}\n    }\n\n    input_slice_offsets_data[global_idx] =  base_offset + u32(relative_slice_offset);\n  }`}},{inputs:[t],outputs:[-1]})[0]},ua=(e,t)=>{const n=e.inputs,i=n[0].dims,r=n[0].dataType,s=n[1].dims,a=s[s.length-1],o=dt.sizeToDimension(s,s.length-1),u=dt.sizeFromDimension(i,t.batchDims+a),d=dt.sizeToDimension(i,t.batchDims),l=dt.sizeFromDimension(i,t.batchDims),p=o/d,c=new Array(a);let h=u;for(let e=0;e<a;++e)c[a-1-e]=h,h*=i[t.batchDims+a-1-e];const f=oa(e,n[1],c,t.batchDims,i,o,p,l,a),m=t.batchDims+a;if(m>i.length)throw new Error("last dimension of indices must not be larger than rank of input tensor");const g=s.slice(0,-1).concat(i.slice(m)),_=dt.size(g),w=[{type:12,data:_},{type:12,data:u},...Wt(n[0].dims,f.dims,g)];e.compute({name:"GatherND",shaderCache:{hint:t.cacheKey,inputDependencies:["rank","rank"]},getRunData:()=>({outputs:[{dims:g,dataType:r}],dispatchGroup:{x:Math.ceil(_/64)},programUniforms:w}),getShaderSource:e=>{const t=Xt("data",n[0].dataType,n[0].dims.length),i=Xt("slice_offsets",12,f.dims.length),r=Yt("output",n[0].dataType,g.length);return`\n          ${e.registerUniform("output_size","u32").registerUniform("slice_size","u32").declareVariables(t,i,r)}\n            ${e.mainStart()}\n            ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n          let slice_offset = slice_offsets[global_idx / uniforms.slice_size];\n          output[global_idx] = data[u32(slice_offset) + global_idx % uniforms.slice_size];\n        }`}},{inputs:[n[0],f]})},da=e=>({batchDims:e.batch_dims,cacheKey:""})}}),Wd=P({"web/lib/wasm/jsep/webgpu/ops/gather-block-quantized.ts"(){rd(),od(),hd(),fd(),la=(e,t)=>{if(e.length<3||e.length>4)throw new Error("GatherBlockQuantized requires 3 or 4 inputs.");const n=dt.normalizeAxis(t.quantizeAxis,e[0].dims.length),i=t.blockSize,r=e[0],s=e[2],a=4===e.length?e[3]:void 0;if(s.dims.length!==r.dims.length||!r.dims.map((e,t)=>t===n?Math.ceil(e/i)===s.dims[t]:e===s.dims[t]).reduce((e,t)=>e&&t,!0))throw new Error("Scales must have the same rank as the input tensor and the dims should match except on gatherAxis.");if(a){if(a.dataType!==r.dataType)throw new Error("Zero point must have the same data type as the input tensor.");if(a.dims.length!==s.dims.length||!a.dims.map((e,t)=>e===s.dims[t]).reduce((e,t)=>e&&t,!0))throw new Error("Zero point must have the same rank as the input tensor and the dims should match except on quantizeAxis.")}},pa=(e,t)=>{const n=e[0].dims,i=e[1].dims,r=n.length,s=dt.normalizeAxis(t.gatherAxis,r),a=dt.normalizeAxis(t.quantizeAxis,r),o=n.slice(0);o.splice(s,1,...i);const u=dt.size(o),d=e[2].dataType,l=22===e[0].dataType,p=[{type:12,data:u},{type:12,data:a},{type:12,data:s},{type:12,data:t.blockSize},...Wt(...e.map((e,t)=>e.dims),o)];return{name:"GatherBlockQuantized",shaderCache:{hint:`${t.cacheKey};${e.filter((e,t)=>1!==t).map(e=>e.dims.join("_")).join(";")}`,inputDependencies:Array.from({length:e.length},(e,t)=>"rank")},getRunData:()=>({outputs:[{dims:o,dataType:d}],dispatchGroup:{x:Math.ceil(u/64)},programUniforms:p}),getShaderSource:t=>{const r=Xt("data",e[0].dataType,e[0].dims.length),a=Xt("inputIndices",e[1].dataType,e[1].dims.length),u=Xt("scales",e[2].dataType,e[2].dims.length),p=e.length>3?Xt("zeroPoint",e[3].dataType,e[3].dims.length):void 0,c=Yt("output",d,o.length),h=[r,a,u];return p&&h.push(p),`\n        ${t.registerUniforms([{name:"output_size",type:"u32"},{name:"quantize_axis",type:"u32"},{name:"gather_axis",type:"u32"},{name:"block_size",type:"u32"}]).declareVariables(...h,c)}\n        ${t.mainStart()}\n        let output_indices = ${c.offsetToIndices("global_idx")};\n        var indices_indices = ${a.type.indices}(0);\n        ${i.length>1?`\n          for (var i: u32 = 0; i < ${i.length}; i++) {\n            let index = ${c.indicesGet("output_indices","uniforms.gather_axis + i")};\n            ${a.indicesSet("indices_indices","i","index")};\n          }`:`indices_indices = ${c.indicesGet("output_indices","uniforms.gather_axis")};`};\n        var data_indices = ${r.type.indices}(0);\n        for (var i: u32 = 0; i < uniforms.gather_axis; i++) {\n          let index = ${c.indicesGet("output_indices","i")};\n          ${r.indicesSet("data_indices","i","index")};\n        }\n        var index_from_indices = ${a.getByIndices("indices_indices")};\n        if (index_from_indices < 0) {\n          index_from_indices += ${n[s]};\n        }\n        ${r.indicesSet("data_indices","uniforms.gather_axis","u32(index_from_indices)")};\n        for (var i = uniforms.gather_axis + 1; i < ${o.length}; i++) {\n          let index = ${c.indicesGet("output_indices",`i + ${i.length} - 1`)};\n          ${r.indicesSet("data_indices","i","index")};\n        }\n        let data_offset = ${r.indicesToOffset("data_indices")};\n        let data_index = data_offset % 8;\n        // Convert 4-bit packed data to 8-bit packed data.\n        let packed_4bit_quantized_data = ${r.getByOffset("data_offset / 8")};\n        let packed_8bit_quantized_data = (packed_4bit_quantized_data >> (4 * (data_index % 2))) & 0x0f0f0f0f;\n        let quantized_data_vec = ${l?"unpack4xI8":"unpack4xU8"}(u32(packed_8bit_quantized_data));\n        let quantized_data = quantized_data_vec[data_index / 2];\n        var scale_indices = data_indices;\n        let quantize_axis_index = ${u.indicesGet("data_indices","uniforms.quantize_axis")} / uniforms.block_size;\n        ${u.indicesSet("scale_indices","uniforms.quantize_axis","quantize_axis_index")};\n        var scale = ${u.getByIndices("scale_indices")};\n        ${p?`\n              let zero_point_indices = scale_indices;\n              let zero_point_offset = ${p.indicesToOffset("zero_point_indices")};\n              let zero_point_index = zero_point_offset % 8;\n              let packed_4bit_zero_points = ${p.getByOffset("zero_point_offset / 8")};\n              let packed_8bit_zero_points = (packed_4bit_zero_points >> (4 * (zero_point_index % 2))) & 0x0f0f0f0f;\n              let zero_point_vec = ${l?"unpack4xI8":"unpack4xU8"}(u32(packed_8bit_zero_points));\n              let zero_point = zero_point_vec[zero_point_index / 2];`:"var zero_point = 0"};\n        let dequantized_data = ${Gt(d)}(quantized_data - zero_point) * scale;\n        ${c.setByOffset("global_idx","dequantized_data")};\n    }`}}},ca=(e,t)=>{const n=e.inputs;la(n,t),e.compute(pa(e.inputs,t))},ha=e=>qt({blockSize:e.blockSize,gatherAxis:e.gatherAxis,quantizeAxis:e.quantizeAxis})}}),jd=P({"web/lib/wasm/jsep/webgpu/ops/gather-elements.ts"(){rd(),od(),hd(),fd(),fa=e=>{if(!e||2!==e.length)throw new Error("GatherElements requires 2 inputs.");if(e[0].dims.length<1)throw new Error("GatherElements requires that the data input be rank >= 1.");if(e[0].dims.length!==e[1].dims.length)throw new Error("GatherElements requires that the data input and\n                     indices input tensors be of same rank.")},ma=(e,t)=>{const n=e[0].dims,i=e[0].dataType,r=n.length,s=e[1].dims,a=e[1].dataType,o=dt.normalizeAxis(t.axis,r),u=n[o],d=s.slice(0),l=dt.size(d),p=Xt("input",i,r),c=Xt("indicesInput",a,s.length),h=Yt("output",i,d.length),f=[{type:12,data:l},{type:6,data:u},{type:12,data:o}];return f.push(...Wt(n,s,d)),{name:"GatherElements",shaderCache:{inputDependencies:["rank","rank"]},getRunData:()=>({outputs:[{dims:d,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(l/64)},programUniforms:f}),getShaderSource:e=>`\n      ${e.registerUniform("outputSize","u32").registerUniform("axisDimLimit","i32").registerUniform("axis","u32").declareVariables(p,c,h)}\n      ${e.mainStart()}\n      ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}\n\n      let outputIndices = ${h.offsetToIndices("global_idx")};\n\n      var idx = ${c.getByOffset("global_idx")};\n      if (idx < 0) {\n        idx = idx + uniforms.axisDimLimit;\n      }\n      var inputIndices = ${p.type.indices}(outputIndices);\n      ${p.indicesSet("inputIndices","uniforms.axis","u32(idx)")};\n      let value = ${p.getByIndices("inputIndices")};\n\n      ${h.setByOffset("global_idx","value")};\n  }`}},ga=e=>qt({axis:e.axis}),_a=(e,t)=>{const n=e.inputs;fa(n),e.compute(ma(e.inputs,t))}}}),Hd=P({"web/lib/wasm/jsep/webgpu/ops/gemm.ts"(){rd(),od(),fd(),wa=e=>{if(!e)throw new Error("Input is missing");if(e.length<2||e.length>3)throw new Error("Invaid input number.");if(3===e.length&&e[2].dims.length>2)throw new Error("Invalid input shape of C");if(e[0].dataType!==e[1].dataType||3===e.length&&e[0].dataType!==e[2].dataType)throw new Error("Input types are mismatched")},ya=(e,t)=>{const n=e[0].dims.slice(),i=e[1].dims.slice(),[r,s,a]=pt.getShapeOfGemmResult(n,t.transA,i,t.transB,3===e.length?e[2].dims:void 0),o=[r,s];if(!o)throw new Error("Can't use gemm on the given tensors");const u=Math.ceil(s/16),d=Math.ceil(r/16),l=(dt.size(o),[{type:12,data:u},{type:12,data:r},{type:12,data:s},{type:12,data:a},{type:1,data:t.alpha},{type:1,data:t.beta}]),p=["type","type"];3===e.length&&(l.push(...Wt(e[2].dims)),p.push("rank")),l.push(...Wt(o));return{name:"GemmShared",shaderCache:{hint:`${t.cacheKey}`,inputDependencies:p},getRunData:()=>({outputs:[{dims:o,dataType:e[0].dataType}],dispatchGroup:{x:u*d},programUniforms:l}),getShaderSource:n=>{const i=Xt("a",e[0].dataType,e[0].dims),r=Xt("b",e[1].dataType,e[1].dims);let s=null;const a=[i,r];3===e.length&&(s=Xt("c",e[2].dataType,e[2].dims.length),a.push(s));const u=Yt("output",e[0].dataType,o.length);a.push(u);let d="",l="";t.transA&&t.transB?(l=`\n      var col = tile_row_start + local_id.x;\n      var row = k_start + local_id.y;\n      if (col < uniforms.M && row < uniforms.K) {\n        tile_a[local_id.y][local_id.x] = a[row * uniforms.M + col];\n      } else {\n        tile_a[local_id.y][local_id.x] = ${i.type.value}(0);\n      }\n\n      col = k_start + local_id.x;\n      row = tile_col_start + local_id.y;\n      if (col < uniforms.K && row < uniforms.N) {\n        tile_b[local_id.y][local_id.x] = b[row * uniforms.K + col];\n      } else {\n        tile_b[local_id.y][local_id.x] = ${r.type.value}(0);\n      }\n      `,d="value += tile_a[k][local_id.y] * tile_b[local_id.x][k];"):t.transA&&!t.transB?(l=`\n      var col = tile_row_start + local_id.x;\n      var row = k_start + local_id.y;\n      if (col < uniforms.M && row < uniforms.K) {\n        tile_a[local_id.y][local_id.x] = a[row * uniforms.M + col];\n      } else {\n        tile_a[local_id.y][local_id.x] = ${i.type.value}(0);\n      }\n\n      col = tile_col_start + local_id.x;\n      row = k_start + local_id.y;\n      if (col < uniforms.N && row < uniforms.K) {\n        tile_b[local_id.y][local_id.x] = b[row * uniforms.N + col];\n      } else {\n        tile_b[local_id.y][local_id.x] = ${r.type.value}(0);\n      }\n      `,d="value += tile_a[k][local_id.y] * tile_b[k][local_id.x];"):!t.transA&&t.transB?(l=`\n      var col = k_start + local_id.x;\n      var row = tile_row_start + local_id.y;\n      if (col < uniforms.K && row < uniforms.M) {\n        tile_a[local_id.y][local_id.x] = a[row * uniforms.K + col];\n      } else {\n        tile_a[local_id.y][local_id.x] = ${i.type.value}(0);\n      }\n\n      col = k_start + local_id.x;\n      row = tile_col_start + local_id.y;\n      if (col < uniforms.K && row < uniforms.N) {\n        tile_b[local_id.y][local_id.x] = b[row * uniforms.K + col];\n      } else {\n        tile_b[local_id.y][local_id.x] = ${r.type.value}(0);\n      }\n      `,d="value += tile_a[local_id.y][k] * tile_b[local_id.x][k];"):t.transA||t.transB||(l=`\n      var col = k_start + local_id.x;\n      var row = tile_row_start + local_id.y;\n      if (col < uniforms.K && row < uniforms.M) {\n        tile_a[local_id.y][local_id.x] = a[row * uniforms.K + col];\n      } else {\n        tile_a[local_id.y][local_id.x] = ${i.type.value}(0);\n      }\n\n      col = tile_col_start + local_id.x;\n      row = k_start + local_id.y;\n      if (col < uniforms.N && row < uniforms.K) {\n        tile_b[local_id.y][local_id.x] = b[row * uniforms.N + col];\n      } else {\n        tile_b[local_id.y][local_id.x] = ${r.type.value}(0);\n      }\n      `,d="value += tile_a[local_id.y][k] * tile_b[k][local_id.x];");const p=1===t.alpha?"":"value *= uniforms.alpha;";return`\n  ${n.registerUniforms([{name:"num_tile_n",type:"u32"},{name:"M",type:"u32"},{name:"N",type:"u32"},{name:"K",type:"u32"},{name:"alpha",type:"f32"},{name:"beta",type:"f32"}]).declareVariables(...a)}\n  var<workgroup> tile_a: array<array<${i.type.storage}, 16>, 16>;\n  var<workgroup> tile_b: array<array<${r.type.storage}, 16>, 16>;\n  ${n.mainStart([16,16,1])}\n    let tile_col_start = (workgroup_index % uniforms.num_tile_n) * 16;\n    let tile_row_start = (workgroup_index / uniforms.num_tile_n) * 16;\n    let num_tiles = (uniforms.K - 1) / 16 + 1;\n    var k_start = 0u;\n    var value = ${u.type.value}(0);\n    for (var t: u32 = 0u; t < num_tiles; t++) {\n      ${l}\n      k_start = k_start + 16;\n      workgroupBarrier();\n\n      for (var k: u32 = 0u; k < 16; k++) {\n        ${d}\n      }\n      workgroupBarrier();\n    }\n\n    ${p}\n    let m = tile_row_start + local_id.y;\n    let n = tile_col_start + local_id.x;\n    ${null!=s?`let cOffset = ${s.broadcastedIndicesToOffset("vec2(m, n)",u)}; value += ${u.type.value}(uniforms.beta) * ${s.getByOffset("cOffset")};`:""}\n    if (m < uniforms.M && n < uniforms.N) {\n      output[m * uniforms.N + n] = value;\n    }\n  }`}}},$a=e=>({transA:e.transA,transB:e.transB,alpha:e.alpha,beta:e.beta,cacheKey:`${e.transA};${e.transB};${1===e.alpha}`}),ba=(e,t)=>{wa(e.inputs),e.compute(ya(e.inputs,t))}}}),Fd=P({"web/lib/wasm/jsep/webgpu/ops/grid-sample.ts"(){rd(),od(),hd(),fd(),[va,xa,ka,Sa]=[0,1,2,3],Ia=e=>{if(4!==e[0].dims.length)throw new Error("only 4-D tensor is supported.");if(e[0].dims.length!==e[1].dims.length)throw new Error("input dimensions must be equal to grid dimensions");if(e[0].dims.length-2!==e[1].dims[e[1].dims.length-1])throw new Error("last dimension of grid must be equal to "+(e[0].dims.length-2));if(e[0].dims[0]!==e[1].dims[0])throw new Error("grid batch size must match input batch size")},Ta=e=>`\n  fn gs_bicubic_interpolate(p: mat4x4<${e}>, x: f32, y: f32) -> ${e} {\n    var v: vec4<f32>;\n    var coeffs = gs_get_cubic_coeffs(x);\n    for (var i = 0; i < 4; i++) {\n      v[i] = coeffs[0] * p[i][0] + coeffs[1] * p[i][1] + coeffs[2] * p[i][2] + coeffs[3] * p[i][3];\n    }\n    coeffs = gs_get_cubic_coeffs(y);\n    let pixel = ${e}(coeffs[0] * v[0] + coeffs[1] * v[1] + coeffs[2] * v[2] + coeffs[3] * v[3]);\n    return pixel;\n  }\n`,za=e=>`\n  fn gs_denormalize(n: f32, length: i32) -> f32 {\n    ${0===e.alignCorners?"\n    // alignCorners: false => [-1, 1] to [-0.5, length - 0.5]\n    return ((n + 1.0) * f32(length) - 1.0) / 2.0;\n    ":"\n    // alignCorners: true => [-1, 1] to [0, length - 1]\n    return (n + 1.0) / 2.0 * (f32(length - 1));\n    "}\n  }\n`,Ea=e=>`\n  ${"reflection"===e.paddingMode?"\n      fn gs_reflect(x: i32, x_min: f32, x_max: f32) -> u32 {\n        var dx = 0.0;\n        var fx = f32(x);\n        let range = x_max - x_min;\n        if (fx < x_min) {\n          dx = x_min - fx;\n          let n = u32(dx / range);\n          let r = dx - f32(n) * range;\n          if (n % 2 == 0) {\n            fx = x_min + r;\n          } else {\n            fx = x_max - r;\n          }\n        } else if (fx > x_max) {\n          dx = fx - x_max;\n          let n = u32(dx / range);\n          let r = dx - f32(n) * range;\n          if (n % 2 == 0) {\n            fx = x_max - r;\n          } else {\n            fx = x_min + r;\n          }\n        }\n        return u32(fx);\n      }":""}\n`,Ca=(e,t,n)=>`\n  fn pixel_at_grid(r: i32, c: i32, H: i32, W: i32, batch: u32, channel: u32, border: vec4<f32>) -> ${t} {\n     var pixel = ${t}(0);\n     var indices = vec4<u32>(0);\n     indices[${va}] = batch;\n     indices[${xa}] = channel;`+(()=>{switch(n.paddingMode){case"zeros":return`\n          if (r >= 0 && r < H && c >=0 && c < W) {\n            indices[${ka}] = u32(r);\n            indices[${Sa}] = u32(c);\n          } else {\n            return ${t}(0);\n          }\n        `;case"border":return`\n          indices[${ka}] = u32(clamp(r, 0, H - 1));\n          indices[${Sa}] = u32(clamp(c, 0, W - 1));\n        `;case"reflection":return`\n          indices[${ka}] = gs_reflect(r, border[1], border[3]);\n          indices[${Sa}] = gs_reflect(c, border[0], border[2]);\n        `;default:throw new Error(`padding mode ${n.paddingMode} is not supported`)}})()+`\n    return ${e.getByIndices("indices")};\n  }\n`,Oa=(e,t,n)=>(()=>{switch(n.mode){case"nearest":return`\n          let result = pixel_at_grid(i32(round(y)), i32(round(x)), H_in, W_in, indices[${va}], indices[${xa}], border);\n        `;case"bilinear":return`\n          let x1 = i32(floor(x));\n          let y1 = i32(floor(y));\n          let x2 = x1 + 1;\n          let y2 = y1 + 1;\n\n          let p11 = pixel_at_grid(y1, x1, H_in, W_in, indices[${va}], indices[${xa}], border);\n          let p12 = pixel_at_grid(y1, x2, H_in, W_in, indices[${va}], indices[${xa}], border);\n          let p21 = pixel_at_grid(y2, x1, H_in, W_in, indices[${va}], indices[${xa}], border);\n          let p22 = pixel_at_grid(y2, x2, H_in, W_in, indices[${va}], indices[${xa}], border);\n\n          let dx2 = ${t}(f32(x2) - x);\n          let dx1 = ${t}(x - f32(x1));\n          let dy2 = ${t}(f32(y2) - y);\n          let dy1 = ${t}(y - f32(y1));\n          let result = dy2 * (dx2 * p11 + dx1 * p12) + dy1 * (dx2 * p21 + dx1 * p22);\n        `;case"bicubic":return`\n          let x0 = i32(floor(x)) - 1;\n          let y0 = i32(floor(y)) - 1;\n          var p: mat4x4<${t}>;\n          for (var h = 0; h < 4; h++) {\n            for (var w = 0; w < 4; w++) {\n              p[h][w] = pixel_at_grid(h + y0, w + x0, H_in, W_in, indices[${va}], indices[${xa}], border);\n            }\n          }\n\n          let dx = x - f32(x0 + 1);\n          let dy = y - f32(y0 + 1);\n          let result = gs_bicubic_interpolate(p, dx, dy);\n        `;default:throw new Error(`mode ${n.mode} is not supported`)}})()+`${e.setByOffset("global_idx","result")}`,Aa=(e,t)=>{const n=Xt("x",e[0].dataType,e[0].dims.length),i=[e[1].dims[0],e[1].dims[1],e[1].dims[2]],r=Xt("grid",e[1].dataType,i.length,2);let s=[e[0].dims[0],e[0].dims[1],e[1].dims[1],e[1].dims[2]];"NHWC"===t.format&&(s=[e[0].dims[0],e[1].dims[1],e[1].dims[2],e[0].dims[3]],[va,xa,ka,Sa]=[0,3,1,2]);const a=Yt("output",e[0].dataType,s.length),o=n.type.value,u=[{type:12,data:dt.size(s)},...Wt(e[0].dims,i,s)];return{name:"GridSample",shaderCache:{hint:`${t.cacheKey}`,inputDependencies:["type","type"]},getRunData:e=>{const t=dt.size(s);return{outputs:[{dims:s,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(t/64)},programUniforms:u}},getShaderSource:e=>`\n  ${e.registerUniform("output_size","u32").declareVariables(n,r,a)}\n  \n  fn gs_get_cubic_coeffs(x: f32) -> vec4<f32> {\n    let cubic_alpha = -0.75f;\n    let x_abs = abs(x);\n    var coeffs: vec4<f32>;\n    coeffs[0] = (((cubic_alpha * (x_abs + 1) - 5 * cubic_alpha) * (x_abs + 1) + 8 * cubic_alpha) * (x_abs + 1) - 4 * cubic_alpha);\n    coeffs[1] = (((cubic_alpha + 2) * x_abs - (cubic_alpha + 3)) * x_abs * x_abs + 1);\n    coeffs[2] = (((cubic_alpha + 2) * (1 - x_abs) - (cubic_alpha + 3)) * (1 - x_abs) * (1 - x_abs) + 1);\n    coeffs[3] = (((cubic_alpha * (2 - x_abs) - 5 * cubic_alpha) * (2 - x_abs) + 8 * cubic_alpha) * (2 - x_abs) - 4 * cubic_alpha);\n    return coeffs;\n  }\n\n  ${Ta(o)}\n  ${za(t)}\n  ${Ea(t)}\n  ${Ca(n,o,t)}\n\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n      let H_in = i32(uniforms.x_shape[${ka}]);\n      let W_in = i32(uniforms.x_shape[${Sa}]);\n\n      ${0===t.alignCorners?"\n      let x_min = -0.5;\n      let x_max = f32(W_in) - 0.5;\n      let y_min = -0.5;\n      let y_max = f32(H_in) - 0.5;\n      ":"\n      let x_min = 0.0;\n      let x_max = f32(W_in) - 1.0;\n      let y_min = 0.0;\n      let y_max = f32(H_in) - 1.0;\n      "};\n      let border = vec4<f32>(x_min, y_min, x_max, y_max);\n\n      let indices = ${a.offsetToIndices("global_idx")};\n      var grid_indices = vec3<u32>(indices[${va}], indices[${ka}], indices[${Sa}]);\n      let nxy = ${r.getByIndices("grid_indices")};\n      var x = gs_denormalize(f32(nxy[0]), W_in);\n      var y = gs_denormalize(f32(nxy[1]), H_in);\n\n      ${Oa(a,o,t)}\n  }`}},Ba=(e,t)=>{Ia(e.inputs),e.compute(Aa(e.inputs,t))},Ra=e=>qt({alignCorners:e.align_corners,mode:e.mode,paddingMode:e.padding_mode,format:e.format})}}),Kd=P({"web/lib/wasm/jsep/webgpu/ops/multihead-attention.ts"(){rd(),od(),hd(),pd(),yd(),fd(),md(),Da=(e,t)=>e.length>t&&e[t].dims.length>0?e[t]:void 0,Ma=(e,t)=>{const n=e[0],i=Da(e,1),r=Da(e,2),s=Da(e,3),a=Da(e,4),o=Da(e,5),u=Da(e,6),d=Da(e,7);if(3!==n.dims.length&&5!==n.dims.length)throw new Error("Input query is expected to have 3 or 5 dimensions");const l=n.dims[0],p=n.dims[1],c=3===n.dims.length?n.dims[2]:t.numHeads*n.dims[4];let h=p,f=0,m=0;const g=Math.floor(c/t.numHeads);if(u&&d&&dt.size(u.dims)&&dt.size(d.dims)){if(4!==u.dims.length)throw new Error('Input "past_key" is expected to have 4 dimensions');if(u.dims[0]!==l||u.dims[1]!==t.numHeads||u.dims[3]!==g)throw new Error('Input "past_key" shape (batch_size, num_heads, past_sequence_length, head_size)');if(d.dims[0]!==l||d.dims[1]!==t.numHeads||d.dims[3]!==g)throw new Error('Input "past_value" shape (batch_size, num_heads, past_sequence_length, head_size)');if(u.dims[2]!==d.dims[2])throw new Error('Input "past_key" and "past_value" shall have same dim 2 (past_sequence_length)');if(4!==d.dims.length)throw new Error('Input "past_value" is expected to have 4 dimensions');f=u.dims[2],m=u.dims[2]}else if(u&&dt.size(u.dims)||d&&dt.size(d.dims))throw new Error('Input "past_key" and "past_value" shall be both present or both absent');let _;if(i&&dt.size(i.dims)>0){if(3!==n.dims.length)throw new Error('Input "query" is expected to have 3 dimensions when key is given');if(i.dims.length<3||i.dims.length>5)throw new Error('Input "key" is expected to have 3, 4, or 5 dimensions');if(n.dims[0]!==i.dims[0])throw new Error('Input "query" and "key" shall have same dim 0 (batch size)');if(3===i.dims.length){if(i.dims[2]!==n.dims[2])throw new Error('Input "query" and "key" shall have same dim 2 (hidden_size)');_=2,h=i.dims[1]}else if(5===i.dims.length){if(i.dims[2]!==t.numHeads||2!==i.dims[3]||i.dims[4]!==g)throw new Error('Expect "key" shape (batch_size, kv_sequence_length, num_heads, 2, head_size) for packed kv');if(r)throw new Error('Expect "value" be none when "key" has packed kv format.');_=5,h=i.dims[1]}else{if(i.dims[1]!==t.numHeads||i.dims[3]!==g)throw new Error('Expect "key" shape (batch_size, num_heads, kv_sequence_length, head_size) for past_key');_=0,h=i.dims[2]}}else{if(5!==n.dims.length)throw new Error('Input "query" is expected to have 5 dimensions when key is empty');if(n.dims[2]!==t.numHeads||3!==n.dims[3])throw new Error('Expect "query" shape (batch_size, kv_sequence_length, num_heads, 3, head_size) for packed kv');_=3}if(s&&dt.size(s.dims)>0){if(1!==s.dims.length)throw new Error('Input "bias" is expected to have 1 dimension');if(i&&5===i.dims.length&&2===i.dims[3])throw new Error("bias is not allowed for packed kv.")}const w=f+h;let y=0;if(a&&dt.size(a.dims)>0){y=8;const e=a.dims;if(1===e.length?e[0]===l?y=1:e[0]===3*l+2&&(y=3):2===e.length&&e[0]===l&&e[1]===w&&(y=5),8===y)throw new Error('Input "key_padding_mask" shape shall be (batch_size) or (batch_size, total_sequence_length)');throw new Error("Mask not supported")}let $=!1,b=c;if(r&&dt.size(r.dims)>0){if(3!==r.dims.length&&4!==r.dims.length)throw new Error('Input "value" is expected to have 3 or 4 dimensions');if(n.dims[0]!==r.dims[0])throw new Error('Input "query" and "value" shall have same dim 0 (batch_size)');if(3===r.dims.length){if(h!==r.dims[1])throw new Error('Input "key" and "value" shall have the same dim 1 (kv_sequence_length)');b=r.dims[2]}else{if(h!==r.dims[2])throw new Error('Input "key" and "value" shall have the same dim 2 (kv_sequence_length)');b=r.dims[1]*r.dims[3],$=!0}}if(a&&dt.size(a.dims)>0)throw new Error("Key padding mask is not supported");if(o&&dt.size(o.dims)>0){if(4!==o.dims.length)throw new Error('Input "attention_bias" is expected to have 4 dimensions');if(o.dims[0]!==l||o.dims[1]!==t.numHeads||o.dims[2]!==p||o.dims[3]!==w)throw new Error('Expect "attention_bias" shape (batch_size, num_heads, sequence_length, total_sequence_length)')}return{batchSize:l,sequenceLength:p,pastSequenceLength:f,kvSequenceLength:h,totalSequenceLength:w,maxSequenceLength:m,inputHiddenSize:0,hiddenSize:c,vHiddenSize:b,headSize:g,vHeadSize:Math.floor(b/t.numHeads),numHeads:t.numHeads,isUnidirectional:!1,pastPresentShareBuffer:!1,maskFilterValue:t.maskFilterValue,maskType:y,scale:t.scale,broadcastResPosBias:!1,passPastInKv:$,qkvFormat:_}},Ua=e=>qt({...e}),Pa=qt({perm:[0,2,1,3]}),qa=(e,t,n,i,r,s,a)=>{const o=[i,r,s],u=dt.size(o),d=[{type:12,data:u},{type:12,data:a},{type:12,data:s}];return e.compute({name:"MultiHeadAttentionAddBias",shaderCache:{inputDependencies:["type","type"]},getRunData:()=>({outputs:[{dims:o,dataType:t.dataType,gpuDataType:0}],dispatchGroup:{x:Math.ceil(u/64)},programUniforms:d}),getShaderSource:e=>{const i=Yt("qkv_with_bias",t.dataType,o),r=Xt("qkv",t.dataType,o),s=Xt("bias",n.dataType,o);return`\n  ${e.registerUniforms([{name:"output_size",type:"u32"},{name:"bias_offset",type:"u32"},{name:"hidden_size",type:"u32"}]).declareVariables(r,s,i)}\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n    let bias_offset_idx = (global_idx % uniforms.hidden_size) + uniforms.bias_offset;\n\n    qkv_with_bias[global_idx] = qkv[global_idx] + bias[bias_offset_idx];\n  }`}},{inputs:[t,n],outputs:[-1]})[0]},Na=(e,t,n,i,r,s,a,o)=>{let u=s;if(a&&dt.size(a.dims)>0){if(1===i)throw new Error("AddBiasReshape is not implemented. Please export your model with packed QKV or KV");return u=qa(e,s,a,t,i,n*r,o),u=u.reshape([t,i,n,r]),1===n||1===i?u:e.compute(ln(u,Pa.perm),{inputs:[u],outputs:[-1]})[0]}return 3===s.dims.length&&(u=s.reshape([t,i,n,r])),1===n||1===i?u:e.compute(ln(u,Pa.perm),{inputs:[u],outputs:[-1]})[0]},Va=(e,t)=>{const n=Ma(e.inputs,t),i=e.inputs[0],r=Da(e.inputs,1),s=Da(e.inputs,2),a=Da(e.inputs,3),o=Da(e.inputs,4),u=Da(e.inputs,5),d=Da(e.inputs,6),l=Da(e.inputs,7);if(5===i.dims.length)throw new Error("Packed QKV is not implemented");if(5===r?.dims.length)throw new Error("Packed KV is not implemented");const p=r&&s&&4===r.dims.length&&4===s.dims.length,c=Na(e,n.batchSize,n.numHeads,n.sequenceLength,n.headSize,i,a,0);if(p)return mi(e,c,r,s,o,void 0,d,l,u,n);if(!r||!s)throw new Error("key and value must be provided");const h=Na(e,n.batchSize,n.numHeads,n.kvSequenceLength,n.headSize,r,a,n.hiddenSize),f=Na(e,n.batchSize,n.numHeads,n.kvSequenceLength,n.vHeadSize,s,a,2*n.hiddenSize);mi(e,c,h,f,o,void 0,d,l,u,n)}}}),Zd=P({"web/lib/wasm/jsep/webgpu/ops/split.ts"(){rd(),od(),hd(),fd(),La=e=>{if(!e||e.length<1)throw new Error("too few inputs")},Ga=(e,t)=>{const n=[];let i=t.numOutputs;return e[1].dims[0]>0&&(e[1].getBigInt64Array().forEach(e=>n.push(Number(e))),i=n.length),qt({numOutputs:i,axis:t.axis,splitSizes:n})},Wa=e=>`\nfn calculateOutputIndex(index: u32) -> u32 {\n    for (var i: u32 = 0u; i < ${e}u; i += 1u ) {\n    if (index < ${Zt("uniforms.size_in_split_axis","i",e)}) {\n        return i;\n    }\n    }\n    return ${e}u;\n}`,ja=e=>{const t=e.length,n=[];for(let i=0;i<t;++i){const r=e[i].setByIndices("indices","input[global_idx]");1===t?n.push(r):0===i?n.push(`if (output_number == ${i}u) { ${r} }`):i===t-1?n.push(`else { ${r} }`):n.push(`else if (output_number == ${i}) { ${r} }`)}return`\n      fn writeBufferData(output_number: u32, indices: ${e[0].type.indices}, global_idx: u32) {\n        ${n.join("\n")}\n      }`},Ha=(e,t)=>{const n=e[0].dims,i=dt.size(n),r=e[0].dataType,s=dt.normalizeAxis(t.axis,n.length),a=new Array(t.numOutputs),o=Xt("input",r,n.length),u=new Array(t.numOutputs),d=[],l=[];let p=0;const c=[{type:12,data:i}];for(let i=0;i<t.numOutputs;i++){p+=t.splitSizes[i],u[i]=p;const o=n.slice();o[s]=t.splitSizes[i],l.push(o),a[i]=Yt(`output${i}`,r,o.length),d.push({dims:l[i],dataType:e[0].dataType})}return c.push({type:12,data:u},...Wt(n,...l)),{name:"Split",shaderCache:{hint:t.cacheKey,inputDependencies:["rank"]},getShaderSource:e=>`\n  ${e.registerUniform("input_size","u32").registerUniform("size_in_split_axis","u32",u.length).declareVariables(o,...a)}\n  ${Wa(u.length)}\n  ${ja(a)}\n\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.input_size")}\n\n    var indices = ${o.offsetToIndices("global_idx")};\n    var index = ${o.indicesGet("indices",s)};\n    let output_number = calculateOutputIndex(index);\n    if (output_number != 0) {\n      index -= ${Zt("uniforms.size_in_split_axis","output_number - 1u",u.length)};\n      ${o.indicesSet("indices",s,"index")};\n    }\n    writeBufferData(output_number, indices, global_idx);\n  }`,getRunData:()=>({outputs:d,dispatchGroup:{x:Math.ceil(i/64)},programUniforms:c})}},Fa=(e,t)=>{La(e.inputs);const n=1===e.inputs.length?t:Ga(e.inputs,t);e.compute(Ha(e.inputs,n),{inputs:[0]})},Ka=e=>{const t=e.axis,n=e.splitSizes,i=e.numOutputs<0?n.length:e.numOutputs;if(i!==n.length)throw new Error("numOutputs and splitSizes length must be equal");return qt({axis:t,numOutputs:i,splitSizes:n})}}}),Qd=P({"web/lib/wasm/jsep/webgpu/ops/rotary-embedding.ts"(){rd(),od(),hd(),fd(),Za=(e,t)=>{const[n,i,r,s]=e,{numHeads:a,rotaryEmbeddingDim:o}=t;if(3!==n.dims.length&&4!==n.dims.length)throw new Error(`Input 'x' is expected to have 3 or 4 dimensions, got ${n.dims.length}`);if(!dt.areEqual(i.dims,[])&&!dt.areEqual(i.dims,[1])&&2!==i.dims.length)throw new Error(`Input 'position_ids' is expected to have 0, 1, or 2 dimensions, got ${i.dims.length}`);if(2!==r.dims.length)throw new Error(`Input 'cos_cache' is expected to have 2 dimensions, got ${r.dims.length}`);if(2!==s.dims.length)throw new Error(`Input 'sin_cache' is expected to have 2 dimensions, got ${s.dims.length}`);if(!dt.areEqual(r.dims,s.dims))throw new Error("Inputs 'cos_cache' and 'sin_cache' are expected to have the same shape");if(o>0&&0===a)throw new Error("num_heads must be provided if rotary_embedding_dim is specified");const u=n.dims[0],d=n.dims[n.dims.length-2],l=r.dims[0],p=dt.sizeFromDimension(n.dims,1)/d,c=0===o?2*r.dims[1]:p/a;if(o>c)throw new Error("rotary_embedding_dim must be less than or equal to head_size");if(2===i.dims.length){if(u!==i.dims[0])throw new Error(`Input 'position_ids' dimension 0 should be of size batch_size, got ${i.dims[0]}`);if(d!==i.dims[1])throw new Error(`Input 'position_ids' dimension 1 should be of size sequence_length, got ${i.dims[1]}`)}if(c/2!==r.dims[1]&&o/2!==r.dims[1])throw new Error(`Input 'cos_cache' dimension 1 should be same as head_size / 2 or rotary_embedding_dim / 2, got ${r.dims[1]}`);if(d>l)throw new Error("Updating cos_cache and sin_cache in RotaryEmbedding is not currently supported")},Qa=(e,t)=>{const{interleaved:n,numHeads:i,rotaryEmbeddingDim:r,scale:s}=t,a=e[0].dims[0],o=dt.sizeFromDimension(e[0].dims,1),u=e[0].dims[e[0].dims.length-2],d=o/u,l=e[2].dims[1],p=0===r?2*l:d/i,c=new Array(a,u,d/p,p-l),h=dt.computeStrides(c),f=[{type:1,data:s},{type:12,data:c},{type:12,data:h},...3===e[0].dims.length?new Array({type:12,data:[o,d,p,1]}):[],...4===e[0].dims.length?new Array({type:12,data:[o,p,u*p,1]}):[],...Wt(e[0].dims,e[1].dims,e[2].dims,e[3].dims,e[0].dims)];return{name:"RotaryEmbedding",shaderCache:{hint:qt({interleaved:n}).cacheKey,inputDependencies:["rank","rank","rank","rank"]},getShaderSource:t=>{const i=Xt("input",e[0].dataType,e[0].dims.length),r=Xt("position_ids",e[1].dataType,e[1].dims.length),s=Xt("cos_cache",e[2].dataType,e[2].dims.length),a=Xt("sin_cache",e[3].dataType,e[3].dims.length),o=Yt("output",e[0].dataType,e[0].dims.length);return t.registerUniforms([{name:"scale",type:"f32"},{name:"global_shape",type:"u32",length:c.length},{name:"global_strides",type:"u32",length:h.length},{name:"input_output_strides",type:"u32",length:h.length}]),`\n        ${t.declareVariables(i,r,s,a,o)}\n\n        ${t.mainStart(Nt)}\n          let half_rotary_emb_dim = uniforms.${s.name}_shape[1];\n          let bsnh = global_idx / uniforms.global_strides % uniforms.global_shape;\n          let size = uniforms.global_shape[0] * uniforms.global_strides[0];\n          ${t.guardAgainstOutOfBoundsWorkgroupSizes("size")}\n\n          if (bsnh[3] < half_rotary_emb_dim) {\n            let position_ids_idx =\n                ${r.broadcastedIndicesToOffset("bsnh.xy",Yt("",r.type.tensor,2))};\n            let position_id =\n                u32(${r.getByOffset("position_ids_idx")}) + select(0, bsnh[1], position_ids_idx == 0);\n            let i = dot(bsnh, uniforms.input_output_strides) + select(0, bsnh[3], ${n});\n            let j = i + select(half_rotary_emb_dim, 1, ${n});\n            let re = ${i.getByOffset("i")} * ${s.get("position_id","bsnh[3]")} -\n                ${i.getByOffset("j")} * ${a.get("position_id","bsnh[3]")};\n            ${o.setByOffset("i","re")}\n            let im = ${i.getByOffset("i")} * ${a.get("position_id","bsnh[3]")} +\n                ${i.getByOffset("j")} * ${s.get("position_id","bsnh[3]")};\n            ${o.setByOffset("j","im")}\n          } else {\n            let k = dot(bsnh, uniforms.input_output_strides) + half_rotary_emb_dim;\n            ${o.setByOffset("k",i.getByOffset("k"))}\n          }\n        }`},getRunData:()=>({outputs:[{dims:e[0].dims,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(dt.size(c)/Nt)},programUniforms:f})}},Xa=(e,t)=>{Za(e.inputs,t),e.compute(Qa(e.inputs,t))}}}),Xd=P({"web/lib/wasm/jsep/webgpu/ops/group-query-attention.ts"(){hd(),rd(),yd(),Kd(),Zd(),md(),Qd(),fd(),Ya=(e,t)=>{if(t.doRotary&&e.length<=7)throw new Error("cos_cache and sin_cache inputs are required if do_rotary is specified");const n=e[0],i=e[1],r=e[2],s=e[3],a=e[4];if(0!==t.doRotary&&e.length<=7)throw new Error("cos_cast and sin_cache are expected if do_rotary attribute is non-zero");if(-1!==t.localWindowSize)throw new Error("Local attention is not supported");if(0!==t.softcap)throw new Error("Softcap is not supported");if(0!==t.rotaryInterleaved)throw new Error("Rotary interleaved is not supported");if(t.smoothSoftmax)throw new Error("Smooth softmax is not supported");if(3!==n.dims.length&&5!==n.dims.length)throw new Error("Input query is expected to have 3 or 5 dimensions");const o=n.dims[0],u=n.dims[1];let d=3===n.dims.length?n.dims[2]:t.numHeads*n.dims[4],l=u,p=0;const c=!i||0===i.dims.length,h=c?Math.floor(d/(t.numHeads+2*t.kvNumHeads)):Math.floor(d/t.numHeads);c&&(d=h*t.numHeads);const f=s&&0!==s.dims.length,m=a&&0!==a.dims.length;if(f&&4===s.dims.length&&s.dims[0]===o&&s.dims[1]!==t.kvNumHeads&&s.dims[2]===t.kvNumHeads&&s.dims[3]===h)throw new Error("BSNH pastKey/pastValue is not supported");if(f&&m){if(4!==s.dims.length)throw new Error('Input "past_key" is expected to have 4 dimensions');if(4!==a.dims.length)throw new Error('Input "past_value" is expected to have 4 dimensions');p=s.dims[2]}else if(f||m)throw new Error('Input "past_key" and "past_value" shall be both present or both absent');let g=1;if(i&&i.dims.length>0){if(3!==n.dims.length)throw new Error('Input "query" is expected to have 3 dimensions when key is given');if(i.dims.length<3||i.dims.length>5)throw new Error('Input "key" is expected to have 3, 4, or 5 dimensions');if(n.dims[0]!==i.dims[0])throw new Error('Input "query" and "key" shall have same dim 0 (batch size)');if(3===i.dims.length){if(n.dims[2]%i.dims[2]!==0)throw new Error('Dimension 2 of "query" should be a multiple of "key"');l=i.dims[1]}else if(5===i.dims.length){if(i.dims[2]!==t.numHeads||2!==i.dims[3]||i.dims[4]!==h)throw new Error('Expect "key" shape (batch_size, kv_sequence_length, num_heads, 2, head_size) for packed kv');if(r)throw new Error('Expect "value" be none when "key" has packed kv format.');l=i.dims[1]}else{if(i.dims[1]!==t.numHeads||i.dims[3]!==h)throw new Error('Expect "key" shape (batch_size, num_heads, kv_sequence_length, head_size) for past_key');l=i.dims[2]}}else{if(3!==n.dims.length&&5!==n.dims.length)throw new Error('Input "query" is expected to have 3 or 5 dimensions when key is empty');if(5===n.dims.length&&(n.dims[2]!==t.numHeads||3!==n.dims[3]))throw new Error('Expect "query" shape (batch_size, kv_sequence_length, num_heads, 3, head_size) for packed kv');g=3}let _=!1,w=t.kvNumHeads?h*t.kvNumHeads:d;if(r&&r.dims.length>0){if(3!==r.dims.length&&4!==r.dims.length)throw new Error('Input "value" is expected to have 3 or 4 dimensions');if(n.dims[0]!==r.dims[0])throw new Error('Input "query" and "value" shall have same dim 0 (batch_size)');if(3===r.dims.length){if(l!==r.dims[1])throw new Error('Input "key" and "value" shall have the same dim 1 (kv_sequence_length)');w=r.dims[2]}else{if(l!==r.dims[2])throw new Error('Input "past_key" and "past_value" shall have the same dim 2 (kv_sequence_length)');w=r.dims[1]*r.dims[3],_=!0}}const y=e.length>4?e[5]:void 0;if(y&&1!==y.dims.length&&y.dims[0]!==o)throw new Error('Input "seqlens" is expected to have 1 dimension and the same dim 0 as batch_size');return{batchSize:o,sequenceLength:u,pastSequenceLength:p,kvSequenceLength:l,totalSequenceLength:-1,maxSequenceLength:-1,inputHiddenSize:0,hiddenSize:d,vHiddenSize:w,headSize:h,vHeadSize:Math.floor(w/t.kvNumHeads),numHeads:t.numHeads,kvNumHeads:t.kvNumHeads,nReps:t.numHeads/t.kvNumHeads,pastPresentShareBuffer:!1,maskType:0,scale:t.scale,broadcastResPosBias:!1,passPastInKv:_,qkvFormat:g}},Ja=qt({perm:[0,2,1,3]}),eo=(e,t,n)=>{let i=t;const r=n.kvNumHeads;return 3===t.dims.length&&0!==n.kvSequenceLength&&(i=t.reshape([n.batchSize,n.kvSequenceLength,r,n.headSize]),i=e.compute(ln(i,Ja.perm),{inputs:[i],outputs:[-1]})[0]),i},to=(e,t,n,i)=>{const r=[e*t],s=e*t,a=[{type:12,data:s},{type:12,data:t},{type:12,data:e}];return{name:"GeneratePositionIds",shaderCache:{hint:`${e};${t}`,inputDependencies:["type","type"]},getRunData:()=>({outputs:[{dims:r,dataType:7}],dispatchGroup:{x:Math.ceil(s/64)},programUniforms:a}),getShaderSource:e=>{const t=Xt("seq_lens",n.dataType,n.dims),s=Xt("total_seq_lens",i.dataType,i.dims),a=Yt("pos_ids",7,r);return`\n  ${e.registerUniforms([{name:"output_size",type:"u32"},{name:"sequence_length",type:"u32"},{name:"batch_size",type:"u32"}]).declareVariables(t,s,a)}\n  ${e.mainStart()}\n    ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n    let total_sequence_length = u32(${s.getByOffset("0")});\n    let is_subsequent_prompt = uniforms.sequence_length > 1 && uniforms.sequence_length != total_sequence_length;\n    let is_first_prompt = !is_subsequent_prompt && uniforms.sequence_length == total_sequence_length;\n    let batch_idx = global_idx / uniforms.sequence_length;\n    let sequence_idx = i32(global_idx % uniforms.sequence_length);\n    var pos_id: i32 = 0;\n    let seqlen = ${t.getByOffset("batch_idx")};\n    let total_seqlen = seqlen + 1;\n    if (is_first_prompt) {\n      if (sequence_idx < total_seqlen) {\n        pos_id = sequence_idx;\n      } else {\n        pos_id = 1;\n      }\n      ${a.setByOffset("global_idx","pos_id")}\n    } else if (is_subsequent_prompt) {\n      let past_seqlen = total_seqlen - i32(uniforms.sequence_length);\n      if (past_seqlen + sequence_idx < total_seqlen) {\n        pos_id = past_seqlen + sequence_idx;\n      } else {\n        pos_id = 1;\n      }\n      ${a.setByOffset("global_idx","pos_id")}\n    } else if (global_idx < uniforms.batch_size) {\n      ${a.setByOffset("global_idx","seqlen")}\n    };\n  }\n  `}}},no=(e,t)=>{const n=Ya(e.inputs,t);if(5===e.inputs[0].dims.length)throw new Error("Packed QKV is not implemented");if(5===e.inputs[1]?.dims.length)throw new Error("Packed KV is not implemented");const i=e.inputs[0],r=e.inputs[1]&&e.inputs[1].dims.length>0?e.inputs[1]:void 0,s=e.inputs[2]&&e.inputs[2].dims.length>0?e.inputs[2]:void 0,a=e.inputs[3]&&0!==e.inputs[3].dims.length?e.inputs[3]:void 0,o=e.inputs[4]&&0!==e.inputs[4].dims.length?e.inputs[4]:void 0,u=e.inputs.length>4?e.inputs[5]:void 0,d=e.inputs.length>5?e.inputs[6]:void 0,l=n.kvNumHeads?n.kvNumHeads:n.numHeads,p=qt({axis:2,numOutputs:3,splitSizes:[n.numHeads*n.headSize,l*n.headSize,l*n.headSize]}),[c,h,f]=r||s?[i,r,s]:e.compute(Ha([i],p),{inputs:[i],outputs:[-1,-1,-1]});let m,g;if(t.doRotary){const i=e.compute(to(n.batchSize,n.sequenceLength,u,d),{inputs:[u,d],outputs:[-1]})[0],r=e.inputs[7],s=e.inputs[8],a=qt({interleaved:0!==t.rotaryInterleaved,numHeads:n.numHeads,rotaryEmbeddingDim:0,scale:t.scale}),o=[c,i,r,s],l=[-1];m=e.compute(Qa(o,a),{inputs:o,outputs:l})[0],o.splice(0,1,h);const p=qt({interleaved:0!==t.rotaryInterleaved,numHeads:n.kvNumHeads,rotaryEmbeddingDim:0,scale:t.scale});g=e.compute(Qa(o,p),{inputs:o,outputs:l})[0]}const _=Na(e,n.batchSize,n.numHeads,n.sequenceLength,n.headSize,t.doRotary?m:c,void 0,0),w=eo(e,t.doRotary?g:h,n),y=eo(e,f,n);mi(e,_,w,y,void 0,void 0,a,o,void 0,n,u,d)}}}),Yd=P({"web/lib/wasm/jsep/webgpu/ops/instance-norm.ts"(){rd(),od(),md(),fd(),io=(e,t,n,i,r,s,a,o)=>{const u=jt(s),d=1===u?"f32":`vec${u}f`,l=1===u?"vec2f":`mat2x${u}f`,p=r*a;let c=64;1===p&&(c=256);const h=[r,a,s/u],f=[r,a,2],m=[];return m.push(...Wt(h,f)),e.compute({name:"InstanceNormComputeChannelScaleShift",shaderCache:{hint:`${u};${o};${c}`,inputDependencies:["rank","type","type"]},getRunData:()=>({outputs:[{dims:f,dataType:1}],dispatchGroup:{x:p},programUniforms:m}),getShaderSource:e=>{const r=Xt("x",t.dataType,3,u),s=[r,Xt("scale",n.dataType,n.dims),Xt("bias",i.dataType,i.dims),Yt("output",1,3,2)];return`\n  var<workgroup> workgroup_shared : array<${l}, ${c}>;\n  const workgroup_size = ${c}u;\n  ${e.declareVariables(...s)}\n  ${e.mainStart(c)}\n    let batch = workgroup_index / uniforms.x_shape[1];\n    let channel = workgroup_index % uniforms.x_shape[1];\n    let hight = uniforms.x_shape[2];\n    // initialize workgroup memory\n    var sum = ${d}(0);\n    var squared_sum = ${d}(0);\n    for (var h = local_idx; h < hight; h += workgroup_size) {\n      let value = ${d}(${r.get("batch","channel","h")});\n      sum += value;\n      squared_sum += value * value;\n    }\n    workgroup_shared[local_idx] = ${l}(sum, squared_sum);\n    workgroupBarrier();\n\n    for (var currSize = workgroup_size >> 1;  currSize > 0; currSize = currSize >> 1) {\n      if (local_idx < currSize) {\n        workgroup_shared[local_idx] = workgroup_shared[local_idx] + workgroup_shared[local_idx + currSize];\n      }\n      workgroupBarrier();\n    }\n    if (local_idx == 0) {\n      let sum_final = ${Kt("workgroup_shared[0][0]",u)} / f32(hight * ${u});\n      let squared_sum_final = ${Kt("workgroup_shared[0][1]",u)} / f32(hight * ${u});\n\n      let inv_std_dev = inverseSqrt(squared_sum_final - sum_final * sum_final + f32(${o}));\n      let channel_scale = inv_std_dev * f32(scale[channel]);\n      let channel_shift = f32(bias[channel]) - sum_final * channel_scale;\n      output[workgroup_index] = vec2f(channel_scale, channel_shift);\n    }\n  }`}},{inputs:[t,n,i],outputs:[-1]})[0]},ro=(e,t,n)=>{const i=t[0].dims,r=i,s=i[0],a=i[1],o=dt.sizeFromDimension(i,2),u=jt(o),d=dt.size(r)/u,l=io(e,t[0],t[1],t[2],s,o,a,n.epsilon),p=[s,a,o/u],c=[s,a];e.compute({name:"InstanceNormalization",shaderCache:{hint:`${u}`,inputDependencies:["type","none"]},getRunData:()=>({outputs:[{dims:r,dataType:t[0].dataType}],dispatchGroup:{x:Math.ceil(d/64)},programUniforms:[{type:12,data:d},...Wt(p,c,p)]}),getShaderSource:e=>{const n=Xt("x",t[0].dataType,p.length,u),i=Xt("scale_shift",1,c.length,2),r=Yt("output",t[0].dataType,p.length,u),s=[n,i,r];return`\n  ${e.registerUniform("output_size","u32").declareVariables(...s)}\n  ${e.mainStart()}\n  ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n      let outputIndices = ${r.offsetToIndices("global_idx")};\n      let batch = outputIndices[0];\n      let channel = outputIndices[1];\n      let scale_shift = ${i.getByIndices("vec2<u32>(batch, channel)")};\n      let value = ${n.getByOffset("global_idx")} * ${r.type.value}(scale_shift.x) + ${r.type.value}(scale_shift.y);\n      ${r.setByOffset("global_idx","value")};\n  }`}},{inputs:[t[0],l]})},so=(e,t,n)=>{const i=t[0].dims,r=i,s=i[0],a=i[i.length-1],o=dt.sizeFromDimension(i,1)/a,u=jt(a),d=dt.size(r)/u,l=[{type:12,data:o},{type:12,data:Math.floor(a/u)}];let p=!1;const c=[0,i.length-1];for(let e=0;e<i.length-2;e++)p=p||1!==i[e+1],c.push(e+1);p=p&&1!==i[i.length-1];const h=p?e.compute(ln(e.inputs[0],c),{inputs:[e.inputs[0]],outputs:[-1]})[0]:e.inputs[0].reshape(Array.from({length:i.length},(e,t)=>i[c[t]])),f=io(e,h,t[1],t[2],s,o,a,n.epsilon);e.compute({name:"InstanceNormalizationNHWC",shaderCache:{hint:`${u}`,inputDependencies:["type","type"]},getRunData:()=>({outputs:[{dims:r,dataType:t[0].dataType}],dispatchGroup:{x:Math.ceil(d/64)},programUniforms:l}),getShaderSource:e=>{const n=Lt(t[0].dataType),i=1===u?"vec2f":`mat${u}x2f`,s=e=>{const t=0===e?"x":"y",i=1===u?"f32":`vec${u}f`;switch(u){case 1:return`${n}(${i}(scale.${t}))`;case 2:return`vec2<${n}>(${i}(scale[0].${t}, scale[1].${t}))`;case 4:return`vec4<${n}>(${i}(scale[0].${t}, scale[1].${t}, scale[2].${t}, scale[3].${t}))`;default:throw new Error(`Not supported compoents ${u}`)}},a=Xt("input",t[0].dataType,t[0].dims,u),o=Yt("output",t[0].dataType,r,u);return`\n  @group(0) @binding(0) var<storage, read> input : array<${a.type.storage}>;\n  @group(0) @binding(1) var<storage, read> scale_input : array<${i}>;\n  @group(0) @binding(2) var<storage, read_write> output : array<${o.type.storage}>;\n  struct Uniforms {H: u32, C : u32};\n  @group(0) @binding(3) var<uniform> uniforms: Uniforms;\n\n  ${e.mainStart()}\n    let current_image_number = global_idx / (uniforms.C * uniforms.H);\n    let current_channel_number = global_idx % uniforms.C;\n\n    let scale_offset = current_image_number * uniforms.C + current_channel_number;\n    let scale = scale_input[scale_offset];\n    output[global_idx] = fma(input[global_idx], ${s(0)}, ${s(1)});\n  }`}},{inputs:[t[0],f]})},ao=(e,t)=>{"NHWC"===t.format?so(e,e.inputs,t):ro(e,e.inputs,t)}}}),Jd=P({"web/lib/wasm/jsep/webgpu/ops/layer-norm.ts"(){rd(),od(),fd(),oo=e=>{if(!e||e.length<2)throw new Error("layerNorm requires at least 2 inputs.")},uo=(e,t,n)=>{const i=t.simplified,r=e[0].dims,s=e[1],a=!i&&e[2],o=r,u=dt.normalizeAxis(t.axis,r.length),d=dt.sizeToDimension(r,u),l=dt.sizeFromDimension(r,u),p=dt.size(s.dims),c=a?dt.size(a.dims):0;if(p!==l||a&&c!==l)throw new Error(`Size of X.shape()[axis:] == ${l}.\n       Size of scale and bias (if provided) must match this.\n       Got scale size of ${p} and bias size of ${c}`);const h=[];for(let e=0;e<r.length;++e)e<u?h.push(r[e]):h.push(1);const f=jt(l),m=["type","type"],g=[{type:12,data:d},{type:1,data:l},{type:12,data:Math.floor(l/f)},{type:1,data:t.epsilon}];a&&m.push("type");const _=n>1,w=n>2,y=[{dims:o,dataType:e[0].dataType}];return _&&y.push({dims:h,dataType:1}),w&&y.push({dims:h,dataType:1}),{name:"LayerNormalization",shaderCache:{hint:`${f};${n};${i}`,inputDependencies:m},getRunData:()=>({outputs:y,dispatchGroup:{x:Math.ceil(d/64)},programUniforms:g}),getShaderSource:t=>{const n=Lt(e[0].dataType),r=[Xt("x",e[0].dataType,e[0].dims,f),Xt("scale",s.dataType,s.dims,f)];return a&&r.push(Xt("bias",a.dataType,a.dims,f)),r.push(Yt("output",e[0].dataType,o,f)),_&&r.push(Yt("mean_data_output",1,h)),w&&r.push(Yt("inv_std_output",1,h)),`\n  ${t.registerUniforms([{name:"norm_count",type:"u32"},{name:"norm_size",type:"f32"},{name:"norm_size_vectorized",type:"u32"},{name:"epsilon",type:"f32"}]).declareVariables(...r)}\n  ${t.mainStart()}\n    ${t.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.norm_count")}\n    let offset = global_idx * uniforms.norm_size_vectorized;\n    var mean_vector = ${Ht("f32",f)};\n    var mean_square_vector = ${Ht("f32",f)};\n\n    for (var h: u32 = 0u; h < uniforms.norm_size_vectorized; h++) {\n      let value = ${Ft(n,f,"x[h + offset]")};\n      mean_vector += value;\n      mean_square_vector += value * value;\n    }\n    let mean = ${Kt("mean_vector",f)} / uniforms.norm_size;\n    let inv_std_dev = inverseSqrt(${Kt("mean_square_vector",f)} / uniforms.norm_size ${i?"":"- mean * mean"} + uniforms.epsilon);\n\n    for (var j: u32 = 0; j < uniforms.norm_size_vectorized; j++) {\n      let f32input = ${Ft(n,f,"x[j + offset]")};\n      let f32scale = ${Ft(n,f,"scale[j]")};\n      output[j + offset] = ${r[0].type.value}((f32input ${i?"":"- mean"}) * inv_std_dev * f32scale\n        ${a?`+ ${Ft(n,f,"bias[j]")}`:""}\n      );\n    }\n\n    ${_?"mean_data_output[global_idx] = mean":""};\n    ${w?"inv_std_output[global_idx] = inv_std_dev":""};\n  }`}}},lo=(e,t)=>{oo(e.inputs),e.compute(uo(e.inputs,t,e.outputCount))}}}),el=P({"web/lib/wasm/jsep/webgpu/ops/matmul.ts"(){od(),Ed(),Cd(),po=e=>{if(!e||2!==e.length)throw new Error("MatMul requires 2 inputs.");if(e[0].dims[e[0].dims.length-1]!==e[1].dims[e[1].dims.length-2])throw new Error("shared dimension does not match.")},co=e=>{po(e.inputs);const t=ut.calcShape(e.inputs[0].dims,e.inputs[1].dims,!0);if(!t)throw new Error("Can't use matmul on the given tensors");const n=t[t.length-1],i=e.inputs[0].dims[e.inputs[0].dims.length-1];if(n<8&&i<8)e.compute(Hr(e.inputs,{activation:""},t));else{const r=t[t.length-2],s=dt.size(e.inputs[0].dims.slice(0,-2)),a=dt.size(e.inputs[1].dims.slice(0,-2));if(1!==s&&1===r&&1===a){const r=[1,s,n],a=[e.inputs[0].reshape([1,s,i]),e.inputs[1].reshape([1,i,n])];e.compute(es(a,{activation:""},t,r),{inputs:a})}else e.compute(es(e.inputs,{activation:""},t))}}}}),tl=P({"web/lib/wasm/jsep/webgpu/ops/matmulnbits.ts"(){rd(),od(),hd(),fd(),ho=(e,t)=>{if(e.length<3||e.length>4)throw new Error("MatMulNBits requires 3 or 4 inputs");const n=e[0],i=n.dims.length;if(n.dims[i-1]!==t.k)throw new Error("The last dim of input shape does not match the k value");const r=Math.floor((t.k+t.blockSize-1)/t.blockSize),s=t.blockSize/8*t.bits,a=e[1];if(!dt.areEqual(a.dims,[t.n,r,s]))throw new Error("The second inputs must be 3D tensor with shape N X nBlocksPerCol X blobSize");const o=e[2].dims;if(dt.size(o)!==t.n*r)throw new Error("scales input size error.");if(4===e.length){const n=e[3].dims,i=t.n*(8===t.bits?r:Math.floor((r*t.bits+7)/8));if(dt.size(n)!==i)throw new Error("zeroPoints input size error.")}},fo=(e,t)=>{const n=e[0].dims,i=n.length,r=n[i-2],s=t.k,a=t.n,o=n.slice(0,i-2),u=dt.size(o),d=e[1].dims[2]/4,l=e[0].dataType,p=jt(t.k),c=jt(d),h=jt(a),f=o.concat([r,a]),m=r>1&&a/h%2==0?2:1,g=dt.size(f)/h/m,_=[],w=[u,r,s/p],y=dt.convertShape(e[1].dims).slice();y.splice(-1,1,d/c),_.push(...Wt(w)),_.push(...Wt(y)),_.push(...Wt(e[2].dims)),4===e.length&&_.push(...Wt(dt.convertShape(e[3].dims)));const $=[u,r,a/h];return _.push(...Wt($)),{name:"MatMulNBits",shaderCache:{hint:`${t.blockSize};${t.bits};${p};${c};${h};${m};64`,inputDependencies:Array(e.length).fill("rank")},getRunData:()=>({outputs:[{dims:f,dataType:l}],dispatchGroup:{x:g},programUniforms:_}),getShaderSource:n=>{const i=w.length,r=Xt("a",e[0].dataType,i,p),s=Xt("b",12,y.length,c),a=Xt("scales",e[2].dataType,e[2].dims.length),o=[r,s,a],u=4===e.length?Xt("zero_points",12,e[3].dims.length):void 0;u&&o.push(u);const l=$.length,f=Yt("output",e[0].dataType,l,h),g=Lt(e[0].dataType),_=(()=>{switch(p){case 1:return`array<${g}, 8>`;case 2:return`mat4x2<${g}>`;case 4:return`mat2x4<${g}>`;default:throw new Error(`${p}-component is not supported.`)}})();return`\n        var<workgroup> workgroup_shared: array<${f.type.value}, ${64*m}>;\n        ${n.declareVariables(...o,f)}\n        ${n.mainStart([64,1,1])}\n          let output_indices = ${f.offsetToIndices(`(global_idx / 64) * ${m}`)};\n          let col = output_indices[2];\n          let row = output_indices[1];\n          let batch = output_indices[0];\n          let nBlocksPerCol = uniforms.b_shape[1];\n\n          for (var block = local_id.x; block < nBlocksPerCol; block += 64) {\n            //process one block\n            var word_offset: u32 = block * ${t.blockSize/p};\n            ${(()=>{let e=`\n            var col_index = col * ${h};\n            ${u?"\n            let zero_point_bytes_per_col = (nBlocksPerCol + 1) / 2;\n            var zero_point_byte_count: u32;\n            var zero_point_word_index: u32;\n            var zero_point_byte_offset: u32;\n            let zero_point_nibble_offset: u32 = block & 0x1u;\n            var zero_point_bits_offset: u32;\n            var zero_point_word: u32;":`\n            // The default zero point is 8 for unsigned 4-bit quantization.\n            let zero_point = ${g}(8);`}\n            `;for(let t=0;t<h*m;t++)e+=`\n            let scale${t} = ${a.getByOffset("col_index * nBlocksPerCol + block")};\n            ${u?`\n            zero_point_byte_count = col_index * zero_point_bytes_per_col + (block >> 0x1u);\n            zero_point_word_index = zero_point_byte_count >> 0x2u;\n            zero_point_byte_offset = zero_point_byte_count & 0x3u;\n            zero_point_bits_offset = (zero_point_byte_offset << 3) + (zero_point_nibble_offset << 2);\n            zero_point_word = ${u.getByOffset("zero_point_word_index")} >> zero_point_bits_offset;\n            let zero_point${t} = ${g}((zero_point_word) & 0xFu);`:""}\n            col_index += 1;`;return e})()}\n            for (var word: u32 = 0; word < ${d}; word += ${c}) {\n              ${(()=>{let e=`col_index = col * ${h};`;for(let t=0;t<h*m;t++)e+=`\n            let b${t}_data = ${s.getByIndices(`${s.type.indices}(col_index, block, word)`)};\n            col_index += 1;`;return e+=`\n            var b_value: u32;\n            let b_mask: u32 = 0x0F0F0F0Fu;\n            var b_value_lower: vec4<u32>;\n            var b_value_upper: vec4<u32>;\n            var b_quantized_values: ${_};\n            var b_dequantized_values: ${_};`,e})()}\n              for (var i: u32 = 0; i < ${c}; i++) {\n                ${(()=>{let e=`\n          // reuse a data\n            var input_offset = ${r.indicesToOffset(`${r.type.indices}(batch, row, word_offset)`)};\n            var a_data: ${_};\n            for (var j: u32 = 0; j < ${8/p}; j++) {\n              a_data[j] = ${r.getByOffset("input_offset")};\n              input_offset++;\n            }\n          `;for(let t=0;t<h*m;t++)e+=`\n            b_value = ${1===c?`b${t}_data`:`b${t}_data[i]`};\n            b_value_lower = unpack4xU8(b_value & b_mask);\n            b_value_upper = unpack4xU8((b_value >> 4) & b_mask);\n            b_quantized_values = ${_}(${Array.from({length:4},(e,t)=>`${g}(b_value_lower[${t}]), ${g}(b_value_upper[${t}])`).join(", ")});\n            b_dequantized_values = ${(()=>1===p?`${_}(${Array.from({length:8},(e,n)=>`(b_quantized_values[${n}] - ${u?`zero_point${t}`:"zero_point"}) * scale${t}`).join(", ")});`:`(b_quantized_values - ${_}(${Array(8).fill(u?`zero_point${t}`:"zero_point").join(",")})) * scale${t};`)()};\n            workgroup_shared[local_id.x * ${m} + ${Math.floor(t/h)}]${h>1?`[${t%h}]`:""} += ${Array.from({length:8/p},(e,t)=>1===p?`a_data[${t}] * b_dequantized_values[${t}]`:`dot(a_data[${t}], b_dequantized_values[${t}])`).join(" + ")};\n          `;return e})()}\n                word_offset += ${8/p};\n              }\n            }\n          }\n          workgroupBarrier();\n\n          if (local_id.x < ${m}) {\n            var output_value: ${f.type.value} = ${f.type.value}(0);\n            var workgroup_shared_offset: u32 = local_id.x;\n            for (var b: u32 = 0u; b < 64u; b++) {\n              output_value += workgroup_shared[workgroup_shared_offset];\n              workgroup_shared_offset += ${m};\n            }\n            ${f.setByIndices(`${f.type.indices}(batch, row, col + local_id.x)`,"output_value")};\n          }\n        }`}}},mo=(e,t)=>{const n=e[0].dims,i=n.length,r=n[i-2],s=t.k,a=t.n,o=n.slice(0,i-2),u=dt.size(o),d=e[1].dims[2]/4,l=e[0].dataType,p=jt(t.k),c=jt(d),h=o.concat([r,a]),f=a%8==0?8:a%4==0?4:1,m=128/f,g=m*c*8,_=g/p,w=g/t.blockSize,y=dt.size(h)/f,$=[],b=[u,r,s/p],v=dt.convertShape(e[1].dims).slice();v.splice(-1,1,d/c),$.push(...Wt(b)),$.push(...Wt(v)),$.push(...Wt(e[2].dims)),4===e.length&&$.push(...Wt(dt.convertShape(e[3].dims)));const x=[u,r,a];return $.push(...Wt(x)),{name:"BlockwiseMatMulNBits32",shaderCache:{hint:`${t.blockSize};${p};${c};${m};${f}`,inputDependencies:Array(e.length).fill("rank")},getRunData:()=>({outputs:[{dims:h,dataType:l}],dispatchGroup:{x:y},programUniforms:$}),getShaderSource:n=>{const i=b.length,r=Xt("a",e[0].dataType,i,p),s=Xt("b",12,v.length,c),a=Xt("scales",e[2].dataType,e[2].dims.length),o=[r,s,a],u=4===e.length?Xt("zero_points",12,e[3].dims.length):void 0;u&&o.push(u);const d=x.length,l=Yt("output",e[0].dataType,d),h=Lt(e[0].dataType);return`\n        var<workgroup> sub_a: array<${r.type.value}, ${_}>;\n        var<workgroup> inter_results: array<array<${l.type.value}, ${m}>, ${f}>;\n        ${n.declareVariables(...o,l)}\n        ${n.mainStart([m,f,1])}\n          let output_indices = ${l.offsetToIndices(`workgroup_index * ${f}`)};\n          let col = output_indices[2];\n          let row = output_indices[1];\n          let batch = output_indices[0];\n          let n_blocks_per_col = uniforms.b_shape[1];\n          let num_tiles =  (n_blocks_per_col - 1) / ${w} + 1;\n\n          // Loop over shared dimension.\n          for (var tile: u32 = 0; tile < num_tiles; tile += 1) {\n            let a_col_start = tile * ${_};\n            // load one tile A data into shared memory.\n            for (var a_offset = local_idx; a_offset < ${_}; a_offset += 128)\n            {\n              let a_col = a_col_start + a_offset;\n              if (a_col < uniforms.a_shape[2])\n              {\n                sub_a[a_offset] = ${r.getByIndices(`${r.type.indices}(batch, row, a_col)`)};\n              } else {\n                sub_a[a_offset] = ${r.type.value}(0);\n              }\n            }\n            workgroupBarrier();\n\n            // each thread process one block\n            let b_row = col + local_id.y;\n            let block = tile * ${w} + local_id.x;\n            ${u?`\n            let zero_point_bytes_per_col = (n_blocks_per_col + 1) / 2;\n            let zero_point_byte_count = b_row * zero_point_bytes_per_col + (block >> 0x1u);\n            let zero_point_word_index = zero_point_byte_count >> 0x2u;\n            let zero_point_byte_offset = zero_point_byte_count & 0x3u;\n            let zero_point_nibble_offset: u32 = block & 0x1u;\n            let zero_point_bits_offset = (zero_point_byte_offset << 3) + (zero_point_nibble_offset << 2);\n            let zero_point_word = ${u.getByOffset("zero_point_word_index")} >> zero_point_bits_offset;\n            let zero_point = ${h}((zero_point_word) & 0xFu);`:`\n            // The default zero point is 8 for unsigned 4-bit quantization.\n            let zero_point = ${h}(8);`}\n            let scale = ${a.getByOffset("b_row * n_blocks_per_col + block")};\n            let b_data = ${s.getByIndices(`${s.type.indices}(b_row, block, 0)`)};\n            var word_offset = local_id.x * ${t.blockSize/p};\n            for (var i: u32 = 0; i < ${c}; i++) {\n              ${(()=>{switch(p){case 1:return`\n          let a_data0 = vec4<${h}>(sub_a[word_offset], sub_a[word_offset + 1], sub_a[word_offset + 2], sub_a[word_offset + 3]);\n          let a_data1 = vec4<${h}>(sub_a[word_offset + 4], sub_a[word_offset + 5], sub_a[word_offset + 6], sub_a[word_offset + 7]);`;case 2:return`\n          let a_data0 = vec4<${h}>(sub_a[word_offset], sub_a[word_offset + 1]);\n          let a_data1 = vec4<${h}>(sub_a[word_offset + 2], sub_a[word_offset + 3]);`;case 4:return"\n          let a_data0 = sub_a[word_offset];\n          let a_data1 = sub_a[word_offset + 1];";default:throw new Error(`${p}-component is not supported.`)}})()}\n              let b_value = ${1===c?"b_data":"b_data[i]"};\n              let b_value_lower = unpack4xU8(b_value & 0x0F0F0F0Fu);\n              let b_value_upper = unpack4xU8((b_value >> 4) & 0x0F0F0F0Fu);\n              let b_quantized_values = mat2x4<${h}>(${Array.from({length:4},(e,t)=>`${h}(b_value_lower[${t}]), ${h}(b_value_upper[${t}])`).join(", ")});\n              let b_dequantized_values = (b_quantized_values - mat2x4<${h}>(${Array(8).fill("zero_point").join(",")})) * scale;\n              inter_results[local_id.y][local_id.x] += ${Array.from({length:2},(e,t)=>`dot(a_data${t}, b_dequantized_values[${t}])`).join(" + ")};\n              word_offset += ${8/p};\n            }\n            workgroupBarrier();\n          }\n\n          if (local_idx < ${f}) {\n            var output_value: ${l.type.value} = ${l.type.value}(0);\n            for (var b = 0u; b < ${m}; b++) {\n              output_value += inter_results[local_idx][b];\n            }\n            if (col + local_idx < uniforms.output_shape[2])\n            {\n              ${l.setByIndices(`${l.type.indices}(batch, row, col + local_idx)`,"output_value")}\n            }\n          }\n        }`}}},go=(e,t)=>{ho(e.inputs,t),32===t.blockSize&&e.adapterInfo.isVendor("intel")&&e.adapterInfo.isArchitecture("gen-12lp")?e.compute(mo(e.inputs,t)):e.compute(fo(e.inputs,t))},_o=e=>qt(e)}}),nl=P({"web/lib/wasm/jsep/webgpu/ops/pad.ts"(){rd(),od(),fd(),wo=e=>{if(!e||e.length<1)throw new Error("Too few inputs");if(1!==e[0].dataType&&10!==e[0].dataType)throw new Error("Input type must be float or float16.");if(e.length>=2){let t=2*e[0].dims.length===e[1].dims[0];if(4===e.length&&(t=2*e[3].dims[0]===e[1].dims[0]),!t)throw new Error("The pads should be a 1D tensor of shape [2 * input_rank] or [2 * num_axes].")}},yo=(e,t,n)=>{let i="";for(let r=t-1;r>=0;--r)i+=`\n            k = i32(${e.indicesGet("indices",r)}) - ${Zt("uniforms.pads",r,n)};\n            if (k < 0) {\n              break;\n            }\n            if (k >= i32(${Zt("uniforms.x_shape",r,t)})) {\n              break;\n            }\n            offset += k * i32(${Zt("uniforms.x_strides",r,t)});\n        `;return`\n          value = ${e.type.value}(uniforms.constant_value);\n          for (var i = 0; i < 1; i++) {\n            var offset = 0;\n            var k = 0;\n            ${i}\n            value = x[offset];\n          }\n      `},$o=(e,t,n)=>{let i="";for(let r=t-1;r>=0;--r)i+=`\n                k = i32(${e.indicesGet("indices",r)}) - ${Zt("uniforms.pads",r,n)};\n                if (k < 0) {\n                  k = -k;\n                }\n                {\n                  let _2n_1 = 2 * (i32(${Zt("uniforms.x_shape",r,t)}) - 1);\n                  k = k % _2n_1;\n                  if(k >= i32(${Zt("uniforms.x_shape",r,t)})) {\n                    k = _2n_1 - k;\n                  }\n                }\n                offset += k * i32(${Zt("uniforms.x_strides",r,t)});\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${i}\n              value = x[offset];\n          `},bo=(e,t,n)=>{let i="";for(let r=t-1;r>=0;--r)i+=`\n                k = i32(${e.indicesGet("indices",r)}) - ${Zt("uniforms.pads",r,n)};\n                if (k < 0) {\n                  k = 0;\n                }\n                if (k >= i32(${Zt("uniforms.x_shape",r,t)})) {\n                  k = i32(${Zt("uniforms.x_shape",r,t)}) - 1;\n                }\n                offset += k * i32(${Zt("uniforms.x_strides",r,t)});\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${i}\n              value = x[offset];\n          `},vo=(e,t,n)=>{let i="";for(let r=t-1;r>=0;--r)i+=`\n                k = i32(${e.indicesGet("indices",r)}) - ${Zt("uniforms.pads",r,n)};\n                if (k < 0)  {\n                  k += i32(${Zt("uniforms.x_shape",r,t)}]);\n                }\n                if (k >= i32(${Zt("uniforms.x_shape",r,t)})) {\n                  k -= i32(${Zt("uniforms.x_shape",r,t)});\n                }\n                offset += k * i32(${Zt("uniforms.x_strides",r,t)});\n            `;return`\n              var offset = 0;\n              var k = 0;\n              ${i}\n              value = x[offset];\n          `},xo=(e,t,n)=>{switch(n.mode){case 0:return yo(e,t,n.pads.length);case 1:return $o(e,t,n.pads.length);case 2:return bo(e,t,n.pads.length);case 3:return vo(e,t,n.pads.length);default:throw new Error("Invalid mode")}},ko=(e,t)=>{const n=dt.padShape(e[0].dims.slice(),t.pads),i=e[0].dims,r=[{type:12,data:dt.size(n)},{type:6,data:t.pads}],s=e.length>=3&&e[2].data;return 0===t.mode&&r.push({type:s?e[2].dataType:1,data:t.value}),r.push(...Wt(e[0].dims,n)),{name:"Pad",shaderCache:{hint:`${t.mode}${s}`,inputDependencies:["rank"]},getRunData:()=>({outputs:[{dims:n,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(dt.size(n)/64)},programUniforms:r}),getShaderSource:r=>{const a=Yt("output",e[0].dataType,n.length),o=Xt("x",e[0].dataType,i.length),u=o.type.value,d=xo(a,i.length,t),l=[{name:"output_size",type:"u32"},{name:"pads",type:"i32",length:t.pads.length}];return 0===t.mode&&l.push({name:"constant_value",type:s?u:"f32"}),`\n            ${r.registerUniforms(l).declareVariables(o,a)}\n            ${r.mainStart()}\n            ${r.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n\n            let indices = ${a.offsetToIndices("global_idx")};\n\n            var value = ${u}(0);\n            ${d}\n            output[global_idx] = value;\n        }`}}},So=(e,t)=>{if(e.length>1){const n=e[1].getBigInt64Array(),i=e.length>=3&&e[2].data?10===e[2].dataType?e[2].getUint16Array()[0]:e[2].getFloat32Array()[0]:0,r=e[0].dims.length,s=new Int32Array(2*r).fill(0);if(e.length>=4){const t=e[3].getBigInt64Array();for(let e=0;e<t.length;e++)s[Number(t[e])]=Number(n[e]),s[Number(t[e])+r]=Number(n[e+t.length])}else n.forEach((e,t)=>s[Number(t)]=Number(e));const a=[];return s.forEach(e=>a.push(e)),{mode:t.mode,value:i,pads:a}}return t},Io=(e,t)=>{wo(e.inputs);const n=So(e.inputs,t);e.compute(ko(e.inputs,n),{inputs:[0]})}}}),il=P({"web/lib/wasm/jsep/webgpu/ops/pool.ts"(){le(),rd(),od(),fd(),To=e=>{if(u.webgpu.validateInputContent&&(!e||1!==e.length))throw new Error("Pool ops requires 1 input.")},zo=(e,t,n)=>{const i="NHWC"===t.format,r=e.dims.slice();i&&r.splice(1,0,r.pop());const s=Object.hasOwnProperty.call(t,"dilations"),a=t.kernelShape.slice(),o=t.strides.slice(),u=s?t.dilations.slice():[],d=t.pads.slice();lt.adjustPoolAttributes(n,r,a,o,u,d);const l=lt.computePoolOutputShape(n,r,o,u,a,d,t.autoPad),p=Object.assign({},t);s?Object.assign(p,{kernelShape:a,strides:o,pads:d,dilations:u,cacheKey:t.cacheKey}):Object.assign(p,{kernelShape:a,strides:o,pads:d,cacheKey:t.cacheKey});const c=l.slice();return c.push(c.splice(1,1)[0]),[p,i?c:l]},Eo=(e,t)=>{const n="NHWC"===t.format,i=[{type:12,data:dt.size(e)},{type:12,data:dt.size(t.kernelShape)}],r=[{name:"outputSize",type:"u32"},{name:"kernelSize",type:"u32"}];if(t.kernelShape.length<=2){const e=t.kernelShape[t.kernelShape.length-1],n=t.strides[t.strides.length-1],s=t.pads[t.pads.length/2-1],a=t.pads[t.pads.length-1],o=!!(s+a);i.push({type:12,data:e},{type:12,data:n},{type:12,data:s},{type:12,data:a}),r.push({name:"kw",type:"u32"},{name:"sw",type:"u32"},{name:"pwStart",type:"u32"},{name:"pwEnd",type:"u32"});let u=!1;if(2===t.kernelShape.length){const e=t.kernelShape[t.kernelShape.length-2],n=t.strides[t.strides.length-2],s=t.pads[t.pads.length/2-2],a=t.pads[t.pads.length-2];u=!!(s+a),i.push({type:12,data:e},{type:12,data:n},{type:12,data:s},{type:12,data:a}),r.push({name:"kh",type:"u32"},{name:"sh",type:"u32"},{name:"phStart",type:"u32"},{name:"phEnd",type:"u32"})}return[i,r,!0,o,u]}{if(n)throw new Error("Pooling with kernelShape.length > 2 is not supported for NHWC format.");const e=dt.computeStrides(t.kernelShape);return i.push({type:12,data:e},{type:12,data:t.pads},{type:12,data:t.strides}),r.push({name:"kernelStrides",type:"u32",length:e.length},{name:"pads",type:"u32",length:t.pads.length},{name:"strides",type:"u32",length:t.strides.length}),[i,r,!!t.pads.reduce((e,t)=>e+t),!1,!1]}},Co=(e,t,n,i,r,s,a,o,u,d,l,p)=>{const c="NHWC"===r.format,h=t.type.value,f=Yt("output",t.type.tensor,i);if(r.kernelShape.length<=2){let i="",d="",m="";const g=n-(c?2:1);if(i=l?`\n                for (var i: u32 = 0u; i < uniforms.kw; i++) {\n                  xIndices[${g}] = indices[${g}] * uniforms.sw - uniforms.pwStart + i;\n                  if (xIndices[${g}] < 0 || xIndices[${g}]\n                      >= uniforms.x_shape[${g}]) {\n                    pad++;\n                    continue;\n                  }\n                  let x_val = x[${t.indicesToOffset("xIndices")}];\n                  ${s}\n                }`:`\n                for (var i: u32 = 0u; i < uniforms.kw; i++) {\n                  xIndices[${g}] = indices[${g}] * uniforms.sw - uniforms.pwStart + i;\n                  let x_val = x[${t.indicesToOffset("xIndices")}];\n                  ${s}\n                }`,2===r.kernelShape.length){const e=n-(c?3:2);d=p?`\n                for (var j: u32 = 0u; j < uniforms.kh; j++) {\n                  xIndices[${e}] = indices[${e}] * uniforms.sh - uniforms.phStart + j;\n                  if (xIndices[${e}] < 0 || xIndices[${e}] >= uniforms.x_shape[${e}]) {\n                    pad += i32(uniforms.kw);\n                    continue;\n                  }\n              `:`\n                for (var j: u32 = 0u; j < uniforms.kh; j++) {\n                  xIndices[${e}] = indices[${e}] * uniforms.sh - uniforms.phStart + j;\n                `,m="\n              }\n            "}return`\n            ${e.registerUniforms(u).declareVariables(t,f)}\n\n            ${e.mainStart()}\n              ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}\n\n              let indices = ${f.offsetToIndices("global_idx")};\n              var xIndices = ${f.offsetToIndices("global_idx")};\n\n              var value = ${h}(${o});\n              var pad = 0;\n              ${d}\n              ${i}\n              ${m}\n              ${a}\n\n              output[global_idx] = value;\n            }`}{if(c)throw new Error("Pooling with kernelShape.length > 2 is not supported for NHWC format.");const i=r.kernelShape.length,l=r.pads.length;let p="";return p=d?`\n                if (xIndices[j] >= uniforms.x_shape[j]) {\n                  pad++;\n                  isPad = true;\n                  break;\n                }\n              }\n              if (!isPad) {\n                let x_val = x[${t.indicesToOffset("xIndices")}];\n                ${s}\n              }`:`\n              }\n              let x_val = x[${t.indicesToOffset("xIndices")}];\n              ${s}\n            `,`\n            ${e.registerUniforms(u).declareVariables(t,f)}\n\n            ${e.mainStart()}\n              ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}\n              let indices = ${f.offsetToIndices("global_idx")};\n              var xIndices = ${f.offsetToIndices("global_idx")};\n\n              var offsets: array<u32, ${i}>;\n\n              var value = ${h}(${o});\n              var pad = 0;\n              var isPad = false;\n\n              for (var i: u32 = 0u; i < uniforms.kernelSize; i++) {\n                var offset = i;\n                for (var j = 0u; j < ${i-1}u; j++) {\n                  offsets[j] = offset / ${Zt("uniforms.kernelStrides","j",i)};\n                  offset -= offsets[j] * ${Zt("uniforms.kernelStrides","j",i)};\n                }\n                offsets[${i-1}] = offset;\n\n                isPad = false;\n                for (var j = ${n-i}u; j < ${n}u; j++) {\n                  xIndices[j] = indices[j] * ${Zt("uniforms.strides",`j - ${n-i}u`,i)}\n                    + offsets[j - ${n-i}u] - ${Zt("uniforms.pads","j - 2u",l)};\n                  ${p}\n              }\n              ${a}\n\n              output[global_idx] = value;\n            }`}},Oo=e=>`${e.format};${e.ceilMode};${e.autoPad};${e.kernelShape.length}`,Ao=e=>`${Oo(e)};${e.countIncludePad}`,Bo=e=>`${Oo(e)};${e.storageOrder};${e.dilations}`,Ro=e=>({format:e.format,autoPad:["NOTSET","VALID","SAME_UPPER","SAME_LOWER"][e.auto_pad],ceilMode:e.ceil_mode,kernelShape:e.kernel_shape,strides:e.strides,pads:e.pads}),Do=(e,t,n,i)=>{const[r,s]=zo(t,i,n),a=Xt("x",t.dataType,t.dims.length),o=a.type.value;let u="";r.countIncludePad?u+=`value /= ${o}(uniforms.kernelSize);`:u+=`value /= ${o}(i32(uniforms.kernelSize) - pad);`;const[d,l,p,c,h]=Eo(s,r);return d.push(...Wt(t.dims,s)),{name:e,shaderCache:{hint:`${i.cacheKey};${p};${c};${h}`,inputDependencies:["rank"]},getRunData:()=>({outputs:[{dims:s,dataType:t.dataType}],dispatchGroup:{x:Math.ceil(dt.size(s)/64)},programUniforms:d}),getShaderSource:e=>Co(e,a,t.dims.length,s.length,r,"value += x_val;",u,0,l,p,c,h)}},Mo=e=>{const t=0!==e.count_include_pad,n=Ro(e);if(0!==n.ceilMode)throw new Error("using ceil() in shape computation is not yet supported for AveragePool");const i={countIncludePad:t,...n,cacheKey:""};return{...i,cacheKey:Ao(i)}},Uo=(e,t)=>{To(e.inputs),e.compute(Do("AveragePool",e.inputs[0],!1,t))},Po={autoPad:"",ceilMode:0,countIncludePad:!1,kernelShape:[],strides:[],pads:[],storageOrder:0,dilations:[]},qo=e=>{const t=e.format;return{format:t,...Po,cacheKey:t}},No=(e,t)=>{To(e.inputs),e.compute(Do("GlobalAveragePool",e.inputs[0],!0,t))},Vo=(e,t,n,i)=>{const[r,s]=zo(t,i,n),a=Xt("x",t.dataType,t.dims.length),[o,u,d,l,p]=Eo(s,r);return o.push(...Wt(t.dims,s)),{name:e,shaderCache:{hint:`${i.cacheKey};${d};${l};${p}`,inputDependencies:["rank"]},getRunData:()=>({outputs:[{dims:s,dataType:t.dataType}],dispatchGroup:{x:Math.ceil(dt.size(s)/64)},programUniforms:o}),getShaderSource:e=>Co(e,a,t.dims.length,s.length,r,"\n      value = max(x_val, value);\n    ","",10===t.dataType?-65504:-1e5,u,d,l,p)}},Lo=(e,t)=>{To(e.inputs),e.compute(Vo("MaxPool",e.inputs[0],!1,t))},Go=e=>{const t=e.storage_order,n=e.dilations,i=Ro(e);if(0!==t)throw new Error("column major storage order is not yet supported for MaxPool");if(0!==i.ceilMode)throw new Error("using ceil() in shape computation is not yet supported for MaxPool");const r={storageOrder:t,dilations:n,...i,cacheKey:""};return{...r,cacheKey:Bo(r)}},Wo=e=>{const t=e.format;return{format:t,...Po,cacheKey:t}},jo=(e,t)=>{To(e.inputs),e.compute(Vo("GlobalMaxPool",e.inputs[0],!0,t))}}}),rl=P({"web/lib/wasm/jsep/webgpu/ops/quantize-linear.ts"(){rd(),od(),hd(),fd(),Ho=(e,t)=>{if(e.length<2||e.length>3)throw new Error("DequantizeLinear requires 2 or 3 inputs.");if(3===e.length&&e[1].dims===e[2].dims)throw new Error("x-scale and x-zero-point must have the same shape.");if(3===e.length&&e[0].dataType!==e[2].dataType)throw new Error("x and x-zero-point must have the same data type.");if(6===e[0].dataType&&e.length>2)throw new Error("In the case of dequantizing int32 there is no zero point.");if(0!==e[1].dims.length&&1!==e[1].dims.length&&e[1].dims.length!==e[0].dims.length)throw new Error("scale input must be a scalar, a 1D tensor, or have the same rank as the input tensor.");if(e.length>2){if(e[0].dataType!==e[2].dataType)throw new Error("x and x-zero-point must have the same data type.");if(e[1].dims.length!==e[2].dims.length)throw new Error("scale and zero-point inputs must have the same rank.");if(!e[1].dims.map((t,n)=>t===e[2].dims[n]).reduce((e,t)=>e&&t,!0))throw new Error("scale and zero-point inputs must have the same shape.")}if(t.blockSize>0){if(0===e[1].dims.length||1===e[1].dims.length&&1===e[1].dims[0])throw new Error("blockSize must be set only for block quantization.");if(!e[1].dims.map((n,i)=>i===t.axis||n===e[0].dims[i]).reduce((e,t)=>e&&t,!0))throw new Error("For block qunatization, scale input shape to match the input shape except for the axis");if(e[1].dims.length!==e[0].dims.length)throw new Error("For block qunatization the scale input rank must be the same as the x rank.");const n=e[0].dims[t.axis],i=e[1].dims[t.axis];if(t.blockSize<Math.ceil(n/i)||t.blockSize>Math.ceil(n/(i-1)-1))throw new Error("blockSize must be with in the range [ceil(dI / Si), ceil(dI / (Si - 1) - 1)].")}},Fo=(e,t)=>{const n=dt.normalizeAxis(t.axis,e[0].dims.length),i=e[0].dataType,r=3===i,s=e[0].dims,a=e[1].dataType,o=dt.size(s),u=3===i||2===i,d=u?[Math.ceil(dt.size(e[0].dims)/4)]:e[0].dims,l=e[1].dims,p=e.length>2?e[2]:void 0,c=p?u?[Math.ceil(dt.size(p.dims)/4)]:p.dims:void 0,h=0===l.length||1===l.length&&1===l[0],f=!1===h&&1===l.length,m=jt(o),g=h&&(!u||4===m),_=g?m:1,w=g&&!u?m:1,y=Xt("input",u?12:i,d.length,w),$=Xt("scale",a,l.length),b=p?Xt("zero_point",u?12:i,c.length):void 0,v=Yt("output",a,s.length,_),x=[y,$];b&&x.push(b);const k=[d,l];p&&k.push(c);const S=[{type:12,data:o/_},{type:12,data:n},{type:12,data:t.blockSize},...Wt(...k,s)];return{name:"DequantizeLinear",shaderCache:{hint:t.cacheKey,inputDependencies:b?["rank","rank","rank"]:["rank","rank"]},getShaderSource:e=>`\n      ${e.registerUniforms([{name:"output_size",type:"u32"},{name:"axis",type:"u32"},{name:"block_size",type:"u32"}]).declareVariables(...x,v)}\n      ${e.mainStart()}\n          ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n          let output_indices = ${v.offsetToIndices("global_idx")};\n\n          // Set input x\n          ${u?`\n            let input = ${y.getByOffset("global_idx / 4")};\n            let x_vec = ${r?"unpack4xI8(input)":"unpack4xU8(input)"};\n            let x_value = ${1===_?"x_vec[global_idx % 4]":"x_vec"};`:`let x_value = ${y.getByOffset("global_idx")};`};\n\n          // Set scale input\n          ${h?`let scale_value= ${$.getByOffset("0")}`:f?`\n            let scale_index = ${v.indicesGet("output_indices","uniforms.axis")};\n            let scale_value= ${$.getByOffset("scale_index")};`:`\n            var scale_indices: ${$.type.indices} = output_indices;\n            let index = ${$.indicesGet("scale_indices","uniforms.axis")} / uniforms.block_size;\n            ${$.indicesSet("scale_indices","uniforms.axis","index")};\n            let scale_value= ${$.getByIndices("scale_indices")};`};\n\n          // Set zero-point input\n          ${b?h?u?`\n                let zero_point_input = ${b.getByOffset("0")};\n                let zero_point_vec =  ${r?"unpack4xI8(zero_point_input)":"unpack4xU8(zero_point_input)"};\n                let zero_point_value= zero_point_vec[0]`:`let zero_point_value = ${b.getByOffset("0")}`:f?u?`\n                let zero_point_index = ${v.indicesGet("output_indices","uniforms.axis")};\n                let zero_point_input = ${b.getByOffset("zero_point_index / 4")};\n                let zero_point_vec =  ${r?"unpack4xI8(zero_point_input)":"unpack4xU8(zero_point_input)"};\n                let zero_point_value = zero_point_vec[zero_point_index % 4]`:`\n                let zero_point_index = ${v.indicesGet("output_indices","uniforms.axis")};\n                let zero_point_value = ${b.getByOffset("zero_point_index")};`:u?`\n                let zero_point_offset = ${$.indicesToOffset("scale_indices")};\n                let zero_point_input = ${b.getByOffset("zero_point_offset / 4")};\n                let zero_point_vec = ${r?"unpack4xI8(zero_point_input)":"unpack4xU8(zero_point_input)"};\n                let zero_point_value = zero_point_vec[zero_point_offset % 4];`:`let zero_point_value = ${b.getByIndices("scale_indices")};`:`let zero_point_value = ${u?r?"i32":"u32":y.type.value}(0);`};\n      // Compute and write output\n      ${v.setByOffset("global_idx",`${v.type.value}(x_value - zero_point_value) * scale_value`)};\n      }`,getRunData:()=>({outputs:[{dims:s,dataType:a}],dispatchGroup:{x:Math.ceil(o/_/64),y:1,z:1},programUniforms:S})}},Ko=(e,t)=>{Ho(e.inputs,t),e.compute(Fo(e.inputs,t))},Zo=e=>qt({axis:e.axis,blockSize:e.blockSize})}}),sl=P({"web/lib/wasm/jsep/webgpu/ops/range.ts"(){le(),rd(),fd(),Qo=(e,t,n)=>{if(e===t||e<t&&n<0||e>t&&n>0)throw new Error("Range these inputs' contents are invalid.")},Xo=(e,t,n,i)=>{const r=Math.abs(Math.ceil((t-e)/n)),s=[r],a=r,o=[{type:12,data:a},{type:i,data:e},{type:i,data:n},...Wt(s)];return{name:"Range",shaderCache:{hint:`${i}`},getShaderSource:e=>{const t=Yt("output",i,s.length),n=t.type.value,r=[{name:"outputSize",type:"u32"},{name:"start",type:n},{name:"delta",type:n}];return`\n        ${e.registerUniforms(r).declareVariables(t)}\n        ${e.mainStart()}\n        ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}\n        output[global_idx] = uniforms.start + ${n}(global_idx) * uniforms.delta;\n      }`},getRunData:()=>({outputs:[{dims:s,dataType:i}],dispatchGroup:{x:Math.ceil(a/64)},programUniforms:o})}},Yo=e=>{let t=0,n=0,i=0;6===e.inputs[0].dataType?(t=e.inputs[0].getInt32Array()[0],n=e.inputs[1].getInt32Array()[0],i=e.inputs[2].getInt32Array()[0]):1===e.inputs[0].dataType&&(t=e.inputs[0].getFloat32Array()[0],n=e.inputs[1].getFloat32Array()[0],i=e.inputs[2].getFloat32Array()[0]),u.webgpu.validateInputContent&&Qo(t,n,i),e.compute(Xo(t,n,i,e.inputs[0].dataType),{inputs:[]})}}}),al=P({"web/lib/wasm/jsep/webgpu/ops/scatter-nd.ts"(){rd(),od(),hd(),fd(),Jo=(e,t,n,i)=>{if("none"!==e&&"i32"!==i&&"u32"!==i&&"f32"!==i)throw new Error(`Input ${i} is not supported with reduction ${e}.`);const r="{\n                var oldValue = 0;\n                loop {\n                  let newValueF32 =",s=`;\n                  let newValue = bitcast<i32>(newValueF32);\n                  let res = atomicCompareExchangeWeak(&${t}, oldValue, newValue);\n                  if res.exchanged {\n                    break;\n                  }\n                  oldValue = res.old_value;\n                }\n              }`;switch(e){case"none":return`${t}=${n};`;case"add":return"i32"===i||"u32"===i?`atomicAdd(&${t}, bitcast<${i}>(${n}));`:`\n              ${r}bitcast<${i}>(oldValue) + (${n})${s}`;case"max":return"i32"===i||"u32"===i?`atomicMax(&${t}, bitcast<${i}>(${n}));`:`\n                ${r}max(bitcast<f32>(oldValue), (${n}))${s}`;case"min":return"i32"===i||"u32"===i?`atomicMin(&${t}, bitcast<${i}>(${n}));`:`${r}min(bitcast<${i}>(oldValue), (${n}))${s}`;case"mul":return`${r}(bitcast<${i}>(oldValue) * (${n}))${s}`;default:throw new Error(`Reduction ${e} is not supported.`)}},eu=(e,t)=>{const n=e[0].dims,i=e[1].dims,r=n,s=Math.ceil(dt.sizeToDimension(i,i.length-1)/1),a=i[i.length-1],o=dt.sizeFromDimension(n,a),u=[{type:12,data:s},{type:12,data:a},{type:12,data:o},...Wt(e[1].dims,e[2].dims,r)];return{name:"ScatterND",shaderCache:{hint:`${t.cacheKey}_${t.reduction}`,inputDependencies:["rank","rank"]},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(s/64)},programUniforms:u}),getShaderSource:n=>{const i=Xt("indices",e[1].dataType,e[1].dims.length),s=Xt("updates",e[2].dataType,e[2].dims.length,1),a="none"!==t.reduction&&""!==t.reduction?Jt("output",e[0].dataType,r.length):Yt("output",e[0].dataType,r.length,1);return`\n      ${n.registerUniform("output_size","u32").registerUniform("last_index_dimension","u32").registerUniform("num_updates_elements","u32").declareVariables(i,s,a)}\n      ${n.mainStart()}\n        ${n.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n  var data_offset = 0u;\n  let indices_start = uniforms.last_index_dimension * global_idx;\n  let indices_end = indices_start + uniforms.last_index_dimension;\n  for (var i = indices_start; i < indices_end; i++) {\n    var index = i32(indices[i].x);\n    ${1===e[0].dims.length?"\n    let element_count_dim = uniforms.output_strides;\n    let dim_value = uniforms.output_shape;":"\n    let element_count_dim = uniforms.output_strides[i - indices_start];\n    let dim_value = uniforms.output_shape[i - indices_start];"}\n    if (index >= 0) {\n      if (index >= i32(dim_value)) {\n        index = i32(dim_value - 1);\n      }\n    } else {\n      if (index < -i32(dim_value)) {\n        index = 0;\n      } else {\n        index += i32(dim_value);\n      }\n    }\n    data_offset += u32((u32(index) * element_count_dim));\n  }\n\n  for (var i = 0u; i < uniforms.num_updates_elements; i++) {\n    let value = updates[uniforms.num_updates_elements * global_idx + i];\n    ${Jo(t.reduction,"output[data_offset + i]","value",a.type.value)}\n  }\n\n      }`}}},tu=e=>qt({reduction:e.reduction}),nu=(e,t)=>{e.compute(eu(e.inputs,t),{inputs:[e.inputs[1],e.inputs[2]],outputs:[]})}}}),ol=P({"web/lib/wasm/jsep/webgpu/ops/resize.ts"(){rd(),od(),hd(),fd(),iu=(e,t)=>{if(e.every(e=>e>0||(()=>{throw new Error("Resize requires scales input values to be positive")})),e.length>0)if("linear"===t.mode){if(!(2===e.length||3===e.length||4===e.length&&1===e[0]&&1===e[1]||4===e.length&&1===e[0]&&1===e[3]||5===e.length&&1===e[0]&&1===e[1]))throw new Error("For linear mode, Resize requires scales to be 2D, 3D, 4D with either two outermost or one innermost and\n            one outermost scale values equal to 1, or 5D with two outermost scale values equal to 1")}else if("cubic"===t.mode&&!(2===e.length||4===e.length&&1===e[0]&&1===e[1]||4===e.length&&1===e[0]&&1===e[3]))throw new Error("Resize requires scales input size to be 2 or 4 for cubic mode")},ru=(e,t,n)=>{t.every(e=>e>=0&&e<n||(()=>{throw new Error("Resize requires axes input values to be positive and less than rank")}));const i=new Array(n).fill(1);return t.forEach((t,n)=>i[t]=e[n]),i},su=(e,t,n,i,r,s)=>{const[a,o,u]=n>10?[1,2,3]:[-1,e.length>1?1:-1,-1],d=e[0].dims.length;if(a>0&&e.length>a&&e[a].dims.length>0)e[a].getFloat32Array().forEach(e=>s.push(e));else if("tf_crop_and_resize"===t.coordinateTransformMode)throw new Error("Resize requires RoI input to be specified when coordinateTransformMode is tfCropAndResize");if(o>0&&e.length>o&&1===e[o].dims.length&&e[o].dims[0]>0){if(e[o].getFloat32Array().forEach(e=>i.push(e)),0!==i.length&&i.length!==d&&n>=18&&i.length!==t.axes.length)throw new Error("Resize requires scales input size to be same as input rank or axes size for opset 18 and up");iu(i,t),t.axes.length>0&&ru(i,t.axes,d).forEach((e,t)=>i[t]=e)}if(u>0&&e.length>u&&1===e[u].dims.length&&e[u].dims[0]>0&&(e[u].getBigInt64Array().forEach(e=>r.push(Number(e))),0!==r.length&&r.length!==d&&n>=18&&r.length!==t.axes.length))throw new Error("Resize requires sizes input size to be same as input rank or axes size for opset 18 and up");if(t.axes.length>0){if(0!==i.length&&i.length!==t.axes.length)throw new Error('Resize requires "scales" input size to be of axes rank when axes attributes is specified');if(0!==r.length&&r.length!==t.axes.length)throw new Error('Resize requires "sizes" input size to be of rank axes rank when axes attributes is specified')}if(void 0!==i&&void 0!==r&&i.length>0&&r.length>d)throw new Error("Resize requires only of scales or sizes to be specified")},au=(e,t,n,i)=>`\n  // The whole part and the fractional part are calculated separately due to inaccuracy of floating\n  // point division. As an example, f32(21) / f32(7) may evaluate to 2.99... instead of 3, causing an\n  // offset-by-one error later in floor().\n  let big = (${e}) * (${t});\n  let whole = ${i}(big / (${n}));\n  let fract = ${i}(big % (${n})) / ${i}(${n});\n  return whole + fract;\n`,ou=(e,t)=>`fn getOriginalCoordinateFromResizedCoordinate(xResized: u32, xScale: f32, lengthResized: u32,\n     lengthOriginal: u32, roiStart: f32, roiEnd: f32) -> ${t} { `+(()=>{switch(e){case"asymmetric":return`\n          if (xScale < 1.0 || floor(xScale) != xScale) {\n            return ${t}(xResized) / ${t}(xScale);\n          } else {\n            ${au("xResized","lengthOriginal","lengthResized",t)}\n          }\n        `;case"pytorch_half_pixel":return`if (lengthResized > 1) {\n                    return (${t}(xResized) + 0.5) / ${t}(xScale) - 0.5;\n                  } else {\n                    return 0.0;\n                  }`;case"tf_half_pixel_for_nn":return`return (${t}(xResized) + 0.5) / ${t}(xScale);`;case"align_corners":return`if (lengthResized == 1) {\n                    return 0.0;\n                  } else {\n                    ${au("xResized","lengthOriginal - 1","lengthResized - 1",t)}\n                  }`;case"tf_crop_and_resize":return`if (lengthResized > 1) {\n                    return ${t}(roiStart) * ${t}(lengthOriginal - 1) +\n                        (${t}(xResized) * ${t}(roiEnd - roiStart) * ${t}(lengthOriginal - 1)) /\n                        ${t}(lengthResized - 1);\n                  } else {\n                    return 0.5 * ${t}(roiStart + roiEnd) * ${t}(lengthOriginal - 1);\n                  }`;case"half_pixel_symmetric":return`const outputWidth = ${t}xScale * ${t}(lengthResized);\n                  const adjustment = ${t}(lengthResized) / outputWidth;\n                  const center = ${t}(lengthOriginal) / 2;\n                  const offset = center * (1 - adjustment);\n                  return offset + ((${t}(xResized) + 0.5) / ${t}(xScale)) - 0.5;`;case"half_pixel":return`return ((${t}(xResized) + 0.5) / ${t}(xScale)) - 0.5;`;default:throw new Error(`Coordinate transform mode ${e} is not supported`)}})()+"}",uu=(e,t,n)=>`fn getNearestPixelFromOriginal(xOriginal: ${n}, isDownSample: bool) -> ${n} {`+(()=>{switch(e){case"round_prefer_ceil":return"if (fract(xOriginal) == 0.5) {             return ceil(xOriginal);           } else {             return round(xOriginal);           }";case"floor":return"return floor(xOriginal);";case"ceil":return"return ceil(xOriginal);";case"round_prefer_floor":return"if (fract(xOriginal) == 0.5) {                     return floor(xOriginal);                   } else {                     return round(xOriginal);                   }";default:if(t<11)return"if (isDownSample)                     {                       return ceil(xOriginal);                     } else {                       return xOriginal;                     }";throw new Error(`Nearest mode ${e} is not supported`)}})()+"}",du=(e,t,n)=>{const i=new Array(n).fill(0).concat(new Array(n).fill(1)),r=0===e.length?i:e.slice();return t.length>0?(t.forEach((e,s)=>{i[e]=r[s],i[s+n]=r[t.length+s]}),i):r},lu=(e,t,n,i)=>{let r=[];if(n.length>0)if(i.length>0){if(e.forEach(e=>r.push(e)),Math.max(...i)>e.length)throw new Error("axes is out of bound");i.forEach((e,t)=>r[e]=n[t])}else n.forEach(e=>r.push(e));else{if(0===t.length)throw new Error("Resize requires either scales or sizes.");r=e.map((e,n)=>Math.round(e*t[n]))}return r},pu=(e,t,n)=>{const i=(()=>{switch(n.keepAspectRatioPolicy){case"not_larger":return n.axes.length>0?Math.min(...n.axes.map(e=>t[e]),Number.MAX_VALUE):Math.min(...t,Number.MAX_VALUE);case"not_smaller":return n.axes.length>0?Math.max(...n.axes.map(e=>t[e]),Number.MIN_VALUE):Math.max(...t,Number.MIN_VALUE);default:throw new Error(`Keep aspect ratio policy ${n.keepAspectRatioPolicy} is not supported`)}})();t.fill(1,0,t.length);const r=e.slice();return n.axes.length>0?(n.axes.forEach(e=>t[e]=i),n.axes.forEach(n=>r[n]=Math.round(e[n]*t[n]))):(t.fill(i,0,t.length),r.forEach((e,n)=>r[n]=Math.round(e*t[n]))),r},cu=(e,t,n,i,r)=>`\n    fn calculateOriginalIndicesFromOutputIndices(output_indices: ${e.type.indices}) -> array<${e.type.value}, ${n.length}> {\n      var original_indices: array<${e.type.value}, ${n.length}>;\n      for (var i:u32 = 0; i < ${n.length}; i++) {\n        var output_index = ${e.indicesGet("output_indices","i")};\n        var scale = ${Zt("uniforms.scales","i",i)};\n        var roi_low = ${Zt("uniforms.roi","i",r)};\n        var roi_hi = ${Zt("uniforms.roi",`i + ${t.length}`,r)};\n        if (scale == 1.0) {\n          original_indices[i] = ${e.type.value}(output_index);\n        } else {\n          var input_shape_i = ${Zt("uniforms.input_shape","i",t.length)};\n          var output_shape_i = ${Zt("uniforms.output_shape","i",n.length)};\n          original_indices[i] = getOriginalCoordinateFromResizedCoordinate(output_index, scale, output_shape_i,\n                                                                           input_shape_i, roi_low, roi_hi);\n        }\n      }\n      return original_indices;\n    }`,hu=(e,t,n,i,r,s,a)=>`\n    fn calculateInputIndicesFromOutputIndices(output_indices: ${t.type.indices}) -> ${e.type.indices} {\n      var input_indices: ${e.type.indices};\n      for (var i:u32 = 0; i < ${i.length}; i++) {\n        var output_index = ${t.indicesGet("output_indices","i")};\n        var input_index: u32;\n        var scale = ${Zt("uniforms.scales","i",r)};\n        if (scale == 1.0) {\n          input_index = output_index;\n        } else {\n          var roi_low = ${Zt("uniforms.roi","i",s)};\n          var roi_hi = ${Zt("uniforms.roi",`i + ${n.length}`,s)};\n          var input_shape_i = ${Zt("uniforms.input_shape","i",n.length)};\n          var output_shape_i = ${Zt("uniforms.output_shape","i",i.length)};\n          var original_idx = getOriginalCoordinateFromResizedCoordinate(output_index, scale, output_shape_i,\n                                                                        input_shape_i, roi_low, roi_hi);\n          if (!${a} || (original_idx >= 0 && original_idx < ${t.type.value}(input_shape_i))) {\n            if (original_idx < 0) {\n              input_index = 0;\n            } else if (original_idx > ${t.type.value}(input_shape_i - 1)) {\n              input_index = input_shape_i - 1;\n            } else {\n              input_index = u32(getNearestPixelFromOriginal(original_idx, scale < 1));\n            }\n          } else {\n            input_index = u32(original_idx);\n          }\n        }\n        ${e.indicesSet("input_indices","i","input_index")}\n      }\n      return input_indices;\n    }`,fu=(e,t)=>`\n    fn checkInputIndices(input_indices: ${e.type.indices}) -> bool {\n      for (var i:u32 = 0; i < ${t.length}; i++) {\n        var input_index = ${e.indicesGet("input_indices","i")};\n        if (input_index < 0 || input_index >= ${Zt("uniforms.input_shape","i",t.length)}) {\n          return false;\n        }\n      }\n      return true;\n    }`,mu=(e,t,n,i)=>e.rank>i?`\n    ${e.indicesSet("input_indices",t,"channel")};\n    ${e.indicesSet("input_indices",n,"batch")};\n`:"",gu=(e,t,n,i,r)=>{const[s,a,o,u]=2===n.length?[-1,0,1,-1]:[0,2,3,1],d=e.type.value;return`\n    fn getInputValue(batch: u32, channel: u32, row: u32, col: u32) -> ${d} {\n      var input_indices: ${e.type.indices};\n      ${e.indicesSet("input_indices",a,`max(0, min(row, ${n[a]} - 1))`)};\n      ${e.indicesSet("input_indices",o,`max(0, min(col, ${n[o]} - 1))`)};\n      ${mu(e,u,s,2)}\n      return ${e.getByIndices("input_indices")};\n    }\n\n    fn bilinearInterpolation(output_indices: ${t.type.indices}) -> ${d} {\n      var originalIndices = calculateOriginalIndicesFromOutputIndices(output_indices);\n      var row:${d} = originalIndices[${a}];\n      var col:${d} = originalIndices[${o}];\n      ${i?`if (row < 0 || row > (${n[a]} - 1) || col < 0 || col > (${n[o]} - 1)) {\n        return ${r};\n      }`:""};\n      row = max(0, min(row, ${n[a]} - 1));\n      col = max(0, min(col, ${n[o]} - 1));\n      var row1: u32 = u32(row);\n      var col1: u32 = u32(col);\n      var row2: u32 = u32(row + 1);\n      var col2: u32 = u32(col + 1);\n      var channel: u32 = ${n.length>2?`u32(originalIndices[${u}])`:"0"};\n      var batch: u32 =  ${n.length>2?`u32(originalIndices[${s}])`:"0"};\n      var x11: ${d} = getInputValue(batch, channel, row1, col1);\n      var x12: ${d} = getInputValue(batch, channel, row1, col2);\n      var x21: ${d} = getInputValue(batch, channel, row2, col1);\n      var x22: ${d} = getInputValue(batch, channel, row2, col2);\n      var dx1: ${d} = abs(row - ${d}(row1));\n      var dx2: ${d} = abs(${d}(row2) - row);\n      var dy1: ${d} = abs(col - ${d}(col1));\n      var dy2: ${d} = abs(${d}(col2) - col);\n      if (row1 == row2) {\n        dx1 = 0.5;\n        dx2 = 0.5;\n      }\n      if (col1 == col2) {\n        dy1 = 0.5;\n        dy2 = 0.5;\n      }\n      return (x11 * dx2 * dy2 + x12 * dx2 * dy1 + x21 * dx1 * dy2 + x22 * dx1 * dy1);\n    }`},_u=(e,t,n,i,r,s,a,o,u,d)=>{const l=2===n.length,[p,c]=l?[0,1]:[2,3],h=e.type.value,f=a=>{const l=a===p?"row":"col";return`\n      fn ${l}CubicInterpolation(input_indices: ${e.type.indices}, output_indices: ${t.type.indices}) -> ${h} {\n        var output_index = ${t.indicesGet("output_indices",a)};\n        var originalIdx: ${h} = getOriginalCoordinateFromResizedCoordinate(output_index, ${r[a]},\n        ${i[a]}, ${n[a]}, ${s[a]}, ${s[a]} + ${n.length});\n        var fractOriginalIdx: ${h} = originalIdx - floor(originalIdx);\n        var coefs = getCubicInterpolationCoefs(fractOriginalIdx);\n\n        if (${o} && (originalIdx < 0 || originalIdx > (${n[a]} - 1))) {\n          return ${u};\n        }\n        var data: array<${h}, 4> = array<${h}, 4>(0.0, 0.0, 0.0, 0.0);\n        for (var i: i32 = -1; i < 3; i++) {\n          var ${l}: ${h} = originalIdx + ${h}(i);\n          if (${l} < 0 || ${l} >= ${n[a]}) {\n            ${d?"coefs[i + 1] = 0.0;\n                        continue;":o?`return ${u};`:`${l} = max(0, min(${l}, ${n[a]} - 1));`};\n          }\n        var input_indices_copy: ${e.type.indices} = input_indices;\n          ${e.indicesSet("input_indices_copy",a,`u32(${l})`)};\n          data[i + 1] = ${a===p?e.getByIndices("input_indices_copy"):"rowCubicInterpolation(input_indices_copy, output_indices)"};\n        }\n        return cubicInterpolation1D(data, coefs);\n      }`};return`\n    ${f(p)};\n    ${f(c)};\n  fn getCubicInterpolationCoefs(s: ${h}) -> array<${h}, 4> {\n    var absS = abs(s);\n    var coeffs: array<${h}, 4> = array<${h}, 4>(0.0, 0.0, 0.0, 0.0);\n    var oneMinusAbsS: ${h} = 1.0 - absS;\n    var twoMinusAbsS: ${h} = 2.0 - absS;\n    var onePlusAbsS: ${h} = 1.0 + absS;\n    coeffs[0] = ((${a} * onePlusAbsS - 5 * ${a}) * onePlusAbsS + 8 * ${a}) * onePlusAbsS - 4 * ${a};\n    coeffs[1] = ((${a} + 2) * absS - (${a} + 3)) * absS * absS + 1;\n    coeffs[2] = ((${a} + 2) * oneMinusAbsS - (${a} + 3)) * oneMinusAbsS * oneMinusAbsS + 1;\n    coeffs[3] = ((${a} * twoMinusAbsS - 5 * ${a}) * twoMinusAbsS + 8 * ${a}) * twoMinusAbsS - 4 * ${a};\n    return coeffs;\n  }\n\n  fn cubicInterpolation1D(x: array<${h}, 4>, coefs: array<${h}, 4>) -> ${h} {\n    var coefsSum: ${h} = coefs[0] + coefs[1] + coefs[2] + coefs[3];\n    return (x[0] * coefs[0] + x[1] * coefs[1]+ x[2] * coefs[2]+ x[3] * coefs[3]) / coefsSum;\n  }\n\n  fn bicubicInterpolation(output_indices: ${t.type.indices}) -> ${h} {\n    var input_indices: ${e.type.indices} = output_indices;\n    return colCubicInterpolation(input_indices, output_indices);\n  }\n    `},wu=(e,t,n,i,r)=>{const[s,a,o,u,d]=3===n.length?[-1,0,1,2,-1]:[0,2,3,4,1],l=e.type.value;return`\n    fn getInputValue(batch: u32, channel: u32, depth:u32, height: u32, width: u32) -> ${l} {\n      var input_indices: ${e.type.indices};\n      ${e.indicesSet("input_indices",a,`max(0, min(depth, ${n[a]} - 1))`)};\n      ${e.indicesSet("input_indices",o,`max(0, min(height, ${n[o]} - 1))`)};\n      ${e.indicesSet("input_indices",u,`max(0, min(width, ${n[u]} - 1))`)};\n      ${mu(e,d,s,3)}\n      return ${e.getByIndices("input_indices")};\n    }\n\n    fn trilinearInterpolation(output_indices: ${t.type.indices}) -> ${l} {\n      var originalIndices = calculateOriginalIndicesFromOutputIndices(output_indices);\n      var depth:${l} = originalIndices[${a}];\n      var height:${l} = originalIndices[${o}];\n      var width:${l} = originalIndices[${u}];\n      ${i?`if (depth < 0 || depth > (${n[a]} - 1) || height < 0 || height > (${n[o]} - 1) || width < 0 || (width > ${n[u]} - 1)) {\n      return ${r};\n        }`:""};\n\n    depth = max(0, min(depth, ${n[a]} - 1));\n      height = max(0, min(height, ${n[o]} - 1));\n      width = max(0, min(width, ${n[u]} - 1));\n      var depth1: u32 = u32(depth);\n      var height1: u32 = u32(height);\n      var width1: u32 = u32(width);\n      var depth2: u32 = u32(depth + 1);\n      var height2: u32 = u32(height + 1);\n      var width2: u32 = u32(width + 1);\n      var channel: u32 = ${n.length>3?`u32(originalIndices[${d}])`:"0"};\n      var batch: u32 =  ${n.length>3?`u32(originalIndices[${s}])`:"0"};\n\n      var x111: ${l} = getInputValue(batch, channel, depth1, height1, width1);\n      var x112: ${l} = getInputValue(batch, channel, depth1, height1, width2);\n      var x121: ${l} = getInputValue(batch, channel, depth1, height2, width1);\n      var x122: ${l} = getInputValue(batch, channel, depth1, height2, width2);\n      var x211: ${l} = getInputValue(batch, channel, depth2, height1, width1);\n      var x212: ${l} = getInputValue(batch, channel, depth2, height1, width2);\n      var x221: ${l} = getInputValue(batch, channel, depth2, height2, width1);\n      var x222: ${l} = getInputValue(batch, channel, depth2, height2, width2);\n      var dx1: ${l} = abs(depth - ${l}(depth1));\n      var dx2: ${l} = abs(${l}(depth2) - depth);\n      var dy1: ${l} = abs(height - ${l}(height1));\n      var dy2: ${l} = abs(${l}(height2) - height);\n      var dz1: ${l} = abs(width - ${l}(width1));\n      var dz2: ${l} = abs(${l}(width2) - width);\n      if (depth1 == depth2) {\n        dx1 = 0.5;\n        dx2 = 0.5;\n      }\n      if (height1 == height2) {\n        dy1 = 0.5;\n        dy2 = 0.5;\n      }\n      if (width1 == width2) {\n        dz1 = 0.5;\n        dz2 = 0.5;\n      }\n      return (x111 * dx2 * dy2 * dz2 + x112 * dx2 * dy2 * dz1 + x121 * dx2 * dy1 *dz2 + x122 * dx2 * dy1 * dz1 +\n              x211 * dx1 * dy2 * dz2 + x212 * dx1 * dy2 * dz1 + x221 * dx1 * dy1 *dz2 + x222 * dx1 * dy1 * dz1);\n    }`},yu=(e,t,n,i,r,s)=>{const a=e.dims,o=du(s,t.axes,a.length);let u=lu(a,i,r,t.axes),d=i.slice();0===i.length&&(d=a.map((e,t)=>0===e?1:u[t]/e),"stretch"!==t.keepAspectRatioPolicy&&(u=pu(a,d,t)));const l=Yt("output",e.dataType,u.length),p=Xt("input",e.dataType,a.length),c=dt.size(u),h=a.length===u.length&&a.every((e,t)=>e===u[t]),f="tf_crop_and_resize"===t.coordinateTransformMode,m=t.extrapolationValue,g=p.type.value;return{name:"Resize",shaderCache:{hint:`${t.cacheKey}|${n}|${d.length>0?"cubic"===t.mode?d:d.length:""}|${r.length>0?r:""}|${o.length>0?o:""}|${h}|${"nearest"===t.mode?a.length:a}`,inputDependencies:["rank"]},getShaderSource:e=>`\n      ${h?"":`\n      ${ou(t.coordinateTransformMode,g)};\n      ${(()=>{switch(t.mode){case"nearest":return`\n              ${fu(p,a)};\n              ${uu(t.nearestMode,n,g)};\n              ${hu(p,l,a,u,d.length,o.length,f)};\n              `;case"linear":return`\n              ${cu(l,a,u,d.length,o.length)};\n              ${(()=>{if(2===a.length||4===a.length)return`${gu(p,l,a,f,m)}`;if(3===a.length||5===a.length)return`${wu(p,l,a,f,m)}`;throw Error("Linear mode only supports input dims 2, 3, 4 and 5 are supported in linear mode.")})()};\n            `;case"cubic":return`\n            ${(()=>{if(2===a.length||4===a.length)return`${_u(p,l,a,u,d,o,t.cubicCoeffA,f,t.extrapolationValue,t.excludeOutside)}`;throw Error("Cubic mode only supports input dims 2 and 4 are supported in linear mode.")})()};\n            `;default:throw Error("Invalid resize mode")}})()};\n      `}\n      ${e.registerUniform("output_size","u32").registerUniform("scales","f32",d.length).registerUniform("roi","f32",o.length).declareVariables(p,l)}\n      ${e.mainStart()}\n        ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n        ${h?"output[global_idx] = input[global_idx];":`\n        let output_indices = ${l.offsetToIndices("global_idx")};\n        var input_indices: ${p.type.indices};\n        ${(()=>{switch(t.mode){case"nearest":return`input_indices = calculateInputIndicesFromOutputIndices(output_indices);\n                if (checkInputIndices(input_indices)) {\n                  output[global_idx] = ${p.getByIndices("input_indices")};\n                } else {\n                  output[global_idx] = ${t.extrapolationValue};\n                }`;case"linear":return`output[global_idx] = ${2===a.length||4===a.length?"bilinearInterpolation":"trilinearInterpolation"}(output_indices);`;case"cubic":return"output[global_idx] = bicubicInterpolation(output_indices);";default:throw Error(`Unsupported resize mode: ${t.mode}`)}})()};\n`}\n      }`,getRunData:()=>({outputs:[{dims:u,dataType:e.dataType}],dispatchGroup:{x:Math.ceil(c/64)},programUniforms:[{type:12,data:c},{type:1,data:d},{type:1,data:o},...Wt(a,u)]})}},$u=e=>{const t=e.customDataBuffer;return new Uint32Array(t,t.byteOffset,1)[0]},bu=(e,t)=>{const n=[],i=[],r=[],s=$u(e);if(0!==t.antialias)throw Error("Only default value (0) for Antialias attribute is supported");su(e.inputs,t,s,n,i,r),e.compute(yu(e.inputs[0],t,s,n,i,r),{inputs:[0]})},vu=e=>{const t=e.antialias,n=e.axes,i=e.coordinateTransformMode,r=e.cubicCoeffA,s=0!==e.excludeOutside,a=e.extrapolationValue,o=e.keepAspectRatioPolicy,u=e.mode,d=""===e.nearestMode?"simple":e.nearestMode;return qt({antialias:t,axes:n,coordinateTransformMode:i,cubicCoeffA:r,excludeOutside:s,extrapolationValue:a,keepAspectRatioPolicy:o,mode:u,nearestMode:d})}}}),ul=P({"web/lib/wasm/jsep/webgpu/ops/skip-layer-norm.ts"(){rd(),od(),fd(),xu=e=>{if(!e||e.length<3)throw new Error("layerNorm requires at least 3 inputs.");const t=e[0],n=e[1],i=e[2];if(t.dataType!==n.dataType||t.dataType!==i.dataType)throw new Error("All inputs must have the same data type");if(3!==t.dims.length&&2!==t.dims.length)throw new Error("Input must be 2D or 3D");if(3!==n.dims.length&&2!==n.dims.length)throw new Error("Skip must be 2D or 3D");const r=t.dims[t.dims.length-1],s=t.dims[t.dims.length-2];if(n.dims[n.dims.length-1]!==r)throw new Error("Skip must have the same hidden size as input");if(n.dims[n.dims.length-2]!==s)throw new Error("Skip must have the same sequence length as input");if(1!==i.dims.length)throw new Error("Gamma must be 1D");if(i.dims[i.dims.length-1]!==r)throw new Error("Gamma must have the same hidden size as input");if(e.length>3){const t=e[3];if(1!==t.dims.length)throw new Error("Beta must be 1D");if(t.dims[t.dims.length-1]!==r)throw new Error("Beta must have the same hidden size as input")}if(e.length>4){const t=e[4];if(1!==t.dims.length)throw new Error("Bias must be 1D");if(t.dims[t.dims.length-1]!==r)throw new Error("Bias must have the same hidden size as input")}},ku=(e,t,n,i)=>{const r=t.simplified,s=e[0].dims,a=dt.size(s),o=s,u=a,d=s.slice(-1)[0],l=i?s.slice(0,-1).concat(1):[],p=!r&&e.length>3,c=e.length>4,h=i&&n>1,f=i&&n>2,m=n>3,g=jt(d),_=[{type:12,data:u},{type:12,data:g},{type:12,data:d},{type:1,data:t.epsilon}],w=[{dims:o,dataType:e[0].dataType}];return n>1&&w.push({dims:l,dataType:1}),n>2&&w.push({dims:l,dataType:1}),n>3&&w.push({dims:s,dataType:e[0].dataType}),{name:"SkipLayerNormalization",shaderCache:{hint:`${g};${h};${f};${m}`,inputDependencies:e.map((e,t)=>"type")},getShaderSource:t=>{const n=[Xt("x",e[0].dataType,e[0].dims,g),Xt("skip",e[1].dataType,e[1].dims,g),Xt("gamma",e[2].dataType,e[2].dims,g)];p&&n.push(Xt("beta",e[3].dataType,e[3].dims,g)),c&&n.push(Xt("bias",e[4].dataType,e[4].dims,g)),n.push(Yt("output",e[0].dataType,o,g)),h&&n.push(Yt("mean_output",1,l)),f&&n.push(Yt("inv_std_output",1,l)),m&&n.push(Yt("input_skip_bias_sum",e[0].dataType,o,g));const i=Lt(e[0].dataType),s=Lt(1,g);return`\n\n      ${t.registerUniforms([{name:"output_size",type:"u32"},{name:"components",type:"u32"},{name:"hidden_size",type:"u32"},{name:"epsilon",type:"f32"}]).declareVariables(...n)}\n      var<workgroup> sum_shared : array<${s}, 64>;\n      var<workgroup> sum_squared_shared : array<${s}, 64>;\n\n      ${t.mainStart([64,1,1])}\n        let ix = local_id.x;\n        let iy = global_id.x / 64;\n\n        let hidden_size_vectorized: u32 = uniforms.hidden_size / uniforms.components;\n        var stride = hidden_size_vectorized / 64;\n        let offset = ix * stride + iy * hidden_size_vectorized;\n        let offset1d = stride * ix;\n        if (ix == 63) {\n          stride = hidden_size_vectorized - stride * ix;\n        }\n        for (var i: u32 = 0; i < stride; i++) {\n          let skip_value = skip[offset + i];\n          let bias_value = ${c?"bias[offset1d + i]":i+"(0.0)"};\n          let input_value = x[offset + i];\n          let value = input_value + skip_value + bias_value;\n          ${m?"input_skip_bias_sum[offset + i] = value;":""}\n          output[offset + i] = value;\n          let f32_value = ${Ft(i,g,"value")};\n          sum_shared[ix] += f32_value;\n          sum_squared_shared[ix] += f32_value * f32_value;\n        }\n        workgroupBarrier();\n\n        var reduce_size : u32 = 64;\n        for (var curr_size = reduce_size >> 1;  curr_size > 0; curr_size = reduce_size >> 1) {\n          reduce_size = curr_size + (reduce_size & 1);\n          if (ix < curr_size) {\n            sum_shared[ix] += sum_shared[ix + reduce_size];\n            sum_squared_shared[ix] += sum_squared_shared[ix + reduce_size];\n          }\n          workgroupBarrier();\n        }\n\n        let sum = sum_shared[0];\n        let square_sum = sum_squared_shared[0];\n        let mean = ${Kt("sum",g)} / f32(uniforms.hidden_size);\n        let inv_std_dev = inverseSqrt(${Kt("square_sum",g)} / f32(uniforms.hidden_size) ${r?"":"- mean * mean"} + uniforms.epsilon);\n        ${h?"mean_output[global_idx] = mean;":""}\n        ${f?"inv_std_output[global_idx] = inv_std_dev;":""}\n\n        for (var i: u32 = 0; i < stride; i++) {\n          output[offset + i] = (output[offset + i] ${r?"":`- ${i}(mean)`}) *\n            ${i}(inv_std_dev) * gamma[offset1d + i]\n            ${p?"+ beta[offset1d + i]":""};\n        }\n      }`},getRunData:()=>({outputs:w,dispatchGroup:{x:Math.ceil(u/d)},programUniforms:_})}},Su=(e,t)=>{xu(e.inputs);const n=[0];e.outputCount>1&&n.push(-3),e.outputCount>2&&n.push(-3),e.outputCount>3&&n.push(3),e.compute(ku(e.inputs,t,e.outputCount,!1),{outputs:n})}}}),dl=P({"web/lib/wasm/jsep/webgpu/ops/slice.ts"(){rd(),od(),hd(),fd(),Iu=(e,t)=>{if(!e||e.length<1)throw new Error("too few inputs");if(0!==t.axes.length){if(t.axes.length!==t.starts.length||t.axes.length!==t.ends.length)throw new Error("axes, starts and ends must have the same length")}else if(t.starts.length!==t.ends.length)throw new Error("starts and ends must have the same length");e.slice(1).forEach((t,n)=>{if(6!==e[n+1].dataType&&7!==e[n+1].dataType)throw new Error(`Input ${n} must be an array of int32 or int64`)})},Tu=(e,t)=>{const n=[];if(e.length>t)if(7===e[t].dataType)e[t].getBigInt64Array().forEach(e=>n.push(Number(e)));else{if(6!==e[t].dataType)throw new Error(`Input ${t} must be an array of int32 or int64`);e[t].getInt32Array().forEach(e=>n.push(Number(e)))}return n},zu=(e,t)=>{if(e.length>1){const t=Tu(e,1),n=Tu(e,2);let i=Tu(e,3);return 0===i.length&&(i=[...Array(e[0].dims.length).keys()]),qt({starts:t,ends:n,axes:i})}return t},Eu=(e,t,n,i,r)=>{let s=e;return e<0&&(s+=n[i[t]]),r[t]<0?Math.max(0,Math.min(s,n[i[t]]-1)):Math.max(0,Math.min(s,n[i[t]]))},Cu=(e,t,n)=>`fn calculateInputIndices(output_indices: ${t.type.indices}) -> ${e.type.indices} {\n          var input_indices: ${e.type.indices};\n          var carry = 0u;\n          for (var i = ${n.length-1}; i >= 0; i--) {\n            let input_shape_i = ${Zt("uniforms.input_shape","i",n.length)};\n            let steps_i = ${Zt("uniforms.steps","i",n.length)};\n            let signs_i = ${Zt("uniforms.signs","i",n.length)};\n            let starts_i = ${Zt("uniforms.starts","i",n.length)};\n            var output_index = ${t.indicesGet("output_indices","i")};\n            var input_index = output_index * steps_i + starts_i + carry;\n            carry = input_index / input_shape_i;\n            input_index = input_index % input_shape_i;\n            if (signs_i < 0) {\n              input_index = input_shape_i - input_index - 1u + starts_i;\n            }\n            ${e.indicesSet("input_indices","i","input_index")};\n          }\n          return input_indices;\n      }`,Ou=(e,t)=>{const n=e[0].dims,i=dt.size(n),r=t.axes.length>0?dt.normalizeAxes(t.axes,n.length):[...Array(n.length).keys()];let s=Tu(e,4);s.forEach(e=>0!==e||(()=>{throw new Error("step cannot be 0")})),0===s.length&&(s=Array(r.length).fill(1));const a=t.starts.map((e,t)=>Eu(e,t,n,r,s)),o=t.ends.map((e,t)=>Eu(e,t,n,r,s));if(r.length!==a.length||r.length!==o.length)throw new Error("start, ends and axes should have the same number of elements");if(r.length!==n.length)for(let e=0;e<n.length;++e)r.includes(e)||(a.splice(e,0,0),o.splice(e,0,n[e]),s.splice(e,0,1));const u=s.map(e=>Math.sign(e));s.forEach((e,t,n)=>{if(e<0){const i=(o[t]-a[t])/e,r=a[t],u=r+i*s[t];a[t]=u,o[t]=r,n[t]=-e}});const d=n.slice(0);r.forEach((e,t)=>{d[e]=Math.ceil((o[e]-a[e])/s[e])});const l={dims:d,dataType:e[0].dataType},p=Yt("output",e[0].dataType,d.length),c=Xt("input",e[0].dataType,e[0].dims.length),h=dt.size(d),f=[{name:"outputSize",type:"u32"},{name:"starts",type:"u32",length:a.length},{name:"signs",type:"i32",length:u.length},{name:"steps",type:"u32",length:s.length}],m=[{type:12,data:h},{type:12,data:a},{type:6,data:u},{type:12,data:s},...Wt(e[0].dims,d)];return{name:"Slice",shaderCache:{hint:`${u.length}_${a.length}_${s.length}`,inputDependencies:["rank"]},getShaderSource:e=>`\n      ${e.registerUniforms(f).declareVariables(c,p)}\n        ${Cu(c,p,n)}\n        ${e.mainStart()}\n          ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.outputSize")}\n          let output_indices = ${p.offsetToIndices("global_idx")};\n          let input_indices = calculateInputIndices(output_indices);\n          ${p.setByOffset("global_idx",c.getByIndices("input_indices"))}\n      }`,getRunData:()=>({outputs:[l],dispatchGroup:{x:Math.ceil(i/64)},programUniforms:m})}},Au=(e,t)=>{Iu(e.inputs,t);const n=zu(e.inputs,t);e.compute(Ou(e.inputs,n),{inputs:[0]})},Bu=e=>{const t=e.starts,n=e.ends,i=e.axes;return qt({starts:t,ends:n,axes:i})}}}),ll=P({"web/lib/wasm/jsep/webgpu/ops/softmax.ts"(){rd(),od(),hd(),md(),fd(),Ru=e=>{if(!e||1!==e.length)throw new Error("Softmax op requires 1 input.")},Du=(e,t)=>{const n=e.inputs[0],i=n.dims,r=dt.size(i),s=i.length,a=dt.normalizeAxis(t.axis,s),o=a<i.length-1;let u,d=[];o?(d=Array.from({length:s},(e,t)=>t),d[a]=s-1,d[s-1]=a,u=e.compute(ln(n,d),{inputs:[n],outputs:[-1]})[0]):u=n;const l=u.dims,p=l[s-1],c=r/p,h=jt(p),f=p/h;let m=64;1===c&&(m=256);const g=Xt("x",u.dataType,u.dims,h),_=Yt("result",u.dataType,u.dims,h),w=g.type.value,y="f32"===Lt(u.dataType)?`var threadMax = ${w}(-3.402823e+38f);`:`var threadMax = ${w}(-65504.0h);`,$=e.compute({name:"Softmax",shaderCache:{hint:`${h};${m}`,inputDependencies:["type"]},getRunData:()=>({outputs:[{dims:l,dataType:u.dataType}],dispatchGroup:{x:c},programUniforms:[{type:6,data:f}]}),getShaderSource:e=>{return`\n      var<workgroup> rowMaxShared : ${w};\n      var<workgroup> rowSumShared : ${w};\n      var<workgroup> threadShared : array<${w}, ${m}>;\n\n      fn getValue(row: i32, col: i32, row_stride: i32) -> ${w} {\n        let index = row * row_stride + col;\n        return x[index];\n      }\n\n      fn setValue(row: i32, col: i32, row_stride: i32, value: ${w}) {\n        let index = row * row_stride + col;\n        result[index] = value;\n      }\n      ${e.registerUniform("packedCols","i32").declareVariables(g,_)}\n      ${e.mainStart(m)}\n        let gindex = i32(global_idx);\n        let lindex = i32(local_idx);\n        const wg = ${m};\n        let row = gindex / wg;\n        let cols = uniforms.packedCols;\n        let row_stride : i32 = uniforms.packedCols;\n\n        // find the rows max\n        ${y}\n        for (var col = lindex; col < cols; col += wg) {\n          let value = getValue(row, col, row_stride);\n          threadMax = max(threadMax, value);\n        }\n        if (lindex < cols) {\n          threadShared[lindex] = threadMax;\n        }\n        workgroupBarrier();\n\n        var reduceSize = min(cols, wg);\n        for (var currSize = reduceSize >> 1;  currSize > 0; currSize = reduceSize >> 1) {\n          reduceSize = currSize + (reduceSize & 1);\n          if (lindex < currSize) {\n            threadShared[lindex] = max(threadShared[lindex], threadShared[lindex + reduceSize]);\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowMaxShared = ${w}(${t="threadShared[0]",n=h,4===n?`max(max(${t}.x, ${t}.y), max(${t}.z, ${t}.w))`:2===n?`max(${t}.x, ${t}.y)`:3===n?`max(max(${t}.x, ${t}.y), ${t}.z)`:t});\n        }\n        workgroupBarrier();\n\n        // find the rows sum\n        var threadSum = ${w}(0.0);\n        for (var col = lindex; col < cols; col += wg) {\n          let subExp = exp(getValue(row, col, row_stride) - rowMaxShared);\n          threadSum += subExp;\n        }\n        threadShared[lindex] = threadSum;\n        workgroupBarrier();\n\n        for (var currSize = wg >> 1;  currSize > 0; currSize = currSize >> 1) {\n          if (lindex < currSize) {\n            threadShared[lindex] = threadShared[lindex] + threadShared[lindex + currSize];\n          }\n          workgroupBarrier();\n        }\n        if (lindex == 0) {\n          rowSumShared = ${w}(${Kt("threadShared[0]",h)});\n        }\n        workgroupBarrier();\n\n        // calculate final value for each element in the row\n        for (var col = lindex; col < cols; col += wg) {\n          var value = exp(getValue(row, col, row_stride) - rowMaxShared) / rowSumShared;\n          // max operation protects against NaN since all values should be >=0\n          value = max(value, ${w}(0.0));\n          setValue(row, col, row_stride, value);\n        }\n      }`;var t,n}},{inputs:[u],outputs:[o?-1:0]})[0];o&&e.compute(ln($,d),{inputs:[$]})},Mu=(e,t)=>{Ru(e.inputs),Du(e,t)},Uu=e=>qt({axis:e.axis})}}),pl=P({"web/lib/wasm/jsep/webgpu/ops/tile.ts"(){rd(),od(),fd(),Pu=e=>Array.from(e.getBigInt64Array(),Number),qu=e=>{if(!e||2!==e.length)throw new Error("Tile requires 2 inputs.");if(1!==e[0].dataType&&10!==e[0].dataType&&6!==e[0].dataType&&12!==e[0].dataType)throw new Error("Tile only support float, float16, int32, and uint32 data types");if(7!==e[1].dataType)throw new Error("Tile `repeats` input should be of int64 data type");if(1!==e[1].dims.length)throw new Error("Tile `repeats` input should be 1-D");if(Pu(e[1]).length!==e[0].dims.length)throw new Error("Tile `repeats` input should have same number of elements as rank of input data tensor")},Nu=(e,t)=>{const n=[];for(let i=0;i<e.length;++i)n.push(e[i]*t[i]);return n},Vu=(e,t)=>{const n=e[0].dims,i=null==t?Pu(e[1]):t,r=Nu(n,i),s=dt.size(r),a=e[0].dataType,o=Xt("input",a,n.length),u=Yt("output",a,r.length);return{name:"Tile",shaderCache:{hint:`${i}`,inputDependencies:["rank"]},getRunData:()=>({outputs:[{dims:r,dataType:e[0].dataType}],dispatchGroup:{x:Math.ceil(s/64)},programUniforms:[{type:12,data:s},...Wt(e[0].dims,r)]}),getShaderSource:e=>`\n      const inputShape = ${o.indices(...n)};\n      ${e.registerUniform("output_size","u32").declareVariables(o,u)}\n      ${e.mainStart()}\n      ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.output_size")}\n      let output_indices = ${u.offsetToIndices("global_idx")};\n      var input_indices: ${o.type.indices};\n      for (var i = 0; i < ${n.length}; i++) {\n        let input_dim_i = ${o.indicesGet("uniforms.input_shape","i")};\n        let input_dim_value = ${u.indicesGet("output_indices","i")}  % input_dim_i;\n\n        ${o.indicesSet("input_indices","i","input_dim_value")}\n      }\n      ${u.setByOffset("global_idx",o.getByIndices("input_indices"))}\n    }`}},Lu=e=>{qu(e.inputs),e.compute(Vu(e.inputs),{inputs:[0]})}}}),cl=P({"web/lib/wasm/jsep/webgpu/ops/where.ts"(){rd(),od(),fd(),Gu=(e,t,n,i,r)=>{const s=Yt("output_data",r,n.length,4),a=Xt("a_data",t[1].dataType,t[1].dims.length,4),o=Xt("b_data",t[2].dataType,t[2].dims.length,4),u=Xt("c_data",t[0].dataType,t[0].dims.length,4);let d;const l=(e,t,n)=>`select(${t}, ${e}, ${n})`;if(i){const e=(e,t,n="")=>{const i=`a_data[index_a${t}][component_a${t}]`,r=`b_data[index_b${t}][component_b${t}]`,d=`bool(c_data[index_c${t}] & (0xffu << (component_c${t} * 8)))`;return`\n            let output_indices${t} = ${s.offsetToIndices(`global_idx * 4u + ${t}u`)};\n            let offset_a${t} = ${a.broadcastedIndicesToOffset(`output_indices${t}`,s)};\n            let offset_b${t} = ${o.broadcastedIndicesToOffset(`output_indices${t}`,s)};\n            let offset_c${t} = ${u.broadcastedIndicesToOffset(`output_indices${t}`,s)};\n            let index_a${t} = offset_a${t} / 4u;\n            let index_b${t} = offset_b${t} / 4u;\n            let index_c${t} = offset_c${t} / 4u;\n            let component_a${t} = offset_a${t} % 4u;\n            let component_b${t} = offset_b${t} % 4u;\n            let component_c${t} = offset_c${t} % 4u;\n            ${e}[${t}] = ${n}(${l(i,r,d)});\n          `};d=9===r?`\n            var data = vec4<u32>(0);\n            ${e("data",0,"u32")}\n            ${e("data",1,"u32")}\n            ${e("data",2,"u32")}\n            ${e("data",3,"u32")}\n            output_data[global_idx] = dot(vec4<u32>(0x1, 0x100, 0x10000, 0x1000000), vec4<u32>(data));`:`\n            ${e("output_data[global_idx]",0)}\n            ${e("output_data[global_idx]",1)}\n            ${e("output_data[global_idx]",2)}\n            ${e("output_data[global_idx]",3)}\n          `}else d=s.setByOffset("global_idx",l(a.getByOffset("global_idx"),o.getByOffset("global_idx"),u.getByOffset("global_idx")));return`\n        ${e.registerUniform("vec_size","u32").declareVariables(u,a,o,s)}\n        ${e.mainStart()}\n        ${e.guardAgainstOutOfBoundsWorkgroupSizes("uniforms.vec_size")}\n        ${d}\n      }`},Wu=e=>{const t=e[1].dims,n=e[2].dims,i=e[0].dims,r=e[1].dataType,s=!(dt.areEqual(t,n)&&dt.areEqual(n,i));let a=t,o=dt.size(t);if(s){const e=ut.calcShape(ut.calcShape(t,n,!1),i,!1);if(!e)throw new Error("Can't perform where op on the given tensors");a=e,o=dt.size(a)}const u=Math.ceil(o/4);return{name:"Where",shaderCache:{inputDependencies:["rank","rank","rank"]},getShaderSource:t=>Gu(t,e,a,s,r),getRunData:()=>({outputs:[{dims:a,dataType:r}],dispatchGroup:{x:Math.ceil(o/64/4)},programUniforms:[{type:12,data:u},...Wt(i,t,n,a)]})}},ju=e=>{e.compute(Wu(e.inputs))}}}),hl=P({"web/lib/wasm/jsep/webgpu/op-resolve-rules.ts"(){wd(),yd(),$d(),bd(),xd(),kd(),Sd(),Rd(),Md(),Ud(),Pd(),qd(),Nd(),Vd(),Ld(),Gd(),Wd(),jd(),Hd(),Fd(),Xd(),Yd(),Jd(),el(),tl(),Kd(),nl(),il(),rl(),sl(),al(),_d(),ol(),Qd(),ul(),dl(),ll(),Zd(),pl(),md(),vd(),cl(),Hu=new Map([["Abs",[Ti]],["Acos",[zi]],["Acosh",[Ei]],["Add",[vr]],["ArgMax",[ui,di]],["ArgMin",[oi,di]],["Asin",[Ci]],["Asinh",[Oi]],["Atan",[Ai]],["Atanh",[Bi]],["Attention",[_i]],["AveragePool",[Uo,Mo]],["BatchNormalization",[bi]],["BiasAdd",[ki]],["BiasSplitGelu",[wr]],["Cast",[Di,Ri]],["Ceil",[Pi]],["Clip",[Ui]],["Concat",[Mr,Ur]],["Conv",[bs,_s]],["ConvTranspose",[Os,Ts]],["Cos",[qi]],["Cosh",[Ni]],["CumSum",[Bs,Rs]],["DepthToSpace",[Ps,qs]],["DequantizeLinear",[Ko,Zo]],["Div",[xr]],["Einsum",[Ks,Zs]],["Elu",[Li,Vi]],["Equal",[kr]],["Erf",[Wi]],["Exp",[ji]],["Expand",[ea]],["FastGelu",[na]],["Floor",[Hi]],["FusedConv",[bs,_s]],["Gather",[aa,sa]],["GatherElements",[_a,ga]],["GatherBlockQuantized",[ca,ha]],["GatherND",[ua,da]],["Gelu",[Fi]],["Gemm",[ba,$a]],["GlobalAveragePool",[No,qo]],["GlobalMaxPool",[jo,Wo]],["Greater",[zr]],["GreaterOrEqual",[Cr]],["GridSample",[Ba,Ra]],["GroupQueryAttention",[no]],["HardSigmoid",[tr,er]],["InstanceNormalization",[ao]],["LayerNormalization",[lo]],["LeakyRelu",[Ki,Vi]],["Less",[Er]],["LessOrEqual",[Or]],["Log",[cr]],["MatMul",[co]],["MatMulNBits",[go,_o]],["MaxPool",[Lo,Go]],["Mul",[Sr]],["MultiHeadAttention",[Va,Ua]],["Neg",[Qi]],["Not",[Zi]],["Pad",[Io]],["Pow",[Ir]],["QuickGelu",[mr,Vi]],["Range",[Yo]],["Reciprocal",[Xi]],["ReduceMin",[ti]],["ReduceMean",[Qn]],["ReduceMax",[ei]],["ReduceSum",[ii]],["ReduceProd",[ni]],["ReduceL1",[Xn]],["ReduceL2",[Yn]],["ReduceLogSum",[si]],["ReduceLogSumExp",[Jn]],["ReduceSumSquare",[ri]],["Relu",[Yi]],["Resize",[bu,vu]],["RotaryEmbedding",[Xa]],["ScatterND",[nu,tu]],["Sigmoid",[Ji]],["Sin",[nr]],["Sinh",[ir]],["Slice",[Au,Bu]],["SkipLayerNormalization",[Su]],["Split",[Fa,Ka]],["Sqrt",[rr]],["Softmax",[Mu,Uu]],["Sub",[Tr]],["Tan",[sr]],["Tanh",[or]],["ThresholdedRelu",[pr,Vi]],["Tile",[Lu]],["Transpose",[pn,cn]],["Where",[ju]]])}}),fl=P({"web/lib/wasm/jsep/webgpu/program-manager.ts"(){le(),ad(),fd(),Fu=class{constructor(e){this.backend=e,this.repo=new Map,this.attributesBound=!1}getArtifact(e){return this.repo.get(e)}setArtifact(e,t){this.repo.set(e,t)}run(e,t,n,i,r){T(e.programInfo.name);const s=this.backend.device,a=this.backend.getComputePassEncoder();this.backend.writeTimestamp(2*this.backend.pendingDispatchNumber);const o=[];for(const e of t)o.push({binding:o.length,resource:{buffer:e.buffer}});for(const e of n)o.push({binding:o.length,resource:{buffer:e.buffer}});r&&o.push({binding:o.length,resource:r});const u=s.createBindGroup({layout:e.computePipeline.getBindGroupLayout(0),entries:o,label:e.programInfo.name});if("capturing"===this.backend.sessionStatus){const t={kernelId:this.backend.currentKernelId,computePipeline:e.computePipeline,bindGroup:u,dispatchGroup:i};this.backend.capturedCommandList.get(this.backend.currentSessionId).push(t)}a.setPipeline(e.computePipeline),a.setBindGroup(0,u),a.dispatchWorkgroups(...i),this.backend.writeTimestamp(2*this.backend.pendingDispatchNumber+1),this.backend.pendingDispatchNumber++,(this.backend.pendingDispatchNumber>=this.backend.maxDispatchNumber||"at-passes"===this.backend.queryType)&&this.backend.endComputePass(),this.backend.pendingDispatchNumber>=this.backend.maxDispatchNumber&&this.backend.flush(),z(e.programInfo.name)}dispose(){}build(e,t){T(e.name);const n=this.backend.device,i=[];[{feature:"shader-f16",extension:"f16"},{feature:"subgroups",extension:"subgroups"}].forEach(e=>{n.features.has(e.feature)&&i.push(`enable ${e.extension};`)});const r=nn(t,this.backend.device.limits),s=e.getShaderSource(r),a=`${i.join("\n")}\n${r.additionalImplementations}\n${s}`,o=n.createShaderModule({code:a,label:e.name});at("verbose",()=>`[WebGPU] ${e.name} shader code: ${a}`);const u=n.createComputePipeline({compute:{module:o,entryPoint:"main"},layout:"auto",label:e.name});return z(e.name),{programInfo:e,computePipeline:u,uniformVariablesInfo:r.variablesInfo}}normalizeDispatchGroupSize(e){const t="number"==typeof e?e:e.x,n="number"==typeof e?1:e.y||1,i="number"==typeof e?1:e.z||1,r=this.backend.device.limits.maxComputeWorkgroupsPerDimension;if(t<=r&&n<=r&&i<=r)return[t,n,i];const s=t*n*i;let a=Math.ceil(Math.sqrt(s));if(a>r){if(a=Math.ceil(Math.cbrt(s)),a>r)throw new Error("Total dispatch size exceeds WebGPU maximum.");return[a,a,a]}return[a,a,1]}}}}),ml={};q(ml,{WebGpuBackend:()=>Xu});var gl,_l,wl,yl=P({"web/lib/wasm/jsep/backend-webgpu.ts"(){le(),rd(),ad(),ud(),cd(),hl(),fl(),Ku=(e,t)=>{if(t.length!==e.length)throw new Error(`inputDependencies length ${t.length} is not equal to inputTensors length ${e.length}.`);const n=[];for(let i=0;i<e.length;++i){const r=e[i].dataType;switch(t[i]){case"none":n.push("");break;case"type":n.push(`${r}`);break;case"rank":{const t=e[i].dims.length;n.push(`${r};${t}`);break}case"dims":{const t=e[i].dims.join(",");n.push(`${r};${t}`);break}default:throw new Error(`unsupported input dependency: ${t[i]}`)}}return n.join("|")},Zu=(e,t,n)=>{let i=e.name;return e.shaderCache?.hint&&(i+="["+e.shaderCache.hint+"]"),i+=":"+n+`:${Ku(t,e.shaderCache?.inputDependencies??new Array(t.length).fill("dims"))}`,i},Qu=class{constructor(e){e&&(this.architecture=e.architecture,this.vendor=e.vendor)}isArchitecture(e){return this.architecture===e}isVendor(e){return this.vendor===e}},Xu=class{constructor(){this.currentSessionId=null,this.currentKernelId=null,this.commandEncoder=null,this.computePassEncoder=null,this.maxDispatchNumber=16,this.pendingDispatchNumber=0,this.pendingKernels=[],this.pendingQueries=new Map,this.sessionStatus="default",this.capturedCommandList=new Map,this.capturedPendingKernels=new Map,this.sessionExternalDataMapping=new Map}get currentKernelCustomData(){if(null===this.currentKernelId)throw new Error("currentKernelCustomData(): currentKernelId is null. (should not happen)");let e=this.kernelCustomData.get(this.currentKernelId);return e||(e={},this.kernelCustomData.set(this.currentKernelId,e)),e}async initialize(e,t){this.env=e;const n=[],i={requiredLimits:{maxComputeWorkgroupStorageSize:t.limits.maxComputeWorkgroupStorageSize,maxComputeWorkgroupsPerDimension:t.limits.maxComputeWorkgroupsPerDimension,maxStorageBufferBindingSize:t.limits.maxStorageBufferBindingSize,maxBufferSize:t.limits.maxBufferSize,maxComputeInvocationsPerWorkgroup:t.limits.maxComputeInvocationsPerWorkgroup,maxComputeWorkgroupSizeX:t.limits.maxComputeWorkgroupSizeX,maxComputeWorkgroupSizeY:t.limits.maxComputeWorkgroupSizeY,maxComputeWorkgroupSizeZ:t.limits.maxComputeWorkgroupSizeZ},requiredFeatures:n},r=e=>t.features.has(e)&&n.push(e)&&!0;r("chromium-experimental-timestamp-query-inside-passes")||r("timestamp-query"),r("shader-f16"),r("subgroups"),this.device=await t.requestDevice(i),this.adapterInfo=new Qu(t.info||await t.requestAdapterInfo()),this.gpuDataManager=Ut(this),this.programManager=new Fu(this),this.kernels=new Map,this.kernelPersistentData=new Map,this.kernelCustomData=new Map,rt(e.logLevel,!!e.debug),this.device.onuncapturederror=e=>{e.error instanceof GPUValidationError&&console.error(`An uncaught WebGPU validation error was raised: ${e.error.message}`)},Object.defineProperty(this.env.webgpu,"device",{value:this.device,writable:!1,enumerable:!0,configurable:!1}),Object.defineProperty(this.env.webgpu,"adapter",{value:t,writable:!1,enumerable:!0,configurable:!1}),this.setQueryType()}dispose(){void 0!==this.querySet&&this.querySet.destroy(),this.gpuDataManager.dispose()}getCommandEncoder(){return this.commandEncoder||(this.commandEncoder=this.device.createCommandEncoder()),this.commandEncoder}getComputePassEncoder(){if(!this.computePassEncoder){const e=this.getCommandEncoder(),t={};"at-passes"===this.queryType&&(t.timestampWrites={querySet:this.querySet,beginningOfPassWriteIndex:2*this.pendingDispatchNumber,endOfPassWriteIndex:2*this.pendingDispatchNumber+1}),this.computePassEncoder=e.beginComputePass(t)}return this.computePassEncoder}endComputePass(){this.computePassEncoder&&(this.computePassEncoder.end(),this.computePassEncoder=null)}flush(){if(!this.commandEncoder)return;let e;T(),this.endComputePass(),"none"!==this.queryType&&(this.commandEncoder.resolveQuerySet(this.querySet,0,2*this.pendingDispatchNumber,this.queryResolveBuffer,0),e=this.device.createBuffer({size:2*this.pendingDispatchNumber*8,usage:GPUBufferUsage.MAP_READ|GPUBufferUsage.COPY_DST}),this.pendingQueries.set(e,this.pendingKernels),this.pendingKernels=[],this.commandEncoder.copyBufferToBuffer(this.queryResolveBuffer,0,e,0,2*this.pendingDispatchNumber*8)),this.device.queue.submit([this.commandEncoder.finish()]),this.gpuDataManager.refreshPendingBuffers(),this.commandEncoder=null,this.pendingDispatchNumber=0,"none"!==this.queryType&&e.mapAsync(GPUMapMode.READ).then(()=>{const t=new BigUint64Array(e.getMappedRange()),n=this.pendingQueries.get(e);for(let e=0;e<t.length/2;e++){const i=n[e],r=i.kernelId,s=this.kernels.get(r),a=s.kernelType,o=s.kernelName,u=i.programName,d=i.inputTensorViews,l=i.outputTensorViews,p=t[2*e],c=t[2*e+1];void 0===this.queryTimeBase&&(this.queryTimeBase=p);const h=Number(p-this.queryTimeBase),f=Number(c-this.queryTimeBase);if(!Number.isSafeInteger(h)||!Number.isSafeInteger(f))throw new RangeError("incorrect timestamp range");if(this.env.webgpu.profiling?.ondata)this.env.webgpu.profiling.ondata({version:1,inputsMetadata:d.map(e=>({dims:e.dims,dataType:He(e.dataType)})),outputsMetadata:l.map(e=>({dims:e.dims,dataType:He(e.dataType)})),kernelId:r,kernelType:a,kernelName:o,programName:u,startTime:h,endTime:f});else{let e="";d.forEach((t,n)=>{e+=`input[${n}]: [${t.dims}] | ${He(t.dataType)}, `});let t="";l.forEach((e,n)=>{t+=`output[${n}]: [${e.dims}] | ${He(e.dataType)}, `}),console.log(`[profiling] kernel "${r}|${a}|${o}|${u}" ${e}${t}start time: ${h} ns, execution time: ${f-h} ns`)}S("GPU",`${u}::${p}::${c}`)}e.unmap(),this.pendingQueries.delete(e)}),z()}run(e,t,n,i,r,s){T(e.name);const a=[];for(let e=0;e<t.length;++e){const n=t[e].data;if(0===n)continue;const i=this.gpuDataManager.get(n);if(!i)throw new Error(`no GPU data for input: ${n}`);a.push(i)}const{outputs:o,dispatchGroup:u,programUniforms:d}=e.getRunData(t),l=0===n.length?o.map((e,t)=>t):n;if(l.length!==o.length)throw new Error(`Output size ${l.length} must be equal to ${o.length}.`);const p=[],c=[];for(let e=0;e<o.length;++e){if(!Number.isInteger(l[e])||l[e]<-3||l[e]>=s)throw new Error(`Invalid output index: ${l[e]}`);if(-3===l[e])continue;const t=-1===l[e],n=-2===l[e],a=t||n?r(o[e].dataType,o[e].dims):i(l[e],o[e].dataType,o[e].dims);if(p.push(a),0===a.data)continue;const u=this.gpuDataManager.get(a.data);if(!u)throw new Error(`no GPU data for output: ${a.data}`);if(t&&this.temporaryData.push(u),n){let e=this.kernelPersistentData.get(this.currentKernelId);e||(e=[],this.kernelPersistentData.set(this.currentKernelId,e)),e.push(u)}c.push(u)}if(a.length!==t.length||c.length!==p.length){if(0===c.length)return z(e.name),p;throw new Error(`Program ${e.name} has zero-sized tensor(s) in inputs or outputs. This is not supported now.`)}let h;if(d){let e=0;const t=[];d.forEach(n=>{const i="number"==typeof n.data?[n.data]:n.data;if(0===i.length)return;const r=10===n.type?2:4;let s,a;10===n.type?(a=i.length>4?16:i.length>2?8:i.length*r,s=i.length>4?16:r*i.length):(a=i.length<=2?i.length*r:16,s=16),e=Math.ceil(e/a)*a,t.push(e);const o=10===n.type?8:4;e+=i.length>4?Math.ceil(i.length/o)*s:i.length*r});const n=16;e=Math.ceil(e/n)*n;const i=new ArrayBuffer(e);d.forEach((e,n)=>{const r=t[n],s="number"==typeof e.data?[e.data]:e.data;if(6===e.type)new Int32Array(i,r,s.length).set(s);else if(12===e.type)new Uint32Array(i,r,s.length).set(s);else if(10===e.type)new Uint16Array(i,r,s.length).set(s);else{if(1!==e.type)throw new Error(`Unsupported uniform type: ${He(e.type)}`);new Float32Array(i,r,s.length).set(s)}});const r=this.gpuDataManager.create(e,GPUBufferUsage.COPY_DST|GPUBufferUsage.UNIFORM);this.device.queue.writeBuffer(r.buffer,0,i,0,e),this.gpuDataManager.release(r.id),h={offset:0,size:e,buffer:r.buffer}}const f=this.programManager.normalizeDispatchGroupSize(u),m=1===f[1]&&1===f[2],g=Zu(e,t,m);let _=this.programManager.getArtifact(g);if(_||(_=this.programManager.build(e,f),this.programManager.setArtifact(g,_),at("info",()=>`[artifact] key: ${g}, programName: ${e.name}`)),d&&_.uniformVariablesInfo){if(d.length!==_.uniformVariablesInfo.length)throw new Error(`Uniform variables count mismatch: expect ${_.uniformVariablesInfo.length}, got ${d.length} in program "${_.programInfo.name}".`);for(let e=0;e<d.length;e++){const t=d[e],n=t.type,i="number"==typeof t.data?1:t.data.length,[r,s]=_.uniformVariablesInfo[e];if(n!==r||i!==s)throw new Error(`Uniform variable ${e} mismatch: expect type ${r} with size ${s}, got type ${n} with size ${i} in program "${_.programInfo.name}".`)}}if(at("info",()=>`[ProgramManager] run "${e.name}" (key=${g}) with ${f[0]}x${f[1]}x${f[2]}`),"none"!==this.queryType||"capturing"===this.sessionStatus){const e={kernelId:this.currentKernelId,programName:_.programInfo.name,inputTensorViews:t,outputTensorViews:p};this.pendingKernels.push(e),"capturing"===this.sessionStatus&&this.capturedPendingKernels.get(this.currentSessionId).push(e)}return this.programManager.run(_,a,c,f,h),z(e.name),p}upload(e,t){this.gpuDataManager.upload(e,t)}memcpy(e,t){this.gpuDataManager.memcpy(e,t)}async download(e,t){await this.gpuDataManager.download(e,t)}alloc(e){return this.gpuDataManager.create(e).id}free(e){return this.gpuDataManager.release(e)}createKernel(e,t,n,i){const r=Hu.get(e);if(!r)throw new Error(`kernel not implemented: ${e}`);const s={kernelType:e,kernelName:i,kernelEntry:r[0],attributes:[r[1],n]};this.kernels.set(t,s)}releaseKernel(e){const t=this.kernelPersistentData.get(e);if(t){for(const e of t)this.gpuDataManager.release(e.id);this.kernelPersistentData.delete(e)}this.kernelCustomData.delete(e),this.kernels.delete(e)}computeKernel(e,t,n){const i=this.kernels.get(e);if(!i)throw new Error(`kernel not created: ${e}`);const r=i.kernelType,s=i.kernelName,a=i.kernelEntry,o=i.attributes;if(null!==this.currentKernelId)throw new Error(`kernel "[${r}] ${s}" is not allowed to be called recursively`);this.currentKernelId=e,o[0]&&(o[1]=o[0](o[1]),o[0]=void 0),at("info",()=>`[WebGPU] Start to run kernel "[${r}] ${s}"...`);const u=this.env.debug;this.temporaryData=[];try{return u&&this.device.pushErrorScope("validation"),a(t,o[1]),0}catch(e){return n.push(Promise.resolve(`[WebGPU] Kernel "[${r}] ${s}" failed. ${e}`)),1}finally{u&&n.push(this.device.popErrorScope().then(e=>e?`GPU validation error for kernel "[${r}] ${s}": ${e.message}`:null));for(const e of this.temporaryData)this.gpuDataManager.release(e.id);this.temporaryData=[],this.currentKernelId=null}}registerBuffer(e,t,n,i){let r=this.sessionExternalDataMapping.get(e);r||(r=new Map,this.sessionExternalDataMapping.set(e,r));const s=r.get(t),a=this.gpuDataManager.registerExternalBuffer(n,i,s);return r.set(t,[a,n]),a}unregisterBuffers(e){const t=this.sessionExternalDataMapping.get(e);t&&(t.forEach(e=>this.gpuDataManager.unregisterExternalBuffer(e[0])),this.sessionExternalDataMapping.delete(e))}getBuffer(e){const t=this.gpuDataManager.get(e);if(!t)throw new Error(`no GPU data for buffer: ${e}`);return t.buffer}createDownloader(e,t,n){return async()=>{const i=await Dt(this,e,t);return ft(i.buffer,n)}}writeTimestamp(e){"inside-passes"===this.queryType&&this.computePassEncoder.writeTimestamp(this.querySet,e)}setQueryType(){this.queryType="none",("default"===this.env.webgpu.profiling?.mode||(void 0===this.env.trace?this.env.wasm.trace:this.env.trace))&&(this.device.features.has("chromium-experimental-timestamp-query-inside-passes")?this.queryType="inside-passes":this.device.features.has("timestamp-query")&&(this.queryType="at-passes"),"none"!==this.queryType&&void 0===this.querySet&&(this.querySet=this.device.createQuerySet({type:"timestamp",count:2*this.maxDispatchNumber}),this.queryResolveBuffer=this.device.createBuffer({size:2*this.maxDispatchNumber*8,usage:GPUBufferUsage.COPY_SRC|GPUBufferUsage.QUERY_RESOLVE})))}captureBegin(){at("info","captureBegin"),this.capturedCommandList.get(this.currentSessionId)||this.capturedCommandList.set(this.currentSessionId,[]),this.capturedPendingKernels.get(this.currentSessionId)||this.capturedPendingKernels.set(this.currentSessionId,[]),this.flush(),this.sessionStatus="capturing"}captureEnd(){at("info","captureEnd"),this.flush(),this.sessionStatus="default"}replay(){at("info","replay"),this.sessionStatus="replaying";const e=this.capturedCommandList.get(this.currentSessionId),t=this.capturedPendingKernels.get(this.currentSessionId),n=e.length;this.pendingKernels=[];for(let i=0;i<n;i++){const n=this.getComputePassEncoder(),r=e[i];this.writeTimestamp(2*this.pendingDispatchNumber),n.setPipeline(r.computePipeline),n.setBindGroup(0,r.bindGroup),n.dispatchWorkgroups(...r.dispatchGroup),this.writeTimestamp(2*this.pendingDispatchNumber+1),this.pendingDispatchNumber++,"none"!==this.queryType&&this.pendingKernels.push(t[i]),(this.pendingDispatchNumber>=this.maxDispatchNumber||"at-passes"===this.queryType)&&this.endComputePass(),this.pendingDispatchNumber>=this.maxDispatchNumber&&this.flush()}this.flush(),this.sessionStatus="default"}onCreateSession(){this.gpuDataManager.onCreateSession()}onReleaseSession(e){this.unregisterBuffers(e),this.capturedCommandList.has(e)&&this.capturedCommandList.delete(e),this.capturedPendingKernels.has(e)&&this.capturedPendingKernels.delete(e),this.gpuDataManager.onReleaseSession(e)}onRunStart(e){this.currentSessionId=e,this.setQueryType()}}}}),$l={};q($l,{init:()=>wl});var bl,vl,xl,kl,Sl,Il,Tl,zl,El,Cl,Ol,Al,Bl,Rl,Dl,Ml,Ul,Pl,ql,Nl,Vl,Ll,Gl,Wl,jl,Hl,Fl,Kl,Zl,Ql,Xl,Yl,Jl,ep,tp,np,ip,rp=P({"web/lib/wasm/jsep/init.ts"(){rd(),ad(),od(),ld(),gl=class e{constructor(e,t,n,i){this.module=e,this.dataType=t,this.data=n,this.dims=i}getFloat32Array(){if(1!==this.dataType)throw new Error("Invalid data type");const e=dt.size(this.dims);return 0===e?new Float32Array:new Float32Array(this.module.HEAP8.buffer,this.data,e)}getBigInt64Array(){if(7!==this.dataType)throw new Error("Invalid data type");const e=dt.size(this.dims);return 0===e?new BigInt64Array:new BigInt64Array(this.module.HEAP8.buffer,this.data,e)}getInt32Array(){if(6!==this.dataType)throw new Error("Invalid data type");const e=dt.size(this.dims);return 0===e?new Int32Array:new Int32Array(this.module.HEAP8.buffer,this.data,e)}getUint16Array(){if(10!==this.dataType&&4!==this.dataType)throw new Error("Invalid data type");const e=dt.size(this.dims);return 0===e?new Uint16Array:new Uint16Array(this.module.HEAP8.buffer,this.data,e)}reshape(t){if(dt.size(t)!==dt.size(this.dims))throw new Error("Invalid new shape");return new e(this.module,this.dataType,this.data,t)}},_l=class{constructor(e,t,n){this.module=e,this.backend=t,this.customDataOffset=0,this.customDataSize=0,this.adapterInfo=t.adapterInfo;const i=e.PTR_SIZE;let r=n/e.PTR_SIZE;const s=4===i?"i32":"i64";this.opKernelContext=Number(e.getValue(i*r++,s));const a=Number(e.getValue(i*r++,s));this.outputCount=Number(e.getValue(i*r++,s)),this.customDataOffset=Number(e.getValue(i*r++,"*")),this.customDataSize=Number(e.getValue(i*r++,s));const o=[];for(let t=0;t<a;t++){const t=Number(e.getValue(i*r++,s)),n=Number(e.getValue(i*r++,"*")),a=Number(e.getValue(i*r++,s)),u=[];for(let t=0;t<a;t++)u.push(Number(e.getValue(i*r++,s)));o.push(new gl(e,t,n,u))}this.inputs=o}get kernelCustomData(){return this.backend.currentKernelCustomData}get customDataBuffer(){return this.module.HEAPU8.subarray(this.customDataOffset,this.customDataOffset+this.customDataSize)}compute(e,t){const n=t?.inputs?.map(e=>"number"==typeof e?this.inputs[e]:e)??this.inputs,i=t?.outputs??[];return this.backend.run(e,n,i,(e,t,n)=>new gl(this.module,t,this.output(e,n),n),(e,t)=>{const n=Fe(e,t);if(!n)throw new Error(`Unsupported data type: ${e}`);const i=n>0?this.backend.gpuDataManager.create(n).id:0;return new gl(this.module,e,i,t)},this.outputCount)}output(e,t){const n=this.module.stackSave();try{const n=this.module.PTR_SIZE,i=4===n?"i32":"i64",r=this.module.stackAlloc((1+t.length)*n);this.module.setValue(r,t.length,i);for(let e=0;e<t.length;e++)this.module.setValue(r+n*(e+1),t[e],i);return this.module._JsepOutput(this.opKernelContext,e,r)}catch(n){throw new Error(`Failed to generate kernel's output[${e}] with dims [${t}]. If you are running with pre-allocated output, please make sure the output type/dims are correct. Error: ${n}`)}finally{this.module.stackRestore(n)}}},wl=async(e,t,n,i)=>{const r=t.jsepInit;if(!r)throw new Error("Failed to initialize JSEP. The WebAssembly module is not built with JSEP support.");if("webgpu"===e){const e=new(0,(yl(),N(ml)).WebGpuBackend);await e.initialize(n,i),r("webgpu",[e,t=>e.alloc(Number(t)),t=>e.free(t),(n,i,r,s=!1)=>{if(s)at("verbose",()=>`[WebGPU] jsepCopyGpuToGpu: src=${Number(n)}, dst=${Number(i)}, size=${Number(r)}`),e.memcpy(Number(n),Number(i));else{at("verbose",()=>`[WebGPU] jsepCopyCpuToGpu: dataOffset=${Number(n)}, gpuDataId=${Number(i)}, size=${Number(r)}`);const s=t.HEAPU8.subarray(Number(n>>>0),Number(n>>>0)+Number(r));e.upload(Number(i),s)}},async(n,i,r)=>{at("verbose",()=>`[WebGPU] jsepCopyGpuToCpu: gpuDataId=${n}, dataOffset=${i}, size=${r}`),await e.download(Number(n),()=>t.HEAPU8.subarray(Number(i)>>>0,Number(i+r)>>>0))},(n,i,r)=>e.createKernel(n,Number(i),r,t.UTF8ToString(t._JsepGetNodeName(Number(i)))),t=>e.releaseKernel(t),(n,i,r,s)=>{at("verbose",()=>`[WebGPU] jsepRun: sessionHandle=${r}, kernel=${n}, contextDataOffset=${i}`);const a=new _l(t,e,Number(i));return e.computeKernel(Number(n),a,s)},()=>e.captureBegin(),()=>e.captureEnd(),()=>e.replay()])}else{const e=new zt(n);r("webnn",[e,()=>e.reserveTensorId(),t=>e.releaseTensorId(t),async(t,n,i,r,s)=>e.ensureTensor(t,n,i,r,s),(t,n)=>{e.uploadTensor(t,n)},async(t,n)=>e.downloadTensor(t,n),(t,n)=>e.registerMLContext(t,n),!!n.trace])}}}}),sp=P({"web/lib/wasm/wasm-core-impl.ts"(){le(),nd(),id(),rd(),ed(),td(),sd(),bl=(e,t)=>{0!==Re()._OrtInit(e,t)&&Ue("Can't initialize onnxruntime.")},vl=async e=>{bl(e.wasm.numThreads,Ze(e.logLevel))},xl=async(e,t)=>{Re().asyncInit?.();let n=e.webgpu.adapter;if("webgpu"===t){if("undefined"==typeof navigator||!navigator.gpu)throw new Error("WebGPU is not supported in current environment");if(n){if("object"!=typeof n.limits||"object"!=typeof n.features||"function"!=typeof n.requestDevice)throw new Error("Invalid GPU adapter set in `env.webgpu.adapter`. It must be a GPUAdapter object.")}else{const t=e.webgpu.powerPreference;if(void 0!==t&&"low-power"!==t&&"high-performance"!==t)throw new Error(`Invalid powerPreference setting: "${t}"`);const i=e.webgpu.forceFallbackAdapter;if(void 0!==i&&"boolean"!=typeof i)throw new Error(`Invalid forceFallbackAdapter setting: "${i}"`);if(n=await navigator.gpu.requestAdapter({powerPreference:t,forceFallbackAdapter:i}),!n)throw new Error('Failed to get GPU adapter. You may need to enable flag "--enable-unsafe-webgpu" if you are using Chrome.')}}if("webnn"===t&&("undefined"==typeof navigator||!navigator.ml))throw new Error("WebNN is not supported in current environment");{const i=(rp(),N($l)).init;"webgpu"===t&&await i("webgpu",Re(),e,n),"webnn"===t&&await i("webnn",Re(),e)}},kl=new Map,Sl=e=>{const t=Re(),n=t.stackSave();try{const n=t.PTR_SIZE,i=t.stackAlloc(2*n);0!==t._OrtGetInputOutputCount(e,i,i+n)&&Ue("Can't get session input/output count.");const r=4===n?"i32":"i64";return[Number(t.getValue(i,r)),Number(t.getValue(i+n,r))]}finally{t.stackRestore(n)}},Il=(e,t)=>{const n=Re(),i=n.stackSave();let r=0;try{const i=n.PTR_SIZE,s=n.stackAlloc(2*i);0!==n._OrtGetInputOutputMetadata(e,t,s,s+i)&&Ue("Can't get session input/output metadata.");const a=Number(n.getValue(s,"*"));r=Number(n.getValue(s+i,"*"));const o=n.HEAP32[r/4];if(0===o)return[a,0];const u=n.HEAPU32[r/4+1],d=[];for(let e=0;e<u;e++){const t=Number(n.getValue(r+8+e*i,"*"));d.push(0!==t?n.UTF8ToString(t):Number(n.getValue(r+8+(e+u)*i,"*")))}return[a,o,d]}finally{n.stackRestore(i),0!==r&&n._OrtFree(r)}},Tl=e=>{const t=Re(),n=t._malloc(e.byteLength);if(0===n)throw new Error(`Can't create a session. failed to allocate a buffer of size ${e.byteLength}.`);return t.HEAPU8.set(e,n),[n,e.byteLength]},zl=async(e,t)=>{let n,i;const r=Re();Array.isArray(e)?[n,i]=e:e.buffer===r.HEAPU8.buffer?[n,i]=[e.byteOffset,e.byteLength]:[n,i]=Tl(e);let s=0,a=0,o=0,u=[];const d=[],l=[];try{if([a,u]=await We(t),t?.externalData&&r.mountExternalData){const e=[];for(const n of t.externalData){const t="string"==typeof n?n:n.path;e.push(Je("string"==typeof n?n:n.data).then(e=>{r.mountExternalData(t,e)}))}await Promise.all(e)}for(const e of t?.executionProviders??[])if("webnn"===("string"==typeof e?e:e.name)){if(r.shouldTransferToMLTensor=!1,"string"!=typeof e){const t=e,n=t?.context,i=t?.gpuDevice,s=t?.deviceType,a=t?.powerPreference;r.currentContext=n||(i?await r.webnnCreateMLContext(i):await r.webnnCreateMLContext({deviceType:s,powerPreference:a}))}else r.currentContext=await r.webnnCreateMLContext();break}s=await r._OrtCreateSession(n,i,a),r.webgpuOnCreateSession?.(s),0===s&&Ue("Can't create a session."),r.jsepOnCreateSession?.(),r.currentContext&&(r.webnnRegisterMLContext(s,r.currentContext),r.currentContext=void 0,r.shouldTransferToMLTensor=!0);const[e,p]=Sl(s),c=!!t?.enableGraphCapture,h=[],f=[],m=[],g=[],_=[];for(let t=0;t<e;t++){const[e,n,i]=Il(s,t);0===e&&Ue("Can't get an input name."),d.push(e);const a=r.UTF8ToString(e);h.push(a),m.push(0===n?{name:a,isTensor:!1}:{name:a,isTensor:!0,type:He(n),shape:i})}for(let n=0;n<p;n++){const[i,a,o]=Il(s,n+e);0===i&&Ue("Can't get an output name."),l.push(i);const u=r.UTF8ToString(i);f.push(u),g.push(0===a?{name:u,isTensor:!1}:{name:u,isTensor:!0,type:He(a),shape:o});{if(c&&void 0===t?.preferredOutputLocation){_.push("gpu-buffer");continue}const e="string"==typeof t?.preferredOutputLocation?t.preferredOutputLocation:t?.preferredOutputLocation?.[u]??"cpu",n=r.webnnIsGraphOutput;if("cpu"===e&&n&&n(s,u)){_.push("ml-tensor-cpu-output");continue}if("cpu"!==e&&"cpu-pinned"!==e&&"gpu-buffer"!==e&&"ml-tensor"!==e)throw new Error(`Not supported preferred output location: ${e}.`);if(c&&"gpu-buffer"!==e)throw new Error(`Not supported preferred output location: ${e}. Only 'gpu-buffer' location is supported when enableGraphCapture is true.`);_.push(e)}}let w=null;return _.some(e=>"gpu-buffer"===e||"ml-tensor"===e||"ml-tensor-cpu-output"===e)&&(o=r._OrtCreateBinding(s),0===o&&Ue("Can't create IO binding."),w={handle:o,outputPreferredLocations:_,outputPreferredLocationsEncoded:_.map(e=>"ml-tensor-cpu-output"===e?"ml-tensor":e).map(e=>Ye(e))}),kl.set(s,[s,d,l,w,c,!1]),[s,h,f,m,g]}catch(e){throw d.forEach(e=>r._OrtFree(e)),l.forEach(e=>r._OrtFree(e)),0!==o&&0!==r._OrtReleaseBinding(o)&&Ue("Can't release IO binding."),0!==s&&0!==r._OrtReleaseSession(s)&&Ue("Can't release session."),e}finally{r._free(n),0!==a&&0!==r._OrtReleaseSessionOptions(a)&&Ue("Can't release session options."),u.forEach(e=>r._free(e)),r.unmountExternalData?.()}},El=e=>{const t=Re(),n=kl.get(e);if(!n)throw new Error(`cannot release session. invalid session id: ${e}`);const[i,r,s,a,o]=n;a&&(o&&0!==t._OrtClearBoundOutputs(a.handle)&&Ue("Can't clear bound outputs."),0!==t._OrtReleaseBinding(a.handle)&&Ue("Can't release IO binding.")),t.jsepOnReleaseSession?.(e),t.webnnOnReleaseSession?.(e),t.webgpuOnReleaseSession?.(e),r.forEach(e=>t._OrtFree(e)),s.forEach(e=>t._OrtFree(e)),0!==t._OrtReleaseSession(i)&&Ue("Can't release session."),kl.delete(e)},Cl=async(e,t,n,i,r,s,a=!1)=>{if(!e)return void t.push(0);const o=Re(),u=o.PTR_SIZE,d=e[0],l=e[1],p=e[3];let c,h,f=p;if("string"===d&&("gpu-buffer"===p||"ml-tensor"===p))throw new Error("String tensor is not supported on GPU.");if(a&&"gpu-buffer"!==p)throw new Error(`External buffer must be provided for input/output index ${s} when enableGraphCapture is true.`);if("gpu-buffer"===p){const t=e[2].gpuBuffer;h=Fe(je(d),l);{const e=o.jsepRegisterBuffer;if(!e)throw new Error('Tensor location "gpu-buffer" is not supported without using WebGPU.');c=e(i,s,t,h)}}else if("ml-tensor"===p){const t=e[2].mlTensor;h=Fe(je(d),l);const n=o.webnnRegisterMLTensor;if(!n)throw new Error('Tensor location "ml-tensor" is not supported without using WebNN.');c=n(i,t,je(d),l)}else{const t=e[2];if(Array.isArray(t)){h=u*t.length,c=o._malloc(h),n.push(c);for(let e=0;e<t.length;e++){if("string"!=typeof t[e])throw new TypeError(`tensor data at index ${e} is not a string`);o.setValue(c+e*u,De(t[e],n),"*")}}else{const e=o.webnnIsGraphInput,s=o.webnnIsGraphOutput;if("string"!==d&&e&&s){const a=o.UTF8ToString(r);if(e(i,a)||s(i,a)){const e=je(d);h=Fe(e,l),f="ml-tensor";const n=o.webnnCreateTemporaryTensor,r=o.webnnUploadTensor;if(!n||!r)throw new Error('Tensor location "ml-tensor" is not supported without using WebNN.');const s=await n(i,e,l);r(s,new Uint8Array(t.buffer,t.byteOffset,t.byteLength)),c=s}else h=t.byteLength,c=o._malloc(h),n.push(c),o.HEAPU8.set(new Uint8Array(t.buffer,t.byteOffset,h),c)}else h=t.byteLength,c=o._malloc(h),n.push(c),o.HEAPU8.set(new Uint8Array(t.buffer,t.byteOffset,h),c)}}const m=o.stackSave(),g=o.stackAlloc(4*l.length);try{l.forEach((e,t)=>o.setValue(g+t*u,e,4===u?"i32":"i64"));const e=o._OrtCreateTensor(je(d),c,h,g,l.length,Ye(f));0===e&&Ue(`Can't create tensor for input/output. session=${i}, index=${s}.`),t.push(e)}finally{o.stackRestore(m)}},Ol=async(e,t,n,i,r,s)=>{const a=Re(),o=a.PTR_SIZE,u=kl.get(e);if(!u)throw new Error(`cannot run inference. invalid session id: ${e}`);const d=u[0],l=u[1],p=u[2],c=u[3],h=u[4],f=u[5],m=t.length,g=i.length;let _=0,w=[];const y=[],$=[],b=[],v=a.stackSave(),x=a.stackAlloc(m*o),k=a.stackAlloc(m*o),S=a.stackAlloc(g*o),I=a.stackAlloc(g*o);try{[_,w]=Pe(s),E("wasm prepareInputOutputTensor");for(let i=0;i<m;i++)await Cl(n[i],y,b,e,l[t[i]],t[i],h);for(let t=0;t<g;t++)await Cl(r[t],$,b,e,p[i[t]],m+i[t],h);C("wasm prepareInputOutputTensor");for(let e=0;e<m;e++)a.setValue(x+e*o,y[e],"*"),a.setValue(k+e*o,l[t[e]],"*");for(let e=0;e<g;e++)a.setValue(S+e*o,$[e],"*"),a.setValue(I+e*o,p[i[e]],"*");if(c&&!f){const{handle:n,outputPreferredLocations:s,outputPreferredLocationsEncoded:o}=c;if(l.length!==m)throw new Error(`input count from feeds (${m}) is expected to be always equal to model's input count (${l.length}).`);E("wasm bindInputsOutputs");for(let i=0;i<m;i++){const r=t[i];0!==await a._OrtBindInput(n,l[r],y[i])&&Ue(`Can't bind input[${i}] for session=${e}.`)}for(let t=0;t<g;t++){const u=i[t],d=r[t]?.[3];d?0!==a._OrtBindOutput(n,p[u],$[t],0)&&Ue(`Can't bind pre-allocated output[${t}] for session=${e}.`):0!==a._OrtBindOutput(n,p[u],0,o[u])&&Ue(`Can't bind output[${t}] to ${s[t]} for session=${e}.`)}C("wasm bindInputsOutputs"),kl.set(e,[d,l,p,c,h,!0])}let u;a.jsepOnRunStart?.(d),a.webnnOnRunStart?.(d),u=c?await a._OrtRunWithBinding(d,c.handle,g,S,_):await a._OrtRun(d,k,x,m,I,g,S,_),0!==u&&Ue("failed to call OrtRun().");const v=[],T=[];E("wasm ProcessOutputTensor");for(let t=0;t<g;t++){const n=Number(a.getValue(S+t*o,"*"));if(n===$[t]){v.push(r[t]);continue}const s=a.stackSave(),u=a.stackAlloc(4*o);let d,l=!1,p=0;try{0!==a._OrtGetTensorData(n,u,u+o,u+2*o,u+3*o)&&Ue(`Can't access output tensor data on index ${t}.`);const r=4===o?"i32":"i64",s=Number(a.getValue(u,r));p=a.getValue(u+o,"*");const h=a.getValue(u+2*o,"*"),f=Number(a.getValue(u+3*o,r)),m=[];for(let e=0;e<f;e++)m.push(Number(a.getValue(h+e*o,r)));0!==a._OrtFree(h)&&Ue("Can't free memory for tensor dims.");const g=m.reduce((e,t)=>e*t,1);d=He(s);const _=c?.outputPreferredLocations[i[t]];if("string"===d){if("gpu-buffer"===_||"ml-tensor"===_)throw new Error("String tensor is not supported on GPU.");const e=[];for(let t=0;t<g;t++){const n=a.getValue(p+t*o,"*"),i=a.getValue(p+(t+1)*o,"*"),r=t===g-1?void 0:i-n;e.push(a.UTF8ToString(n,r))}v.push([d,m,e,"cpu"])}else if("gpu-buffer"===_&&g>0){const e=a.jsepGetBuffer;if(!e)throw new Error('preferredLocation "gpu-buffer" is not supported without using WebGPU.');const t=e(p),i=Fe(s,g);if(void 0===i||!Qe(d))throw new Error(`Unsupported data type: ${d}`);l=!0,v.push([d,m,{gpuBuffer:t,download:a.jsepCreateDownloader(t,i,d),dispose:()=>{0!==a._OrtReleaseTensor(n)&&Ue("Can't release tensor.")}},"gpu-buffer"])}else if("ml-tensor"===_&&g>0){const t=a.webnnEnsureTensor,i=a.webnnIsGraphInputOutputTypeSupported;if(!t||!i)throw new Error('preferredLocation "ml-tensor" is not supported without using WebNN.');if(void 0===Fe(s,g)||!Xe(d))throw new Error(`Unsupported data type: ${d}`);if(!i(e,d,!1))throw new Error(`preferredLocation "ml-tensor" for ${d} output is not supported by current WebNN Context.`);const r=await t(e,p,s,m,!1);l=!0,v.push([d,m,{mlTensor:r,download:a.webnnCreateMLTensorDownloader(p,d),dispose:()=>{a.webnnReleaseTensorId(p),a._OrtReleaseTensor(n)}},"ml-tensor"])}else if("ml-tensor-cpu-output"===_&&g>0){const e=a.webnnCreateMLTensorDownloader(p,d)(),t=v.length;l=!0,T.push((async()=>{const i=[t,await e];return a.webnnReleaseTensorId(p),a._OrtReleaseTensor(n),i})()),v.push([d,m,[],"cpu"])}else{const e=new(Ke(d))(g);new Uint8Array(e.buffer,e.byteOffset,e.byteLength).set(a.HEAPU8.subarray(p,p+e.byteLength)),v.push([d,m,e,"cpu"])}}finally{a.stackRestore(s),"string"===d&&p&&a._free(p),l||a._OrtReleaseTensor(n)}}c&&!h&&(0!==a._OrtClearBoundOutputs(c.handle)&&Ue("Can't clear bound outputs."),kl.set(e,[d,l,p,c,h,!1]));for(const[e,t]of await Promise.all(T))v[e][2]=t;return C("wasm ProcessOutputTensor"),v}finally{a.webnnOnRunEnd?.(d),a.stackRestore(v),y.forEach(e=>a._OrtReleaseTensor(e)),$.forEach(e=>a._OrtReleaseTensor(e)),b.forEach(e=>a._free(e)),0!==_&&a._OrtReleaseRunOptions(_),w.forEach(e=>a._free(e))}},Al=e=>{const t=Re(),n=kl.get(e);if(!n)throw new Error("invalid session id");const i=n[0],r=t._OrtEndProfiling(i);0===r&&Ue("Can't get an profile file name."),t._OrtFree(r)},Bl=e=>{const t=[];for(const n of e){const e=n[2];!Array.isArray(e)&&"buffer"in e&&t.push(e.buffer)}return t}}}),ap=P({"web/lib/wasm/proxy-wrapper.ts"(){le(),sp(),ed(),Ju(),Rl=()=>!!u.wasm.proxy&&"undefined"!=typeof document,Ml=!1,Ul=!1,Pl=!1,Vl=new Map,Ll=(e,t)=>{const n=Vl.get(e);n?n.push(t):Vl.set(e,[t])},Gl=()=>{if(Ml||!Ul||Pl||!Dl)throw new Error("worker not ready")},Wl=e=>{switch(e.data.type){case"init-wasm":Ml=!1,e.data.err?(Pl=!0,Nl[1](e.data.err)):(Ul=!0,Nl[0]()),ql&&(URL.revokeObjectURL(ql),ql=void 0);break;case"init-ep":case"copy-from":case"create":case"release":case"run":case"end-profiling":{const t=Vl.get(e.data.type);e.data.err?t.shift()[1](e.data.err):t.shift()[0](e.data.out);break}}},jl=async()=>{if(!Ul){if(Ml)throw new Error("multiple calls to 'initWasm()' detected.");if(Pl)throw new Error("previous call to 'initWasm()' failed.");if(Ml=!0,Rl())return new Promise((e,t)=>{Dl?.terminate(),xe().then(([n,i])=>{try{(Dl=i).onerror=e=>t(e),Dl.onmessage=Wl,Nl=[e,t];const r={type:"init-wasm",in:u};if(!r.in.wasm.wasmPaths&&n){const e=ge();e&&(r.in.wasm.wasmPaths=e)}Dl.postMessage(r),ql=n}catch(e){t(e)}},t)});try{await Be(u.wasm),await vl(u),Ul=!0}catch(e){throw Pl=!0,e}finally{Ml=!1}}},Hl=async e=>{if(Rl())return Gl(),new Promise((t,n)=>{Ll("init-ep",[t,n]);const i={type:"init-ep",in:{epName:e,env:u}};Dl.postMessage(i)});await xl(u,e)},Fl=async e=>Rl()?(Gl(),new Promise((t,n)=>{Ll("copy-from",[t,n]);const i={type:"copy-from",in:{buffer:e}};Dl.postMessage(i,[e.buffer])})):Tl(e),Kl=async(e,t)=>{if(Rl()){if(t?.preferredOutputLocation)throw new Error('session option "preferredOutputLocation" is not supported for proxy.');return Gl(),new Promise((n,i)=>{Ll("create",[n,i]);const r={type:"create",in:{model:e,options:{...t}}},s=[];e instanceof Uint8Array&&s.push(e.buffer),Dl.postMessage(r,s)})}return zl(e,t)},Zl=async e=>{if(Rl())return Gl(),new Promise((t,n)=>{Ll("release",[t,n]);const i={type:"release",in:e};Dl.postMessage(i)});El(e)},Ql=async(e,t,n,i,r,s)=>{if(Rl()){if(n.some(e=>"cpu"!==e[3]))throw new Error("input tensor on GPU is not supported for proxy.");if(r.some(e=>e))throw new Error("pre-allocated output tensor is not supported for proxy.");return Gl(),new Promise((r,a)=>{Ll("run",[r,a]);const o=n,u={type:"run",in:{sessionId:e,inputIndices:t,inputs:o,outputIndices:i,options:s}};Dl.postMessage(u,Bl(o))})}return Ol(e,t,n,i,r,s)},Xl=async e=>{if(Rl())return Gl(),new Promise((t,n)=>{Ll("end-profiling",[t,n]);const i={type:"end-profiling",in:e};Dl.postMessage(i)});Al(e)}}}),op=P({"web/lib/wasm/session-handler-inference.ts"(){le(),ap(),rd(),pe(),sd(),Yl=(e,t)=>{switch(e.location){case"cpu":return[e.type,e.dims,e.data,"cpu"];case"gpu-buffer":return[e.type,e.dims,{gpuBuffer:e.gpuBuffer},"gpu-buffer"];case"ml-tensor":return[e.type,e.dims,{mlTensor:e.mlTensor},"ml-tensor"];default:throw new Error(`invalid data location: ${e.location} for ${t()}`)}},Jl=e=>{switch(e[3]){case"cpu":return new k(e[0],e[2],e[1]);case"gpu-buffer":{const t=e[0];if(!Qe(t))throw new Error(`not supported data type: ${t} for deserializing GPU tensor`);const{gpuBuffer:n,download:i,dispose:r}=e[2];return k.fromGpuBuffer(n,{dataType:t,dims:e[1],download:i,dispose:r})}case"ml-tensor":{const t=e[0];if(!Xe(t))throw new Error(`not supported data type: ${t} for deserializing MLTensor tensor`);const{mlTensor:n,download:i,dispose:r}=e[2];return k.fromMLTensor(n,{dataType:t,dims:e[1],download:i,dispose:r})}default:throw new Error(`invalid data location: ${e[3]}`)}},ep=class{async fetchModelAndCopyToWasmMemory(e){return Fl(await Je(e))}async loadModel(e,t){let n;T(),n="string"==typeof e?ae?await Je(e):await this.fetchModelAndCopyToWasmMemory(e):e,[this.sessionId,this.inputNames,this.outputNames,this.inputMetadata,this.outputMetadata]=await Kl(n,t),z()}async dispose(){return Zl(this.sessionId)}async run(e,t,n){T();const i=[],r=[];Object.entries(e).forEach(e=>{const t=e[0],n=e[1],s=this.inputNames.indexOf(t);if(-1===s)throw new Error(`invalid input '${t}'`);i.push(n),r.push(s)});const s=[],a=[];Object.entries(t).forEach(e=>{const t=e[0],n=e[1],i=this.outputNames.indexOf(t);if(-1===i)throw new Error(`invalid output '${t}'`);s.push(n),a.push(i)});const o=i.map((e,t)=>Yl(e,()=>`input "${this.inputNames[r[t]]}"`)),u=s.map((e,t)=>e?Yl(e,()=>`output "${this.outputNames[a[t]]}"`):null),d=await Ql(this.sessionId,r,o,a,u,n),l={};for(let e=0;e<d.length;e++)l[this.outputNames[a[e]]]=s[e]??Jl(d[e]);return z(),l}startProfiling(){}endProfiling(){Xl(this.sessionId)}}}}),up={};q(up,{OnnxruntimeWebAssemblyBackend:()=>np,initializeFlags:()=>tp,wasmBackend:()=>ip});var dp=P({"web/lib/backend-wasm.ts"(){le(),ap(),op(),tp=()=>{("number"!=typeof u.wasm.initTimeout||u.wasm.initTimeout<0)&&(u.wasm.initTimeout=0);const e=u.wasm.simd;if("boolean"!=typeof e&&void 0!==e&&"fixed"!==e&&"relaxed"!==e&&(console.warn(`Property "env.wasm.simd" is set to unknown value "${e}". Reset it to \`false\` and ignore SIMD feature checking.`),u.wasm.simd=!1),"boolean"!=typeof u.wasm.proxy&&(u.wasm.proxy=!1),"boolean"!=typeof u.wasm.trace&&(u.wasm.trace=!1),"number"!=typeof u.wasm.numThreads||!Number.isInteger(u.wasm.numThreads)||u.wasm.numThreads<=0)if("undefined"==typeof self||self.crossOriginIsolated){const e="undefined"==typeof navigator?U("node:os").cpus().length:navigator.hardwareConcurrency;u.wasm.numThreads=Math.min(4,Math.ceil((e||1)/2))}else u.wasm.numThreads=1},ip=new(np=class{async init(e){tp(),await jl(),await Hl(e)}async createInferenceSessionHandler(e,t){const n=new ep;return await n.loadModel(e,t),n}})}});le(),le(),le();var lp=se;{const e=(dp(),N(up)).wasmBackend;n("webgpu",e,5),n("webnn",e,5),n("cpu",e,10),n("wasm",e,10)}Object.defineProperty(u.versions,"web",{value:"1.23.0",enumerable:!0});export{A as InferenceSession,S as TRACE,E as TRACE_EVENT_BEGIN,C as TRACE_EVENT_END,T as TRACE_FUNC_BEGIN,z as TRACE_FUNC_END,k as Tensor,lp as default,u as env,n as registerBackend};